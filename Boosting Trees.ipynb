{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": [
        "mE0-HTsY4K6l",
        "jfrfTZuo4SvV",
        "GKNqIWOjz6hk",
        "UdfyC3CY34i6",
        "YIwoZJfR4acJ",
        "a674KREG8bwc",
        "ZYX_QEeq97JC",
        "2DLeVDeY_VNv",
        "WfpYdyxiAOEe",
        "n1d0heI0DmeI",
        "Y7RwtoBaD5Go"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Setting up project"
      ],
      "metadata": {
        "id": "cSdYKLDsyCnR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sGFOX8X3zW5i"
      },
      "outputs": [],
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn import svm\n",
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "from sklearn import metrics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load csv data file\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "-Jfw7Skg0Uvm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "fc5a00d2-d8ab-486c-d248-4bfddcff7ac4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e7a2b355-6448-48ef-b4c6-7901d8c13dc0\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e7a2b355-6448-48ef-b4c6-7901d8c13dc0\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving CS3244_parsed_data full.csv to CS3244_parsed_data full.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read and prepare data\n",
        "import io\n",
        "df = pd.read_csv(io.BytesIO(uploaded['CS3244_parsed_data full.csv']))"
      ],
      "metadata": {
        "id": "xCubSZU8E14I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initial testings"
      ],
      "metadata": {
        "id": "r6ttjoGplBc5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = []\n",
        "y_train_7 = []\n",
        "y_train_30 = []\n",
        "x_test = []\n",
        "y_test_7 = []\n",
        "y_test_30 = []\n",
        "features_all = ['avg', 'vol', 'avg7', 'sd7', 'range7', 'vol7',  'dir7', 'tend7', 'avg30', 'sd30', 'range30', 'vol30', 'dir30', 'tend30', 'RSI', 'stosc', 'MACD']\n",
        "labels = ['dirNext1', 'dirNext7','dirNext30']\n",
        "count_1 = 0\n",
        "count_0 = 0\n",
        "count_2 = 0\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "  if (isinstance(row['date'], str)):\n",
        "    dt = datetime.strptime(row['date'], '%d/%m/%Y')\n",
        "    curr = []\n",
        "\n",
        "    date = int(dt.strftime('%Y-%m-%d').translate({ord('-'): None}))\n",
        "    curr.append(date)\n",
        "\n",
        "    for feature in features_all:\n",
        "      curr.append(row[feature])\n",
        "\n",
        "    if (dt.year == 2008 or dt.year == 2012 or dt.year == 2017): # test data\n",
        "      x_test.append(curr)\n",
        "      y_test_7.append(row['dirNext7'])\n",
        "      y_test_30.append(row['dirNext30'])\n",
        "    else: # train data\n",
        "      x_train.append(curr)\n",
        "      y_train_7.append(row['dirNext7'])\n",
        "      y_test_30.append(row['dirNext30'])\n",
        "\n",
        "    if (row['dirNext7'] == 1): \n",
        "        count_1 += 1\n",
        "    elif (row['dirNext7'] == 0):\n",
        "        count_0 += 1\n",
        "    elif (row['dirNext7'] == -1):\n",
        "        count_2 += 1\n",
        "\n",
        "print(count_1)\n",
        "print(count_0)\n",
        "print(count_2)\n",
        "\n"
      ],
      "metadata": {
        "id": "phBPpovfE3oh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "998735e6-9e90-491b-a24f-7169d604f628"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "99639\n",
            "72852\n",
            "69584\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bst = XGBClassifier(n_estimators=5, max_depth=5, learning_rate=1, objective='binary:logistic', tree_method='hist')\n",
        "bst.fit(np.array(x_train), np.array(y_train_7))\n",
        "y_pred_7 = bst.predict(x_test)\n",
        "print(y_pred_7)"
      ],
      "metadata": {
        "id": "p8svlveoFNL8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af345131-665d-4297-9b74-bec52edf9f2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-1  1 -1 ...  1  1 -1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy:\",metrics.accuracy_score(y_test_7, y_pred_7))\n",
        "print(confusion_matrix(y_test_7,y_pred_7))\n",
        "print(classification_report(y_test_7,y_pred_7))"
      ],
      "metadata": {
        "id": "xOZTDZOVFtBJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4826dfa-82a8-4d9c-e641-ba913f99e708"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.423216885007278\n",
            "[[ 2873  2485 11064]\n",
            " [ 1595  3970 10265]\n",
            " [ 2243  4048 16417]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.43      0.17      0.25     16422\n",
            "           0       0.38      0.25      0.30     15830\n",
            "           1       0.43      0.72      0.54     22708\n",
            "\n",
            "    accuracy                           0.42     54960\n",
            "   macro avg       0.41      0.38      0.36     54960\n",
            "weighted avg       0.42      0.42      0.39     54960\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Feature reduction using df7\n",
        "\n",
        "found best set of features : ['tend7', 'avg30', 'sd30', 'range30', 'vol30', 'stosc', 'MACD']"
      ],
      "metadata": {
        "id": "5MDkRNWPlC5V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## removed sd7"
      ],
      "metadata": {
        "id": "mE0-HTsY4K6l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = []\n",
        "y_train_7 = []\n",
        "y_train_30 = []\n",
        "x_test = []\n",
        "y_test_7 = []\n",
        "y_test_30 = []\n",
        "features = ['avg7', 'range7', 'vol7',  'dir7', 'tend7', 'avg30', 'sd30', 'range30', 'vol30', 'dir30', 'tend30', 'RSI', 'stosc', 'MACD']\n",
        "count = len(features)\n",
        "max = 0\n",
        "max_features = ['avg7', 'sd7', 'range7', 'vol7',  'dir7', 'tend7', 'avg30', 'sd30', 'range30', 'vol30', 'dir30', 'tend30', 'RSI', 'stosc', 'MACD']\n",
        "\n",
        "# for y in range(2):\n",
        "for x in range(len(features)): \n",
        "  features_curr = features[:x] + features[x+1:]\n",
        "  print(\"testing features: \")\n",
        "  print(features_curr)\n",
        "\n",
        "  for index, row in df.iterrows():\n",
        "    if (isinstance(row['date'], str)):\n",
        "      dt = datetime.strptime(row['date'], '%d/%m/%Y')\n",
        "      curr = []\n",
        "\n",
        "      for feature in features_curr:\n",
        "        curr.append(row[feature])\n",
        "\n",
        "      if (dt.year == 2008 or dt.year == 2012 or dt.year == 2017): # test data\n",
        "        x_test.append(curr)\n",
        "        # print(curr)\n",
        "        y_test_7.append(row['dirNext7'])\n",
        "      else: # train data\n",
        "        x_train.append(curr)\n",
        "        y_train_7.append(row['dirNext7'])\n",
        "\n",
        "  bst = XGBClassifier(n_estimators=5, max_depth=5, learning_rate=1, objective='binary:logistic', tree_method='hist')\n",
        "  bst.fit(np.array(x_train), np.array(y_train_7))\n",
        "  y_pred_7 = bst.predict(x_test)\n",
        "  accuracy = metrics.accuracy_score(y_test_7, y_pred_7)\n",
        "  print(\"Accuracy:\", accuracy)\n",
        "  print(confusion_matrix(y_test_7,y_pred_7))\n",
        "  print(classification_report(y_test_7,y_pred_7))\n",
        "\n",
        "  if (accuracy > max): \n",
        "    max = accuracy\n",
        "    max_features = features_curr\n",
        "\n",
        "print(\"------------------ end -----------\")\n",
        "print(\"max accuracy:\")\n",
        "print(max)\n",
        "print(max_features)\n",
        "max = 0\n",
        "features = max_features\n",
        "print(\"------------------ end -----------\")\n"
      ],
      "metadata": {
        "id": "FZiqIEYyHBfY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## removed vol7"
      ],
      "metadata": {
        "id": "jfrfTZuo4SvV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = []\n",
        "y_train_7 = []\n",
        "y_train_30 = []\n",
        "x_test = []\n",
        "y_test_7 = []\n",
        "y_test_30 = []\n",
        "features = ['avg7', 'range7', 'dir7', 'tend7', 'avg30', 'sd30', 'range30', 'vol30', 'dir30', 'tend30', 'RSI', 'stosc', 'MACD']\n",
        "count = len(features)\n",
        "max = 0\n",
        "max_features = []\n",
        "\n",
        "# for y in range(2):\n",
        "for x in range(len(features)): \n",
        "  features_curr = features[:x] + features[x+1:]\n",
        "  print(\"testing features: \")\n",
        "  print(features_curr)\n",
        "\n",
        "  for index, row in df.iterrows():\n",
        "    if (isinstance(row['date'], str)):\n",
        "      dt = datetime.strptime(row['date'], '%d/%m/%Y')\n",
        "      curr = []\n",
        "\n",
        "      for feature in features_curr:\n",
        "        curr.append(row[feature])\n",
        "\n",
        "      if (dt.year == 2008 or dt.year == 2012 or dt.year == 2017): # test data\n",
        "        x_test.append(curr)\n",
        "        # print(curr)\n",
        "        y_test_7.append(row['dirNext7'])\n",
        "      else: # train data\n",
        "        x_train.append(curr)\n",
        "        y_train_7.append(row['dirNext7'])\n",
        "\n",
        "  bst = XGBClassifier(n_estimators=5, max_depth=5, learning_rate=1, objective='binary:logistic', tree_method='hist')\n",
        "  bst.fit(np.array(x_train), np.array(y_train_7))\n",
        "  y_pred_7 = bst.predict(x_test)\n",
        "  accuracy = metrics.accuracy_score(y_test_7, y_pred_7)\n",
        "  print(\"Accuracy:\", accuracy)\n",
        "  print(confusion_matrix(y_test_7,y_pred_7))\n",
        "  print(classification_report(y_test_7,y_pred_7))\n",
        "\n",
        "  if (accuracy > max): \n",
        "    max = accuracy\n",
        "    max_features = features_curr\n",
        "\n",
        "print(\"------------------ end -----------\")\n",
        "print(\"max accuracy:\")\n",
        "print(max)\n",
        "print(max_features)\n",
        "max = 0\n",
        "features = max_features\n",
        "print(\"------------------ end -----------\")\n"
      ],
      "metadata": {
        "id": "j4IsJCzAmgLK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e7f9759-6cfa-40c3-fb00-bd77834d647b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "testing features: \n",
            "['range7', 'dir7', 'tend7', 'avg30', 'sd30', 'range30', 'vol30', 'dir30', 'tend30', 'RSI', 'stosc', 'MACD']\n",
            "Accuracy: 0.42194323144104806\n",
            "[[ 2911  2367 11144]\n",
            " [ 1563  3887 10380]\n",
            " [ 2300  4016 16392]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.43      0.18      0.25     16422\n",
            "           0       0.38      0.25      0.30     15830\n",
            "           1       0.43      0.72      0.54     22708\n",
            "\n",
            "    accuracy                           0.42     54960\n",
            "   macro avg       0.41      0.38      0.36     54960\n",
            "weighted avg       0.42      0.42      0.38     54960\n",
            "\n",
            "testing features: \n",
            "['avg7', 'dir7', 'tend7', 'avg30', 'sd30', 'range30', 'vol30', 'dir30', 'tend30', 'RSI', 'stosc', 'MACD']\n",
            "Accuracy: 0.4229803493449782\n",
            "[[ 5562  4850 22432]\n",
            " [ 3074  7622 20964]\n",
            " [ 4264  7842 33310]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.43      0.17      0.24     32844\n",
            "           0       0.38      0.24      0.29     31660\n",
            "           1       0.43      0.73      0.55     45416\n",
            "\n",
            "    accuracy                           0.42    109920\n",
            "   macro avg       0.41      0.38      0.36    109920\n",
            "weighted avg       0.42      0.42      0.38    109920\n",
            "\n",
            "testing features: \n",
            "['avg7', 'range7', 'tend7', 'avg30', 'sd30', 'range30', 'vol30', 'dir30', 'tend30', 'RSI', 'stosc', 'MACD']\n",
            "Accuracy: 0.42244056283357595\n",
            "[[ 8275  7540 33451]\n",
            " [ 4517 11646 31327]\n",
            " [ 6144 12249 49731]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.44      0.17      0.24     49266\n",
            "           0       0.37      0.25      0.30     47490\n",
            "           1       0.43      0.73      0.54     68124\n",
            "\n",
            "    accuracy                           0.42    164880\n",
            "   macro avg       0.41      0.38      0.36    164880\n",
            "weighted avg       0.42      0.42      0.38    164880\n",
            "\n",
            "testing features: \n",
            "['avg7', 'range7', 'dir7', 'avg30', 'sd30', 'range30', 'vol30', 'dir30', 'tend30', 'RSI', 'stosc', 'MACD']\n",
            "Accuracy: 0.41583424308588063\n",
            "[[15001  9162 41525]\n",
            " [ 9682 14964 38674]\n",
            " [14072 15308 61452]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.39      0.23      0.29     65688\n",
            "           0       0.38      0.24      0.29     63320\n",
            "           1       0.43      0.68      0.53     90832\n",
            "\n",
            "    accuracy                           0.42    219840\n",
            "   macro avg       0.40      0.38      0.37    219840\n",
            "weighted avg       0.40      0.42      0.39    219840\n",
            "\n",
            "testing features: \n",
            "['avg7', 'range7', 'dir7', 'tend7', 'sd30', 'range30', 'vol30', 'dir30', 'tend30', 'RSI', 'stosc', 'MACD']\n",
            "Accuracy: 0.4144395924308588\n",
            "[[23404 11850 46856]\n",
            " [14351 19209 45590]\n",
            " [22746 19519 71275]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.39      0.29      0.33     82110\n",
            "           0       0.38      0.24      0.30     79150\n",
            "           1       0.44      0.63      0.51    113540\n",
            "\n",
            "    accuracy                           0.41    274800\n",
            "   macro avg       0.40      0.39      0.38    274800\n",
            "weighted avg       0.40      0.41      0.40    274800\n",
            "\n",
            "testing features: \n",
            "['avg7', 'range7', 'dir7', 'tend7', 'avg30', 'range30', 'vol30', 'dir30', 'tend30', 'RSI', 'stosc', 'MACD']\n",
            "Accuracy: 0.41206028626880153\n",
            "[[24027 13199 61306]\n",
            " [16090 21468 57422]\n",
            " [24250 21612 90386]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.37      0.24      0.29     98532\n",
            "           0       0.38      0.23      0.28     94980\n",
            "           1       0.43      0.66      0.52    136248\n",
            "\n",
            "    accuracy                           0.41    329760\n",
            "   macro avg       0.40      0.38      0.37    329760\n",
            "weighted avg       0.40      0.41      0.39    329760\n",
            "\n",
            "testing features: \n",
            "['avg7', 'range7', 'dir7', 'tend7', 'avg30', 'sd30', 'vol30', 'dir30', 'tend30', 'RSI', 'stosc', 'MACD']\n",
            "Accuracy: 0.4112757330006238\n",
            "[[34857 14756 65341]\n",
            " [22396 24655 63759]\n",
            " [34758 25484 98714]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.38      0.30      0.34    114954\n",
            "           0       0.38      0.22      0.28    110810\n",
            "           1       0.43      0.62      0.51    158956\n",
            "\n",
            "    accuracy                           0.41    384720\n",
            "   macro avg       0.40      0.38      0.38    384720\n",
            "weighted avg       0.40      0.41      0.39    384720\n",
            "\n",
            "testing features: \n",
            "['avg7', 'range7', 'dir7', 'tend7', 'avg30', 'sd30', 'range30', 'dir30', 'tend30', 'RSI', 'stosc', 'MACD']\n",
            "Accuracy: 0.415149654294032\n",
            "[[ 51250  15039  65087]\n",
            " [ 32795  26398  67447]\n",
            " [ 50334  26445 104885]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.38      0.39      0.39    131376\n",
            "           0       0.39      0.21      0.27    126640\n",
            "           1       0.44      0.58      0.50    181664\n",
            "\n",
            "    accuracy                           0.42    439680\n",
            "   macro avg       0.40      0.39      0.39    439680\n",
            "weighted avg       0.41      0.42      0.40    439680\n",
            "\n",
            "testing features: \n",
            "['avg7', 'range7', 'dir7', 'tend7', 'avg30', 'sd30', 'range30', 'vol30', 'tend30', 'RSI', 'stosc', 'MACD']\n",
            "Accuracy: 0.410039624777616\n",
            "[[ 40109  19327  88362]\n",
            " [ 27755  33167  81548]\n",
            " [ 40920  33906 129546]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.37      0.27      0.31    147798\n",
            "           0       0.38      0.23      0.29    142470\n",
            "           1       0.43      0.63      0.51    204372\n",
            "\n",
            "    accuracy                           0.41    494640\n",
            "   macro avg       0.40      0.38      0.37    494640\n",
            "weighted avg       0.40      0.41      0.39    494640\n",
            "\n",
            "testing features: \n",
            "['avg7', 'range7', 'dir7', 'tend7', 'avg30', 'sd30', 'range30', 'vol30', 'dir30', 'RSI', 'stosc', 'MACD']\n",
            "Accuracy: 0.4099963609898108\n",
            "[[ 47135  22271  94814]\n",
            " [ 33960  35906  88434]\n",
            " [ 47586  37201 142293]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.37      0.29      0.32    164220\n",
            "           0       0.38      0.23      0.28    158300\n",
            "           1       0.44      0.63      0.51    227080\n",
            "\n",
            "    accuracy                           0.41    549600\n",
            "   macro avg       0.39      0.38      0.37    549600\n",
            "weighted avg       0.40      0.41      0.39    549600\n",
            "\n",
            "testing features: \n",
            "['avg7', 'range7', 'dir7', 'tend7', 'avg30', 'sd30', 'range30', 'vol30', 'dir30', 'tend30', 'stosc', 'MACD']\n",
            "Accuracy: 0.41370087336244543\n",
            "[[ 49711  22446 108485]\n",
            " [ 34779  38609 100742]\n",
            " [ 49365  38636 161787]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.37      0.28      0.32    180642\n",
            "           0       0.39      0.22      0.28    174130\n",
            "           1       0.44      0.65      0.52    249788\n",
            "\n",
            "    accuracy                           0.41    604560\n",
            "   macro avg       0.40      0.38      0.37    604560\n",
            "weighted avg       0.40      0.41      0.39    604560\n",
            "\n",
            "testing features: \n",
            "['avg7', 'range7', 'dir7', 'tend7', 'avg30', 'sd30', 'range30', 'vol30', 'dir30', 'tend30', 'RSI', 'MACD']\n",
            "Accuracy: 0.40773592916060164\n",
            "[[ 50338  23842 122884]\n",
            " [ 37578  40431 111951]\n",
            " [ 52681  41674 178141]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.36      0.26      0.30    197064\n",
            "           0       0.38      0.21      0.27    189960\n",
            "           1       0.43      0.65      0.52    272496\n",
            "\n",
            "    accuracy                           0.41    659520\n",
            "   macro avg       0.39      0.37      0.36    659520\n",
            "weighted avg       0.40      0.41      0.38    659520\n",
            "\n",
            "testing features: \n",
            "['avg7', 'range7', 'dir7', 'tend7', 'avg30', 'sd30', 'range30', 'vol30', 'dir30', 'tend30', 'RSI', 'stosc']\n",
            "Accuracy: 0.40859926100100774\n",
            "[[ 69228  26035 118223]\n",
            " [ 48331  45372 112087]\n",
            " [ 70841  47027 177336]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.37      0.32      0.34    213486\n",
            "           0       0.38      0.22      0.28    205790\n",
            "           1       0.44      0.60      0.50    295204\n",
            "\n",
            "    accuracy                           0.41    714480\n",
            "   macro avg       0.40      0.38      0.38    714480\n",
            "weighted avg       0.40      0.41      0.39    714480\n",
            "\n",
            "------------------ end -----------\n",
            "max accuracy:\n",
            "0.4229803493449782\n",
            "['avg7', 'dir7', 'tend7', 'avg30', 'sd30', 'range30', 'vol30', 'dir30', 'tend30', 'RSI', 'stosc', 'MACD']\n",
            "------------------ end -----------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## removed range7, accuracy 0.4229803493449782"
      ],
      "metadata": {
        "id": "GKNqIWOjz6hk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = []\n",
        "y_train_7 = []\n",
        "y_train_30 = []\n",
        "x_test = []\n",
        "y_test_7 = []\n",
        "y_test_30 = []\n",
        "features = ['avg7', 'dir7', 'tend7', 'avg30', 'sd30', 'range30', 'vol30', 'dir30', 'tend30', 'RSI', 'stosc', 'MACD']\n",
        "count = len(features)\n",
        "max = 0\n",
        "max_features = []\n",
        "\n",
        "# for y in range(2):\n",
        "for x in range(len(features)): \n",
        "  features_curr = features[:x] + features[x+1:]\n",
        "  print(\"testing features: \")\n",
        "  print(features_curr)\n",
        "\n",
        "  for index, row in df.iterrows():\n",
        "    if (isinstance(row['date'], str)):\n",
        "      dt = datetime.strptime(row['date'], '%d/%m/%Y')\n",
        "      curr = []\n",
        "\n",
        "      for feature in features_curr:\n",
        "        curr.append(row[feature])\n",
        "\n",
        "      if (dt.year == 2008 or dt.year == 2012 or dt.year == 2017): # test data\n",
        "        x_test.append(curr)\n",
        "        # print(curr)\n",
        "        y_test_7.append(row['dirNext7'])\n",
        "      else: # train data\n",
        "        x_train.append(curr)\n",
        "        y_train_7.append(row['dirNext7'])\n",
        "\n",
        "  bst = XGBClassifier(n_estimators=5, max_depth=5, learning_rate=1, objective='binary:logistic', tree_method='hist')\n",
        "  bst.fit(np.array(x_train), np.array(y_train_7))\n",
        "  y_pred_7 = bst.predict(x_test)\n",
        "  accuracy = metrics.accuracy_score(y_test_7, y_pred_7)\n",
        "  print(\"Accuracy:\", accuracy)\n",
        "  print(confusion_matrix(y_test_7,y_pred_7))\n",
        "  print(classification_report(y_test_7,y_pred_7))\n",
        "\n",
        "  if (accuracy > max): \n",
        "    max = accuracy\n",
        "    max_features = features_curr\n",
        "\n",
        "print(\"------------------ end -----------\")\n",
        "print(\"max accuracy:\")\n",
        "print(max)\n",
        "print(max_features)\n",
        "max = 0\n",
        "features = max_features\n",
        "print(\"------------------ end -----------\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUlEyfAnz7P3",
        "outputId": "8e98bba9-d2bc-4a0f-a829-46f3609aa7d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "testing features: \n",
            "['dir7', 'tend7', 'avg30', 'sd30', 'range30', 'vol30', 'dir30', 'tend30', 'RSI', 'stosc', 'MACD']\n",
            "Accuracy: 0.4170487627365357\n",
            "[[ 2924  2537 10961]\n",
            " [ 1779  3841 10210]\n",
            " [ 2497  4055 16156]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.41      0.18      0.25     16422\n",
            "           0       0.37      0.24      0.29     15830\n",
            "           1       0.43      0.71      0.54     22708\n",
            "\n",
            "    accuracy                           0.42     54960\n",
            "   macro avg       0.40      0.38      0.36     54960\n",
            "weighted avg       0.41      0.42      0.38     54960\n",
            "\n",
            "testing features: \n",
            "['avg7', 'tend7', 'avg30', 'sd30', 'range30', 'vol30', 'dir30', 'tend30', 'RSI', 'stosc', 'MACD']\n",
            "Accuracy: 0.42337154294032026\n",
            "[[ 6065  4915 21864]\n",
            " [ 3640  7594 20426]\n",
            " [ 4733  7805 32878]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.42      0.18      0.26     32844\n",
            "           0       0.37      0.24      0.29     31660\n",
            "           1       0.44      0.72      0.55     45416\n",
            "\n",
            "    accuracy                           0.42    109920\n",
            "   macro avg       0.41      0.38      0.36    109920\n",
            "weighted avg       0.41      0.42      0.39    109920\n",
            "\n",
            "testing features: \n",
            "['avg7', 'dir7', 'avg30', 'sd30', 'range30', 'vol30', 'dir30', 'tend30', 'RSI', 'stosc', 'MACD']\n",
            "Accuracy: 0.4131246967491509\n",
            "[[11243  6848 31175]\n",
            " [ 6997 11467 29026]\n",
            " [11002 11716 45406]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.38      0.23      0.29     49266\n",
            "           0       0.38      0.24      0.30     47490\n",
            "           1       0.43      0.67      0.52     68124\n",
            "\n",
            "    accuracy                           0.41    164880\n",
            "   macro avg       0.40      0.38      0.37    164880\n",
            "weighted avg       0.40      0.41      0.39    164880\n",
            "\n",
            "testing features: \n",
            "['avg7', 'dir7', 'tend7', 'sd30', 'range30', 'vol30', 'dir30', 'tend30', 'RSI', 'stosc', 'MACD']\n",
            "Accuracy: 0.41435134643377003\n",
            "[[21308  9093 35287]\n",
            " [13449 14857 35014]\n",
            " [21105 14801 54926]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.38      0.32      0.35     65688\n",
            "           0       0.38      0.23      0.29     63320\n",
            "           1       0.44      0.60      0.51     90832\n",
            "\n",
            "    accuracy                           0.41    219840\n",
            "   macro avg       0.40      0.39      0.38    219840\n",
            "weighted avg       0.41      0.41      0.40    219840\n",
            "\n",
            "testing features: \n",
            "['avg7', 'dir7', 'tend7', 'avg30', 'range30', 'vol30', 'dir30', 'tend30', 'RSI', 'stosc', 'MACD']\n",
            "Accuracy: 0.4139774381368268\n",
            "[[28849 10923 42338]\n",
            " [17696 17472 43982]\n",
            " [28769 17331 67440]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.38      0.35      0.37     82110\n",
            "           0       0.38      0.22      0.28     79150\n",
            "           1       0.44      0.59      0.50    113540\n",
            "\n",
            "    accuracy                           0.41    274800\n",
            "   macro avg       0.40      0.39      0.38    274800\n",
            "weighted avg       0.41      0.41      0.40    274800\n",
            "\n",
            "testing features: \n",
            "['avg7', 'dir7', 'tend7', 'avg30', 'sd30', 'vol30', 'dir30', 'tend30', 'RSI', 'stosc', 'MACD']\n",
            "Accuracy: 0.4103651140223193\n",
            "[[28727 11596 58209]\n",
            " [19560 18463 56957]\n",
            " [28842 19274 88132]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.37      0.29      0.33     98532\n",
            "           0       0.37      0.19      0.26     94980\n",
            "           1       0.43      0.65      0.52    136248\n",
            "\n",
            "    accuracy                           0.41    329760\n",
            "   macro avg       0.39      0.38      0.37    329760\n",
            "weighted avg       0.40      0.41      0.39    329760\n",
            "\n",
            "testing features: \n",
            "['avg7', 'dir7', 'tend7', 'avg30', 'sd30', 'range30', 'dir30', 'tend30', 'RSI', 'stosc', 'MACD']\n",
            "Accuracy: 0.40334529008109793\n",
            "[[29235 21499 64220]\n",
            " [19297 29836 61677]\n",
            " [28670 34182 96104]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.38      0.25      0.30    114954\n",
            "           0       0.35      0.27      0.30    110810\n",
            "           1       0.43      0.60      0.50    158956\n",
            "\n",
            "    accuracy                           0.40    384720\n",
            "   macro avg       0.39      0.38      0.37    384720\n",
            "weighted avg       0.39      0.40      0.39    384720\n",
            "\n",
            "testing features: \n",
            "['avg7', 'dir7', 'tend7', 'avg30', 'sd30', 'range30', 'vol30', 'tend30', 'RSI', 'stosc', 'MACD']\n",
            "Accuracy: 0.4156477438136827\n",
            "[[ 39213  15137  77026]\n",
            " [ 25825  25496  75319]\n",
            " [ 38144  25477 118043]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.38      0.30      0.33    131376\n",
            "           0       0.39      0.20      0.26    126640\n",
            "           1       0.44      0.65      0.52    181664\n",
            "\n",
            "    accuracy                           0.42    439680\n",
            "   macro avg       0.40      0.38      0.37    439680\n",
            "weighted avg       0.41      0.42      0.39    439680\n",
            "\n",
            "testing features: \n",
            "['avg7', 'dir7', 'tend7', 'avg30', 'sd30', 'range30', 'vol30', 'dir30', 'RSI', 'stosc', 'MACD']\n",
            "Accuracy: 0.41045406760472264\n",
            "[[ 48321  16661  82816]\n",
            " [ 33828  27575  81067]\n",
            " [ 49280  27961 127131]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.37      0.33      0.35    147798\n",
            "           0       0.38      0.19      0.26    142470\n",
            "           1       0.44      0.62      0.51    204372\n",
            "\n",
            "    accuracy                           0.41    494640\n",
            "   macro avg       0.40      0.38      0.37    494640\n",
            "weighted avg       0.40      0.41      0.39    494640\n",
            "\n",
            "testing features: \n",
            "['avg7', 'dir7', 'tend7', 'avg30', 'sd30', 'range30', 'vol30', 'dir30', 'tend30', 'stosc', 'MACD']\n",
            "Accuracy: 0.4055349344978166\n",
            "[[ 53234  19407  91579]\n",
            " [ 39344  32164  86792]\n",
            " [ 57388  32208 137484]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.35      0.32      0.34    164220\n",
            "           0       0.38      0.20      0.27    158300\n",
            "           1       0.44      0.61      0.51    227080\n",
            "\n",
            "    accuracy                           0.41    549600\n",
            "   macro avg       0.39      0.38      0.37    549600\n",
            "weighted avg       0.40      0.41      0.39    549600\n",
            "\n",
            "testing features: \n",
            "['avg7', 'dir7', 'tend7', 'avg30', 'sd30', 'range30', 'vol30', 'dir30', 'tend30', 'RSI', 'MACD']\n",
            "Accuracy: 0.4100668254598386\n",
            "[[ 69151  21564  89927]\n",
            " [ 47079  35952  91099]\n",
            " [ 70977  36004 142807]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.37      0.38      0.38    180642\n",
            "           0       0.38      0.21      0.27    174130\n",
            "           1       0.44      0.57      0.50    249788\n",
            "\n",
            "    accuracy                           0.41    604560\n",
            "   macro avg       0.40      0.39      0.38    604560\n",
            "weighted avg       0.40      0.41      0.40    604560\n",
            "\n",
            "testing features: \n",
            "['avg7', 'dir7', 'tend7', 'avg30', 'sd30', 'range30', 'vol30', 'dir30', 'tend30', 'RSI', 'stosc']\n",
            "Accuracy: 0.4097479985443959\n",
            "[[ 43009  28477 125578]\n",
            " [ 29713  42255 117992]\n",
            " [ 41336  46187 184973]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.38      0.22      0.28    197064\n",
            "           0       0.36      0.22      0.28    189960\n",
            "           1       0.43      0.68      0.53    272496\n",
            "\n",
            "    accuracy                           0.41    659520\n",
            "   macro avg       0.39      0.37      0.36    659520\n",
            "weighted avg       0.40      0.41      0.38    659520\n",
            "\n",
            "------------------ end -----------\n",
            "max accuracy:\n",
            "0.42337154294032026\n",
            "['avg7', 'tend7', 'avg30', 'sd30', 'range30', 'vol30', 'dir30', 'tend30', 'RSI', 'stosc', 'MACD']\n",
            "------------------ end -----------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## removed dir 7, accuracy 0.42337154294032026"
      ],
      "metadata": {
        "id": "UdfyC3CY34i6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = []\n",
        "y_train_7 = []\n",
        "y_train_30 = []\n",
        "x_test = []\n",
        "y_test_7 = []\n",
        "y_test_30 = []\n",
        "features = ['avg7', 'tend7', 'avg30', 'sd30', 'range30', 'vol30', 'dir30', 'tend30', 'RSI', 'stosc', 'MACD']\n",
        "count = len(features)\n",
        "max = 0\n",
        "max_features = []\n",
        "\n",
        "# for y in range(2):\n",
        "for x in range(len(features)): \n",
        "  features_curr = features[:x] + features[x+1:]\n",
        "  print(\"testing features: \")\n",
        "  print(features_curr)\n",
        "\n",
        "  for index, row in df.iterrows():\n",
        "    if (isinstance(row['date'], str)):\n",
        "      dt = datetime.strptime(row['date'], '%d/%m/%Y')\n",
        "      curr = []\n",
        "\n",
        "      for feature in features_curr:\n",
        "        curr.append(row[feature])\n",
        "\n",
        "      if (dt.year == 2008 or dt.year == 2012 or dt.year == 2017): # test data\n",
        "        x_test.append(curr)\n",
        "        # print(curr)\n",
        "        y_test_7.append(row['dirNext7'])\n",
        "      else: # train data\n",
        "        x_train.append(curr)\n",
        "        y_train_7.append(row['dirNext7'])\n",
        "\n",
        "  bst = XGBClassifier(n_estimators=5, max_depth=5, learning_rate=1, objective='binary:logistic', tree_method='hist')\n",
        "  bst.fit(np.array(x_train), np.array(y_train_7))\n",
        "  y_pred_7 = bst.predict(x_test)\n",
        "  accuracy = metrics.accuracy_score(y_test_7, y_pred_7)\n",
        "  print(\"Accuracy:\", accuracy)\n",
        "  print(confusion_matrix(y_test_7,y_pred_7))\n",
        "  print(classification_report(y_test_7,y_pred_7))\n",
        "\n",
        "  if (accuracy > max): \n",
        "    max = accuracy\n",
        "    max_features = features_curr\n",
        "\n",
        "print(\"------------------ end -----------\")\n",
        "print(\"max accuracy:\")\n",
        "print(max)\n",
        "print(max_features)\n",
        "max = 0\n",
        "features = max_features\n",
        "print(\"------------------ end -----------\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZ-ttqwO39VU",
        "outputId": "25385b06-0b89-45c9-dba1-0b15c84b9a31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "testing features: \n",
            "['tend7', 'avg30', 'sd30', 'range30', 'vol30', 'dir30', 'tend30', 'RSI', 'stosc', 'MACD']\n",
            "Accuracy: 0.4217066957787482\n",
            "[[ 2706  2314 11402]\n",
            " [ 1584  3623 10623]\n",
            " [ 2169  3691 16848]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.42      0.16      0.24     16422\n",
            "           0       0.38      0.23      0.28     15830\n",
            "           1       0.43      0.74      0.55     22708\n",
            "\n",
            "    accuracy                           0.42     54960\n",
            "   macro avg       0.41      0.38      0.36     54960\n",
            "weighted avg       0.41      0.42      0.38     54960\n",
            "\n",
            "testing features: \n",
            "['avg7', 'avg30', 'sd30', 'range30', 'vol30', 'dir30', 'tend30', 'RSI', 'stosc', 'MACD']\n",
            "Accuracy: 0.4144650655021834\n",
            "[[ 3894  4758 24192]\n",
            " [ 2416  7542 21702]\n",
            " [ 3647  7647 34122]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.39      0.12      0.18     32844\n",
            "           0       0.38      0.24      0.29     31660\n",
            "           1       0.43      0.75      0.54     45416\n",
            "\n",
            "    accuracy                           0.41    109920\n",
            "   macro avg       0.40      0.37      0.34    109920\n",
            "weighted avg       0.40      0.41      0.36    109920\n",
            "\n",
            "testing features: \n",
            "['avg7', 'tend7', 'sd30', 'range30', 'vol30', 'dir30', 'tend30', 'RSI', 'stosc', 'MACD']\n",
            "Accuracy: 0.42128214459000485\n",
            "[[ 6325  7013 35928]\n",
            " [ 3670 11412 32408]\n",
            " [ 5348 11052 51724]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.41      0.13      0.20     49266\n",
            "           0       0.39      0.24      0.30     47490\n",
            "           1       0.43      0.76      0.55     68124\n",
            "\n",
            "    accuracy                           0.42    164880\n",
            "   macro avg       0.41      0.38      0.35    164880\n",
            "weighted avg       0.41      0.42      0.37    164880\n",
            "\n",
            "testing features: \n",
            "['avg7', 'tend7', 'avg30', 'range30', 'vol30', 'dir30', 'tend30', 'RSI', 'stosc', 'MACD']\n",
            "Accuracy: 0.42209788937409026\n",
            "[[ 8590  9275 47823]\n",
            " [ 5078 14977 43265]\n",
            " [ 6668 14937 69227]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.42      0.13      0.20     65688\n",
            "           0       0.38      0.24      0.29     63320\n",
            "           1       0.43      0.76      0.55     90832\n",
            "\n",
            "    accuracy                           0.42    219840\n",
            "   macro avg       0.41      0.38      0.35    219840\n",
            "weighted avg       0.41      0.42      0.37    219840\n",
            "\n",
            "testing features: \n",
            "['avg7', 'tend7', 'avg30', 'sd30', 'vol30', 'dir30', 'tend30', 'RSI', 'stosc', 'MACD']\n",
            "Accuracy: 0.4203129548762737\n",
            "[[12205 11602 58303]\n",
            " [ 6890 17525 54735]\n",
            " [ 9494 18274 85772]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.43      0.15      0.22     82110\n",
            "           0       0.37      0.22      0.28     79150\n",
            "           1       0.43      0.76      0.55    113540\n",
            "\n",
            "    accuracy                           0.42    274800\n",
            "   macro avg       0.41      0.38      0.35    274800\n",
            "weighted avg       0.41      0.42      0.37    274800\n",
            "\n",
            "testing features: \n",
            "['avg7', 'tend7', 'avg30', 'sd30', 'range30', 'dir30', 'tend30', 'RSI', 'stosc', 'MACD']\n",
            "Accuracy: 0.4199357108199903\n",
            "[[ 15269  12368  70895]\n",
            " [  8502  20521  65957]\n",
            " [ 12379  21181 102688]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.42      0.15      0.23     98532\n",
            "           0       0.38      0.22      0.28     94980\n",
            "           1       0.43      0.75      0.55    136248\n",
            "\n",
            "    accuracy                           0.42    329760\n",
            "   macro avg       0.41      0.37      0.35    329760\n",
            "weighted avg       0.41      0.42      0.37    329760\n",
            "\n",
            "testing features: \n",
            "['avg7', 'tend7', 'avg30', 'sd30', 'range30', 'vol30', 'tend30', 'RSI', 'stosc', 'MACD']\n",
            "Accuracy: 0.422325327510917\n",
            "[[ 15627  13519  85808]\n",
            " [  8990  23073  78747]\n",
            " [ 11993  23186 123777]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.43      0.14      0.21    114954\n",
            "           0       0.39      0.21      0.27    110810\n",
            "           1       0.43      0.78      0.55    158956\n",
            "\n",
            "    accuracy                           0.42    384720\n",
            "   macro avg       0.41      0.37      0.34    384720\n",
            "weighted avg       0.42      0.42      0.37    384720\n",
            "\n",
            "testing features: \n",
            "['avg7', 'tend7', 'avg30', 'sd30', 'range30', 'vol30', 'dir30', 'RSI', 'stosc', 'MACD']\n",
            "Accuracy: 0.42119041120815137\n",
            "[[ 20298  17753  93325]\n",
            " [ 12105  28518  86017]\n",
            " [ 16534  28757 136373]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.41      0.15      0.23    131376\n",
            "           0       0.38      0.23      0.28    126640\n",
            "           1       0.43      0.75      0.55    181664\n",
            "\n",
            "    accuracy                           0.42    439680\n",
            "   macro avg       0.41      0.38      0.35    439680\n",
            "weighted avg       0.41      0.42      0.38    439680\n",
            "\n",
            "testing features: \n",
            "['avg7', 'tend7', 'avg30', 'sd30', 'range30', 'vol30', 'dir30', 'tend30', 'stosc', 'MACD']\n",
            "Accuracy: 0.42141355329128255\n",
            "[[ 26439  17164 104195]\n",
            " [ 16451  27701  98318]\n",
            " [ 21313  28751 154308]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.41      0.18      0.25    147798\n",
            "           0       0.38      0.19      0.26    142470\n",
            "           1       0.43      0.76      0.55    204372\n",
            "\n",
            "    accuracy                           0.42    494640\n",
            "   macro avg       0.41      0.38      0.35    494640\n",
            "weighted avg       0.41      0.42      0.38    494640\n",
            "\n",
            "testing features: \n",
            "['avg7', 'tend7', 'avg30', 'sd30', 'range30', 'vol30', 'dir30', 'tend30', 'RSI', 'MACD']\n",
            "Accuracy: 0.41874090247452694\n",
            "[[ 24960  21166 118094]\n",
            " [ 15802  33479 109019]\n",
            " [ 21600  33779 171701]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.40      0.15      0.22    164220\n",
            "           0       0.38      0.21      0.27    158300\n",
            "           1       0.43      0.76      0.55    227080\n",
            "\n",
            "    accuracy                           0.42    549600\n",
            "   macro avg       0.40      0.37      0.35    549600\n",
            "weighted avg       0.41      0.42      0.37    549600\n",
            "\n",
            "testing features: \n",
            "['avg7', 'tend7', 'avg30', 'sd30', 'range30', 'vol30', 'dir30', 'tend30', 'RSI', 'stosc']\n",
            "Accuracy: 0.41973501389440254\n",
            "[[ 22835  22773 135034]\n",
            " [ 14074  36389 123667]\n",
            " [ 18285  36972 194531]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.41      0.13      0.19    180642\n",
            "           0       0.38      0.21      0.27    174130\n",
            "           1       0.43      0.78      0.55    249788\n",
            "\n",
            "    accuracy                           0.42    604560\n",
            "   macro avg       0.41      0.37      0.34    604560\n",
            "weighted avg       0.41      0.42      0.36    604560\n",
            "\n",
            "------------------ end -----------\n",
            "max accuracy:\n",
            "0.422325327510917\n",
            "['avg7', 'tend7', 'avg30', 'sd30', 'range30', 'vol30', 'tend30', 'RSI', 'stosc', 'MACD']\n",
            "------------------ end -----------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## removed dir30, accuracy 0.422325327510917"
      ],
      "metadata": {
        "id": "YIwoZJfR4acJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = []\n",
        "y_train_7 = []\n",
        "y_train_30 = []\n",
        "x_test = []\n",
        "y_test_7 = []\n",
        "y_test_30 = []\n",
        "features = ['avg7', 'tend7', 'avg30', 'sd30', 'range30', 'vol30', 'tend30', 'RSI', 'stosc', 'MACD']\n",
        "count = len(features)\n",
        "max = 0\n",
        "max_features = []\n",
        "\n",
        "# for y in range(2):\n",
        "for x in range(len(features)): \n",
        "  features_curr = features[:x] + features[x+1:]\n",
        "  print(\"testing features: \")\n",
        "  print(features_curr)\n",
        "\n",
        "  for index, row in df.iterrows():\n",
        "    if (isinstance(row['date'], str)):\n",
        "      dt = datetime.strptime(row['date'], '%d/%m/%Y')\n",
        "      curr = []\n",
        "\n",
        "      for feature in features_curr:\n",
        "        curr.append(row[feature])\n",
        "\n",
        "      if (dt.year == 2008 or dt.year == 2012 or dt.year == 2017): # test data\n",
        "        x_test.append(curr)\n",
        "        # print(curr)\n",
        "        y_test_7.append(row['dirNext7'])\n",
        "      else: # train data\n",
        "        x_train.append(curr)\n",
        "        y_train_7.append(row['dirNext7'])\n",
        "\n",
        "  bst = XGBClassifier(n_estimators=5, max_depth=5, learning_rate=1, objective='binary:logistic', tree_method='hist')\n",
        "  bst.fit(np.array(x_train), np.array(y_train_7))\n",
        "  y_pred_7 = bst.predict(x_test)\n",
        "  accuracy = metrics.accuracy_score(y_test_7, y_pred_7)\n",
        "  print(\"Accuracy:\", accuracy)\n",
        "  print(confusion_matrix(y_test_7,y_pred_7))\n",
        "  print(classification_report(y_test_7,y_pred_7))\n",
        "\n",
        "  if (accuracy > max): \n",
        "    max = accuracy\n",
        "    max_features = features_curr\n",
        "\n",
        "print(\"------------------ end -----------\")\n",
        "print(\"max accuracy:\")\n",
        "print(max)\n",
        "print(max_features)\n",
        "max = 0\n",
        "features = max_features\n",
        "print(\"------------------ end -----------\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxODUIrM4ciL",
        "outputId": "89ab038d-3547-406a-e4a3-a4a18ff37baf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "testing features: \n",
            "['tend7', 'avg30', 'sd30', 'range30', 'vol30', 'tend30', 'RSI', 'stosc', 'MACD']\n",
            "Accuracy: 0.4210698689956332\n",
            "[[ 2811  2401 11210]\n",
            " [ 1712  3836 10282]\n",
            " [ 2310  3903 16495]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.41      0.17      0.24     16422\n",
            "           0       0.38      0.24      0.30     15830\n",
            "           1       0.43      0.73      0.54     22708\n",
            "\n",
            "    accuracy                           0.42     54960\n",
            "   macro avg       0.41      0.38      0.36     54960\n",
            "weighted avg       0.41      0.42      0.38     54960\n",
            "\n",
            "testing features: \n",
            "['avg7', 'avg30', 'sd30', 'range30', 'vol30', 'tend30', 'RSI', 'stosc', 'MACD']\n",
            "Accuracy: 0.4182496360989811\n",
            "[[ 4288  4464 24092]\n",
            " [ 2516  7441 21703]\n",
            " [ 3790  7381 34245]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.40      0.13      0.20     32844\n",
            "           0       0.39      0.24      0.29     31660\n",
            "           1       0.43      0.75      0.55     45416\n",
            "\n",
            "    accuracy                           0.42    109920\n",
            "   macro avg       0.41      0.37      0.35    109920\n",
            "weighted avg       0.41      0.42      0.37    109920\n",
            "\n",
            "testing features: \n",
            "['avg7', 'tend7', 'sd30', 'range30', 'vol30', 'tend30', 'RSI', 'stosc', 'MACD']\n",
            "Accuracy: 0.41920184376516256\n",
            "[[ 6396  6661 36209]\n",
            " [ 3930 10967 32593]\n",
            " [ 5567 10802 51755]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.40      0.13      0.20     49266\n",
            "           0       0.39      0.23      0.29     47490\n",
            "           1       0.43      0.76      0.55     68124\n",
            "\n",
            "    accuracy                           0.42    164880\n",
            "   macro avg       0.41      0.37      0.34    164880\n",
            "weighted avg       0.41      0.42      0.37    164880\n",
            "\n",
            "testing features: \n",
            "['avg7', 'tend7', 'avg30', 'range30', 'vol30', 'tend30', 'RSI', 'stosc', 'MACD']\n",
            "Accuracy: 0.42065593158660847\n",
            "[[ 8634  9518 47536]\n",
            " [ 4979 15273 43068]\n",
            " [ 7051 15211 68570]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.42      0.13      0.20     65688\n",
            "           0       0.38      0.24      0.30     63320\n",
            "           1       0.43      0.75      0.55     90832\n",
            "\n",
            "    accuracy                           0.42    219840\n",
            "   macro avg       0.41      0.38      0.35    219840\n",
            "weighted avg       0.41      0.42      0.37    219840\n",
            "\n",
            "testing features: \n",
            "['avg7', 'tend7', 'avg30', 'sd30', 'vol30', 'tend30', 'RSI', 'stosc', 'MACD']\n",
            "Accuracy: 0.4213719068413392\n",
            "[[11915 10910 59285]\n",
            " [ 6546 16764 55840]\n",
            " [ 9155 17271 87114]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.43      0.15      0.22     82110\n",
            "           0       0.37      0.21      0.27     79150\n",
            "           1       0.43      0.77      0.55    113540\n",
            "\n",
            "    accuracy                           0.42    274800\n",
            "   macro avg       0.41      0.37      0.35    274800\n",
            "weighted avg       0.41      0.42      0.37    274800\n",
            "\n",
            "testing features: \n",
            "['avg7', 'tend7', 'avg30', 'sd30', 'range30', 'tend30', 'RSI', 'stosc', 'MACD']\n",
            "Accuracy: 0.419389859291606\n",
            "[[ 15273  12814  70445]\n",
            " [  9235  21639  64106]\n",
            " [ 12443  22419 101386]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.41      0.16      0.23     98532\n",
            "           0       0.38      0.23      0.29     94980\n",
            "           1       0.43      0.74      0.54    136248\n",
            "\n",
            "    accuracy                           0.42    329760\n",
            "   macro avg       0.41      0.38      0.35    329760\n",
            "weighted avg       0.41      0.42      0.37    329760\n",
            "\n",
            "testing features: \n",
            "['avg7', 'tend7', 'avg30', 'sd30', 'range30', 'vol30', 'RSI', 'stosc', 'MACD']\n",
            "Accuracy: 0.4210906633395716\n",
            "[[ 16860  15914  82180]\n",
            " [  9791  25073  75946]\n",
            " [ 13513  25374 120069]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.42      0.15      0.22    114954\n",
            "           0       0.38      0.23      0.28    110810\n",
            "           1       0.43      0.76      0.55    158956\n",
            "\n",
            "    accuracy                           0.42    384720\n",
            "   macro avg       0.41      0.38      0.35    384720\n",
            "weighted avg       0.41      0.42      0.37    384720\n",
            "\n",
            "testing features: \n",
            "['avg7', 'tend7', 'avg30', 'sd30', 'range30', 'vol30', 'tend30', 'stosc', 'MACD']\n",
            "Accuracy: 0.423598981077147\n",
            "[[ 18959  16048  96369]\n",
            " [ 10650  25838  90152]\n",
            " [ 14154  26059 141451]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.43      0.14      0.22    131376\n",
            "           0       0.38      0.20      0.27    126640\n",
            "           1       0.43      0.78      0.56    181664\n",
            "\n",
            "    accuracy                           0.42    439680\n",
            "   macro avg       0.41      0.38      0.35    439680\n",
            "weighted avg       0.42      0.42      0.37    439680\n",
            "\n",
            "testing features: \n",
            "['avg7', 'tend7', 'avg30', 'sd30', 'range30', 'vol30', 'tend30', 'RSI', 'MACD']\n",
            "Accuracy: 0.41925036390101894\n",
            "[[ 18550  18851 110397]\n",
            " [ 11999  31182  99289]\n",
            " [ 16015  30711 157646]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.40      0.13      0.19    147798\n",
            "           0       0.39      0.22      0.28    142470\n",
            "           1       0.43      0.77      0.55    204372\n",
            "\n",
            "    accuracy                           0.42    494640\n",
            "   macro avg       0.40      0.37      0.34    494640\n",
            "weighted avg       0.41      0.42      0.37    494640\n",
            "\n",
            "testing features: \n",
            "['avg7', 'tend7', 'avg30', 'sd30', 'range30', 'vol30', 'tend30', 'RSI', 'stosc']\n",
            "Accuracy: 0.4188901018922853\n",
            "[[ 17614  17419 129187]\n",
            " [ 10601  29572 118127]\n",
            " [ 14133  29911 183036]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.42      0.11      0.17    164220\n",
            "           0       0.38      0.19      0.25    158300\n",
            "           1       0.43      0.81      0.56    227080\n",
            "\n",
            "    accuracy                           0.42    549600\n",
            "   macro avg       0.41      0.37      0.33    549600\n",
            "weighted avg       0.41      0.42      0.35    549600\n",
            "\n",
            "------------------ end -----------\n",
            "max accuracy:\n",
            "0.423598981077147\n",
            "['avg7', 'tend7', 'avg30', 'sd30', 'range30', 'vol30', 'tend30', 'stosc', 'MACD']\n",
            "------------------ end -----------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## removed RSI, accuracy 0.423598981077147"
      ],
      "metadata": {
        "id": "a674KREG8bwc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = []\n",
        "y_train_7 = []\n",
        "y_train_30 = []\n",
        "x_test = []\n",
        "y_test_7 = []\n",
        "y_test_30 = []\n",
        "features = ['avg7', 'tend7', 'avg30', 'sd30', 'range30', 'vol30', 'tend30', 'stosc', 'MACD']\n",
        "count = len(features)\n",
        "max = 0\n",
        "max_features = []\n",
        "\n",
        "# for y in range(2):\n",
        "for x in range(len(features)): \n",
        "  features_curr = features[:x] + features[x+1:]\n",
        "  print(\"testing features: \")\n",
        "  print(features_curr)\n",
        "\n",
        "  for index, row in df.iterrows():\n",
        "    if (isinstance(row['date'], str)):\n",
        "      dt = datetime.strptime(row['date'], '%d/%m/%Y')\n",
        "      curr = []\n",
        "\n",
        "      for feature in features_curr:\n",
        "        curr.append(row[feature])\n",
        "\n",
        "      if (dt.year == 2008 or dt.year == 2012 or dt.year == 2017): # test data\n",
        "        x_test.append(curr)\n",
        "        # print(curr)\n",
        "        y_test_7.append(row['dirNext7'])\n",
        "      else: # train data\n",
        "        x_train.append(curr)\n",
        "        y_train_7.append(row['dirNext7'])\n",
        "\n",
        "  bst = XGBClassifier(n_estimators=5, max_depth=5, learning_rate=1, objective='binary:logistic', tree_method='hist')\n",
        "  bst.fit(np.array(x_train), np.array(y_train_7))\n",
        "  y_pred_7 = bst.predict(x_test)\n",
        "  accuracy = metrics.accuracy_score(y_test_7, y_pred_7)\n",
        "  print(\"Accuracy:\", accuracy)\n",
        "  print(confusion_matrix(y_test_7,y_pred_7))\n",
        "  print(classification_report(y_test_7,y_pred_7))\n",
        "\n",
        "  if (accuracy > max): \n",
        "    max = accuracy\n",
        "    max_features = features_curr\n",
        "\n",
        "print(\"------------------ end -----------\")\n",
        "print(\"max accuracy:\")\n",
        "print(max)\n",
        "print(max_features)\n",
        "max = 0\n",
        "features = max_features\n",
        "print(\"------------------ end -----------\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3854d584-77f7-4254-c9ff-464ab4697cdc",
        "id": "sgS9CXlt8bwd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "testing features: \n",
            "['tend7', 'avg30', 'sd30', 'range30', 'vol30', 'tend30', 'stosc', 'MACD']\n",
            "Accuracy: 0.4262008733624454\n",
            "[[ 2830  2266 11326]\n",
            " [ 1629  3609 10592]\n",
            " [ 2285  3438 16985]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.42      0.17      0.24     16422\n",
            "           0       0.39      0.23      0.29     15830\n",
            "           1       0.44      0.75      0.55     22708\n",
            "\n",
            "    accuracy                           0.43     54960\n",
            "   macro avg       0.41      0.38      0.36     54960\n",
            "weighted avg       0.42      0.43      0.38     54960\n",
            "\n",
            "testing features: \n",
            "['avg7', 'avg30', 'sd30', 'range30', 'vol30', 'tend30', 'stosc', 'MACD']\n",
            "Accuracy: 0.42279839883551673\n",
            "[[ 4150  4633 24061]\n",
            " [ 2507  7666 21487]\n",
            " [ 3553  7205 34658]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.41      0.13      0.19     32844\n",
            "           0       0.39      0.24      0.30     31660\n",
            "           1       0.43      0.76      0.55     45416\n",
            "\n",
            "    accuracy                           0.42    109920\n",
            "   macro avg       0.41      0.38      0.35    109920\n",
            "weighted avg       0.41      0.42      0.37    109920\n",
            "\n",
            "testing features: \n",
            "['avg7', 'tend7', 'sd30', 'range30', 'vol30', 'tend30', 'stosc', 'MACD']\n",
            "Accuracy: 0.42352620087336246\n",
            "[[ 6551  6814 35901]\n",
            " [ 4104 10529 32857]\n",
            " [ 5280 10093 52751]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.41      0.13      0.20     49266\n",
            "           0       0.38      0.22      0.28     47490\n",
            "           1       0.43      0.77      0.56     68124\n",
            "\n",
            "    accuracy                           0.42    164880\n",
            "   macro avg       0.41      0.38      0.35    164880\n",
            "weighted avg       0.41      0.42      0.37    164880\n",
            "\n",
            "testing features: \n",
            "['avg7', 'tend7', 'avg30', 'range30', 'vol30', 'tend30', 'stosc', 'MACD']\n",
            "Accuracy: 0.4257278020378457\n",
            "[[ 9380  8756 47552]\n",
            " [ 5428 13630 44262]\n",
            " [ 7469 12781 70582]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.42      0.14      0.21     65688\n",
            "           0       0.39      0.22      0.28     63320\n",
            "           1       0.43      0.78      0.56     90832\n",
            "\n",
            "    accuracy                           0.43    219840\n",
            "   macro avg       0.41      0.38      0.35    219840\n",
            "weighted avg       0.42      0.43      0.37    219840\n",
            "\n",
            "testing features: \n",
            "['avg7', 'tend7', 'avg30', 'sd30', 'vol30', 'tend30', 'stosc', 'MACD']\n",
            "Accuracy: 0.4253966521106259\n",
            "[[12411  9746 59953]\n",
            " [ 7101 16150 55899]\n",
            " [ 9565 15637 88338]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.43      0.15      0.22     82110\n",
            "           0       0.39      0.20      0.27     79150\n",
            "           1       0.43      0.78      0.56    113540\n",
            "\n",
            "    accuracy                           0.43    274800\n",
            "   macro avg       0.42      0.38      0.35    274800\n",
            "weighted avg       0.42      0.43      0.37    274800\n",
            "\n",
            "testing features: \n",
            "['avg7', 'tend7', 'avg30', 'sd30', 'range30', 'tend30', 'stosc', 'MACD']\n",
            "Accuracy: 0.42580664725861234\n",
            "[[ 14881  12840  70811]\n",
            " [  8191  20278  66511]\n",
            " [ 10764  20229 105255]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.44      0.15      0.22     98532\n",
            "           0       0.38      0.21      0.27     94980\n",
            "           1       0.43      0.77      0.56    136248\n",
            "\n",
            "    accuracy                           0.43    329760\n",
            "   macro avg       0.42      0.38      0.35    329760\n",
            "weighted avg       0.42      0.43      0.38    329760\n",
            "\n",
            "testing features: \n",
            "['avg7', 'tend7', 'avg30', 'sd30', 'range30', 'vol30', 'stosc', 'MACD']\n",
            "Accuracy: 0.42796059471823666\n",
            "[[ 18492  12813  83649]\n",
            " [ 10856  21385  78569]\n",
            " [ 13965  20223 124768]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.43      0.16      0.23    114954\n",
            "           0       0.39      0.19      0.26    110810\n",
            "           1       0.43      0.78      0.56    158956\n",
            "\n",
            "    accuracy                           0.43    384720\n",
            "   macro avg       0.42      0.38      0.35    384720\n",
            "weighted avg       0.42      0.43      0.38    384720\n",
            "\n",
            "testing features: \n",
            "['avg7', 'tend7', 'avg30', 'sd30', 'range30', 'vol30', 'tend30', 'MACD']\n",
            "Accuracy: 0.42202056040756913\n",
            "[[ 15031  14907 101438]\n",
            " [  9907  24261  92472]\n",
            " [ 12758  22644 146262]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.40      0.11      0.18    131376\n",
            "           0       0.39      0.19      0.26    126640\n",
            "           1       0.43      0.81      0.56    181664\n",
            "\n",
            "    accuracy                           0.42    439680\n",
            "   macro avg       0.41      0.37      0.33    439680\n",
            "weighted avg       0.41      0.42      0.36    439680\n",
            "\n",
            "testing features: \n",
            "['avg7', 'tend7', 'avg30', 'sd30', 'range30', 'vol30', 'tend30', 'stosc']\n",
            "Accuracy: 0.4181485524826136\n",
            "[[ 11818  17993 117987]\n",
            " [  8007  29384 105079]\n",
            " [ 10850  27891 165631]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.39      0.08      0.13    147798\n",
            "           0       0.39      0.21      0.27    142470\n",
            "           1       0.43      0.81      0.56    204372\n",
            "\n",
            "    accuracy                           0.42    494640\n",
            "   macro avg       0.40      0.37      0.32    494640\n",
            "weighted avg       0.40      0.42      0.35    494640\n",
            "\n",
            "------------------ end -----------\n",
            "max accuracy:\n",
            "0.42796059471823666\n",
            "['avg7', 'tend7', 'avg30', 'sd30', 'range30', 'vol30', 'stosc', 'MACD']\n",
            "------------------ end -----------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## removed trend30, accuracy 0.42796059471823666"
      ],
      "metadata": {
        "id": "ZYX_QEeq97JC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = []\n",
        "y_train_7 = []\n",
        "y_train_30 = []\n",
        "x_test = []\n",
        "y_test_7 = []\n",
        "y_test_30 = []\n",
        "features = ['avg7', 'tend7', 'avg30', 'sd30', 'range30', 'vol30', 'stosc', 'MACD']\n",
        "count = len(features)\n",
        "max = 0\n",
        "max_features = []\n",
        "\n",
        "# for y in range(2):\n",
        "for x in range(len(features)): \n",
        "  features_curr = features[:x] + features[x+1:]\n",
        "  print(\"testing features: \")\n",
        "  print(features_curr)\n",
        "\n",
        "  for index, row in df.iterrows():\n",
        "    if (isinstance(row['date'], str)):\n",
        "      dt = datetime.strptime(row['date'], '%d/%m/%Y')\n",
        "      curr = []\n",
        "\n",
        "      for feature in features_curr:\n",
        "        curr.append(row[feature])\n",
        "\n",
        "      if (dt.year == 2008 or dt.year == 2012 or dt.year == 2017): # test data\n",
        "        x_test.append(curr)\n",
        "        # print(curr)\n",
        "        y_test_7.append(row['dirNext7'])\n",
        "      else: # train data\n",
        "        x_train.append(curr)\n",
        "        y_train_7.append(row['dirNext7'])\n",
        "\n",
        "  bst = XGBClassifier(n_estimators=5, max_depth=5, learning_rate=1, objective='binary:logistic', tree_method='hist')\n",
        "  bst.fit(np.array(x_train), np.array(y_train_7))\n",
        "  y_pred_7 = bst.predict(x_test)\n",
        "  accuracy = metrics.accuracy_score(y_test_7, y_pred_7)\n",
        "  print(\"Accuracy:\", accuracy)\n",
        "  print(confusion_matrix(y_test_7,y_pred_7))\n",
        "  print(classification_report(y_test_7,y_pred_7))\n",
        "\n",
        "  if (accuracy > max): \n",
        "    max = accuracy\n",
        "    max_features = features_curr\n",
        "\n",
        "print(\"------------------ end -----------\")\n",
        "print(\"max accuracy:\")\n",
        "print(max)\n",
        "print(max_features)\n",
        "max = 0\n",
        "features = max_features\n",
        "print(\"------------------ end -----------\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9794d583-7fb6-4f33-f42c-f194caaa6695",
        "id": "4iitS91a97JD"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "testing features: \n",
            "['tend7', 'avg30', 'sd30', 'range30', 'vol30', 'stosc', 'MACD']\n",
            "Accuracy: 0.4314410480349345\n",
            "[[ 2998  2193 11231]\n",
            " [ 1729  3548 10553]\n",
            " [ 2376  3166 17166]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.42      0.18      0.25     16422\n",
            "           0       0.40      0.22      0.29     15830\n",
            "           1       0.44      0.76      0.56     22708\n",
            "\n",
            "    accuracy                           0.43     54960\n",
            "   macro avg       0.42      0.39      0.37     54960\n",
            "weighted avg       0.42      0.43      0.39     54960\n",
            "\n",
            "testing features: \n",
            "['avg7', 'avg30', 'sd30', 'range30', 'vol30', 'stosc', 'MACD']\n",
            "Accuracy: 0.42648289665211064\n",
            "[[ 4499  3876 24469]\n",
            " [ 2488  6373 22799]\n",
            " [ 3566  5843 36007]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.43      0.14      0.21     32844\n",
            "           0       0.40      0.20      0.27     31660\n",
            "           1       0.43      0.79      0.56     45416\n",
            "\n",
            "    accuracy                           0.43    109920\n",
            "   macro avg       0.42      0.38      0.34    109920\n",
            "weighted avg       0.42      0.43      0.37    109920\n",
            "\n",
            "testing features: \n",
            "['avg7', 'tend7', 'sd30', 'range30', 'vol30', 'stosc', 'MACD']\n",
            "Accuracy: 0.42555798156234836\n",
            "[[ 6310  6298 36658]\n",
            " [ 3490 10090 33910]\n",
            " [ 4746  9612 53766]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.43      0.13      0.20     49266\n",
            "           0       0.39      0.21      0.27     47490\n",
            "           1       0.43      0.79      0.56     68124\n",
            "\n",
            "    accuracy                           0.43    164880\n",
            "   macro avg       0.42      0.38      0.34    164880\n",
            "weighted avg       0.42      0.43      0.37    164880\n",
            "\n",
            "testing features: \n",
            "['avg7', 'tend7', 'avg30', 'range30', 'vol30', 'stosc', 'MACD']\n",
            "Accuracy: 0.4274608806404658\n",
            "[[ 8728  9029 47931]\n",
            " [ 5170 14300 43850]\n",
            " [ 6404 13483 70945]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.43      0.13      0.20     65688\n",
            "           0       0.39      0.23      0.29     63320\n",
            "           1       0.44      0.78      0.56     90832\n",
            "\n",
            "    accuracy                           0.43    219840\n",
            "   macro avg       0.42      0.38      0.35    219840\n",
            "weighted avg       0.42      0.43      0.37    219840\n",
            "\n",
            "testing features: \n",
            "['avg7', 'tend7', 'avg30', 'sd30', 'vol30', 'stosc', 'MACD']\n",
            "Accuracy: 0.42690684133915574\n",
            "[[13099  8780 60231]\n",
            " [ 7357 13134 58659]\n",
            " [ 9792 12667 91081]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.43      0.16      0.23     82110\n",
            "           0       0.38      0.17      0.23     79150\n",
            "           1       0.43      0.80      0.56    113540\n",
            "\n",
            "    accuracy                           0.43    274800\n",
            "   macro avg       0.42      0.38      0.34    274800\n",
            "weighted avg       0.42      0.43      0.37    274800\n",
            "\n",
            "testing features: \n",
            "['avg7', 'tend7', 'avg30', 'sd30', 'range30', 'stosc', 'MACD']\n",
            "Accuracy: 0.42598859776807374\n",
            "[[ 14983  11586  71963]\n",
            " [  8729  17727  68524]\n",
            " [ 11390  17094 107764]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.43      0.15      0.22     98532\n",
            "           0       0.38      0.19      0.25     94980\n",
            "           1       0.43      0.79      0.56    136248\n",
            "\n",
            "    accuracy                           0.43    329760\n",
            "   macro avg       0.41      0.38      0.35    329760\n",
            "weighted avg       0.42      0.43      0.37    329760\n",
            "\n",
            "testing features: \n",
            "['avg7', 'tend7', 'avg30', 'sd30', 'range30', 'vol30', 'MACD']\n",
            "Accuracy: 0.42622426699937616\n",
            "[[ 16274  12875  85805]\n",
            " [  9666  19631  81513]\n",
            " [ 12673  18211 128072]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.42      0.14      0.21    114954\n",
            "           0       0.39      0.18      0.24    110810\n",
            "           1       0.43      0.81      0.56    158956\n",
            "\n",
            "    accuracy                           0.43    384720\n",
            "   macro avg       0.41      0.37      0.34    384720\n",
            "weighted avg       0.42      0.43      0.37    384720\n",
            "\n",
            "testing features: \n",
            "['avg7', 'tend7', 'avg30', 'sd30', 'range30', 'vol30', 'stosc']\n",
            "Accuracy: 0.4211972343522562\n",
            "[[ 15566  13618 102192]\n",
            " [  9930  20709  96001]\n",
            " [ 12940  19807 148917]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.40      0.12      0.18    131376\n",
            "           0       0.38      0.16      0.23    126640\n",
            "           1       0.43      0.82      0.56    181664\n",
            "\n",
            "    accuracy                           0.42    439680\n",
            "   macro avg       0.41      0.37      0.33    439680\n",
            "weighted avg       0.41      0.42      0.35    439680\n",
            "\n",
            "------------------ end -----------\n",
            "max accuracy:\n",
            "0.4314410480349345\n",
            "['tend7', 'avg30', 'sd30', 'range30', 'vol30', 'stosc', 'MACD']\n",
            "------------------ end -----------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## removed avg7, accuracy 0.4314410480349345"
      ],
      "metadata": {
        "id": "2DLeVDeY_VNv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = []\n",
        "y_train_7 = []\n",
        "y_train_30 = []\n",
        "x_test = []\n",
        "y_test_7 = []\n",
        "y_test_30 = []\n",
        "features = ['tend7', 'avg30', 'sd30', 'range30', 'vol30', 'stosc', 'MACD']\n",
        "count = len(features)\n",
        "max = 0\n",
        "max_features = []\n",
        "\n",
        "# for y in range(2):\n",
        "for x in range(len(features)): \n",
        "  features_curr = features[:x] + features[x+1:]\n",
        "  print(\"testing features: \")\n",
        "  print(features_curr)\n",
        "\n",
        "  for index, row in df.iterrows():\n",
        "    if (isinstance(row['date'], str)):\n",
        "      dt = datetime.strptime(row['date'], '%d/%m/%Y')\n",
        "      curr = []\n",
        "\n",
        "      for feature in features_curr:\n",
        "        curr.append(row[feature])\n",
        "\n",
        "      if (dt.year == 2008 or dt.year == 2012 or dt.year == 2017): # test data\n",
        "        x_test.append(curr)\n",
        "        # print(curr)\n",
        "        y_test_7.append(row['dirNext7'])\n",
        "      else: # train data\n",
        "        x_train.append(curr)\n",
        "        y_train_7.append(row['dirNext7'])\n",
        "\n",
        "  bst = XGBClassifier(n_estimators=5, max_depth=5, learning_rate=1, objective='binary:logistic', tree_method='hist')\n",
        "  bst.fit(np.array(x_train), np.array(y_train_7))\n",
        "  y_pred_7 = bst.predict(x_test)\n",
        "  accuracy = metrics.accuracy_score(y_test_7, y_pred_7)\n",
        "  print(\"Accuracy:\", accuracy)\n",
        "  print(confusion_matrix(y_test_7,y_pred_7))\n",
        "  print(classification_report(y_test_7,y_pred_7))\n",
        "\n",
        "  if (accuracy > max): \n",
        "    max = accuracy\n",
        "    max_features = features_curr\n",
        "\n",
        "print(\"------------------ end -----------\")\n",
        "print(\"max accuracy:\")\n",
        "print(max)\n",
        "print(max_features)\n",
        "max = 0\n",
        "features = max_features\n",
        "print(\"------------------ end -----------\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "02fad078-2574-400b-b0c1-0782fc371235",
        "id": "kT5mt9em_VNw"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "testing features: \n",
            "['avg30', 'sd30', 'range30', 'vol30', 'stosc', 'MACD']\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-73-9e72c6f41a1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_curr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m       \u001b[0mdt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrptime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'%d/%m/%Y'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36miterrows\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1261\u001b[0m         \u001b[0mklass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor_sliced\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1263\u001b[0;31m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1264\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    439\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msanitize_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m                 \u001b[0mmanager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mode.data_manager\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmanager\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"block\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m                     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSingleBlockManager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_config/config.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__func__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_config/config.py\u001b[0m in \u001b[0;36m_get_option\u001b[0;34m(pat, silent)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_get_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpat\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m     \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_single_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;31m# walk the nested dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_config/config.py\u001b[0m in \u001b[0;36m_get_single_key\u001b[0;34m(pat, silent)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0m_warn_if_deprecated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_translate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## removed sd30, accuracy 0.42970038816108685"
      ],
      "metadata": {
        "id": "WfpYdyxiAOEe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = []\n",
        "y_train_7 = []\n",
        "y_train_30 = []\n",
        "x_test = []\n",
        "y_test_7 = []\n",
        "y_test_30 = []\n",
        "features = ['tend7', 'avg30', 'range30', 'vol30', 'stosc', 'MACD']\n",
        "count = len(features)\n",
        "max = 0\n",
        "max_features = []\n",
        "\n",
        "# for y in range(2):\n",
        "for x in range(len(features)): \n",
        "  features_curr = features[:x] + features[x+1:]\n",
        "  print(\"testing features: \")\n",
        "  print(features_curr)\n",
        "\n",
        "  for index, row in df.iterrows():\n",
        "    if (isinstance(row['date'], str)):\n",
        "      dt = datetime.strptime(row['date'], '%d/%m/%Y')\n",
        "      curr = []\n",
        "\n",
        "      for feature in features_curr:\n",
        "        curr.append(row[feature])\n",
        "\n",
        "      if (dt.year == 2008 or dt.year == 2012 or dt.year == 2017): # test data\n",
        "        x_test.append(curr)\n",
        "        # print(curr)\n",
        "        y_test_7.append(row['dirNext7'])\n",
        "      else: # train data\n",
        "        x_train.append(curr)\n",
        "        y_train_7.append(row['dirNext7'])\n",
        "\n",
        "  bst = XGBClassifier(n_estimators=5, max_depth=5, learning_rate=1, objective='binary:logistic', tree_method='hist')\n",
        "  bst.fit(np.array(x_train), np.array(y_train_7))\n",
        "  y_pred_7 = bst.predict(x_test)\n",
        "  accuracy = metrics.accuracy_score(y_test_7, y_pred_7)\n",
        "  print(\"Accuracy:\", accuracy)\n",
        "  print(confusion_matrix(y_test_7,y_pred_7))\n",
        "  print(classification_report(y_test_7,y_pred_7))\n",
        "\n",
        "  if (accuracy > max): \n",
        "    max = accuracy\n",
        "    max_features = features_curr\n",
        "\n",
        "print(\"------------------ end -----------\")\n",
        "print(\"max accuracy:\")\n",
        "print(max)\n",
        "print(max_features)\n",
        "max = 0\n",
        "features = max_features\n",
        "print(\"------------------ end -----------\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bb3d411-51f8-4f4d-a54e-0c72128bbb9d",
        "id": "SPEaWi3mAOEf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "testing features: \n",
            "['avg30', 'range30', 'vol30', 'stosc', 'MACD']\n",
            "Accuracy: 0.4181222707423581\n",
            "[[ 1695  2026 12701]\n",
            " [ 1083  3310 11437]\n",
            " [ 1609  3124 17975]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.39      0.10      0.16     16422\n",
            "           0       0.39      0.21      0.27     15830\n",
            "           1       0.43      0.79      0.55     22708\n",
            "\n",
            "    accuracy                           0.42     54960\n",
            "   macro avg       0.40      0.37      0.33     54960\n",
            "weighted avg       0.40      0.42      0.36     54960\n",
            "\n",
            "testing features: \n",
            "['tend7', 'range30', 'vol30', 'stosc', 'MACD']\n",
            "Accuracy: 0.4265465793304221\n",
            "[[ 4326  4246 24272]\n",
            " [ 2428  6736 22496]\n",
            " [ 3282  6310 35824]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.43      0.13      0.20     32844\n",
            "           0       0.39      0.21      0.28     31660\n",
            "           1       0.43      0.79      0.56     45416\n",
            "\n",
            "    accuracy                           0.43    109920\n",
            "   macro avg       0.42      0.38      0.35    109920\n",
            "weighted avg       0.42      0.43      0.37    109920\n",
            "\n",
            "testing features: \n",
            "['tend7', 'avg30', 'vol30', 'stosc', 'MACD']\n",
            "Accuracy: 0.42479378942261037\n",
            "[[ 6798  5102 37366]\n",
            " [ 4011  7786 35693]\n",
            " [ 5111  7557 55456]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.43      0.14      0.21     49266\n",
            "           0       0.38      0.16      0.23     47490\n",
            "           1       0.43      0.81      0.56     68124\n",
            "\n",
            "    accuracy                           0.42    164880\n",
            "   macro avg       0.41      0.37      0.33    164880\n",
            "weighted avg       0.42      0.42      0.36    164880\n",
            "\n",
            "testing features: \n",
            "['tend7', 'avg30', 'range30', 'stosc', 'MACD']\n",
            "Accuracy: 0.4267148835516739\n",
            "[[ 9490  8065 48133]\n",
            " [ 5248 12737 45335]\n",
            " [ 6784 12466 71582]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.44      0.14      0.22     65688\n",
            "           0       0.38      0.20      0.26     63320\n",
            "           1       0.43      0.79      0.56     90832\n",
            "\n",
            "    accuracy                           0.43    219840\n",
            "   macro avg       0.42      0.38      0.35    219840\n",
            "weighted avg       0.42      0.43      0.37    219840\n",
            "\n",
            "testing features: \n",
            "['tend7', 'avg30', 'range30', 'vol30', 'MACD']\n",
            "Accuracy: 0.42531659388646287\n",
            "[[10850 10171 61089]\n",
            " [ 6613 15107 57430]\n",
            " [ 8178 14442 90920]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.42      0.13      0.20     82110\n",
            "           0       0.38      0.19      0.25     79150\n",
            "           1       0.43      0.80      0.56    113540\n",
            "\n",
            "    accuracy                           0.43    274800\n",
            "   macro avg       0.41      0.37      0.34    274800\n",
            "weighted avg       0.42      0.43      0.37    274800\n",
            "\n",
            "testing features: \n",
            "['tend7', 'avg30', 'range30', 'vol30', 'stosc']\n",
            "Accuracy: 0.4237111838913149\n",
            "[[ 11097  10081  77354]\n",
            " [  6504  15586  72890]\n",
            " [  8490  14718 113040]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.43      0.11      0.18     98532\n",
            "           0       0.39      0.16      0.23     94980\n",
            "           1       0.43      0.83      0.57    136248\n",
            "\n",
            "    accuracy                           0.42    329760\n",
            "   macro avg       0.41      0.37      0.32    329760\n",
            "weighted avg       0.42      0.42      0.35    329760\n",
            "\n",
            "------------------ end -----------\n",
            "max accuracy:\n",
            "0.4267148835516739\n",
            "['tend7', 'avg30', 'range30', 'stosc', 'MACD']\n",
            "------------------ end -----------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## removed vol30, accuracy 0.4267148835516739"
      ],
      "metadata": {
        "id": "n1d0heI0DmeI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = []\n",
        "y_train_7 = []\n",
        "y_train_30 = []\n",
        "x_test = []\n",
        "y_test_7 = []\n",
        "y_test_30 = []\n",
        "features = ['tend7', 'avg30', 'range30', 'stosc', 'MACD']\n",
        "count = len(features)\n",
        "max = 0\n",
        "max_features = []\n",
        "\n",
        "# for y in range(2):\n",
        "for x in range(len(features)): \n",
        "  features_curr = features[:x] + features[x+1:]\n",
        "  print(\"testing features: \")\n",
        "  print(features_curr)\n",
        "\n",
        "  for index, row in df.iterrows():\n",
        "    if (isinstance(row['date'], str)):\n",
        "      dt = datetime.strptime(row['date'], '%d/%m/%Y')\n",
        "      curr = []\n",
        "\n",
        "      for feature in features_curr:\n",
        "        curr.append(row[feature])\n",
        "\n",
        "      if (dt.year == 2008 or dt.year == 2012 or dt.year == 2017): # test data\n",
        "        x_test.append(curr)\n",
        "        # print(curr)\n",
        "        y_test_7.append(row['dirNext7'])\n",
        "      else: # train data\n",
        "        x_train.append(curr)\n",
        "        y_train_7.append(row['dirNext7'])\n",
        "\n",
        "  bst = XGBClassifier(n_estimators=5, max_depth=5, learning_rate=1, objective='binary:logistic', tree_method='hist')\n",
        "  bst.fit(np.array(x_train), np.array(y_train_7))\n",
        "  y_pred_7 = bst.predict(x_test)\n",
        "  accuracy = metrics.accuracy_score(y_test_7, y_pred_7)\n",
        "  print(\"Accuracy:\", accuracy)\n",
        "  print(confusion_matrix(y_test_7,y_pred_7))\n",
        "  print(classification_report(y_test_7,y_pred_7))\n",
        "\n",
        "  if (accuracy > max): \n",
        "    max = accuracy\n",
        "    max_features = features_curr\n",
        "\n",
        "print(\"------------------ end -----------\")\n",
        "print(\"max accuracy:\")\n",
        "print(max)\n",
        "print(max_features)\n",
        "max = 0\n",
        "features = max_features\n",
        "print(\"------------------ end -----------\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77a4e5f3-5e12-433b-c0a5-d8a8c7925673",
        "id": "ODgeP4RSDmeK"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "testing features: \n",
            "['avg30', 'range30', 'stosc', 'MACD']\n",
            "Accuracy: 0.4193231441048035\n",
            "[[ 1821  2217 12384]\n",
            " [ 1199  3708 10923]\n",
            " [ 1740  3451 17517]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.38      0.11      0.17     16422\n",
            "           0       0.40      0.23      0.29     15830\n",
            "           1       0.43      0.77      0.55     22708\n",
            "\n",
            "    accuracy                           0.42     54960\n",
            "   macro avg       0.40      0.37      0.34     54960\n",
            "weighted avg       0.41      0.42      0.36     54960\n",
            "\n",
            "testing features: \n",
            "['tend7', 'range30', 'stosc', 'MACD']\n",
            "Accuracy: 0.4287754730713246\n",
            "[[ 4488  4028 24328]\n",
            " [ 2584  6652 22424]\n",
            " [ 3532  5893 35991]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.42      0.14      0.21     32844\n",
            "           0       0.40      0.21      0.28     31660\n",
            "           1       0.43      0.79      0.56     45416\n",
            "\n",
            "    accuracy                           0.43    109920\n",
            "   macro avg       0.42      0.38      0.35    109920\n",
            "weighted avg       0.42      0.43      0.37    109920\n",
            "\n",
            "testing features: \n",
            "['tend7', 'avg30', 'stosc', 'MACD']\n",
            "Accuracy: 0.42745633187772925\n",
            "[[ 6700  6114 36452]\n",
            " [ 3665  8955 34870]\n",
            " [ 4717  8583 54824]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.44      0.14      0.21     49266\n",
            "           0       0.38      0.19      0.25     47490\n",
            "           1       0.43      0.80      0.56     68124\n",
            "\n",
            "    accuracy                           0.43    164880\n",
            "   macro avg       0.42      0.38      0.34    164880\n",
            "weighted avg       0.42      0.43      0.37    164880\n",
            "\n",
            "testing features: \n",
            "['tend7', 'avg30', 'range30', 'MACD']\n",
            "Accuracy: 0.4203193231441048\n",
            "[[ 5011  7152 53525]\n",
            " [ 2888 11189 49243]\n",
            " [ 3932 10697 76203]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.42      0.08      0.13     65688\n",
            "           0       0.39      0.18      0.24     63320\n",
            "           1       0.43      0.84      0.56     90832\n",
            "\n",
            "    accuracy                           0.42    219840\n",
            "   macro avg       0.41      0.36      0.31    219840\n",
            "weighted avg       0.41      0.42      0.34    219840\n",
            "\n",
            "testing features: \n",
            "['tend7', 'avg30', 'range30', 'stosc']\n",
            "Accuracy: 0.41533842794759823\n",
            "[[ 4229  8004 69877]\n",
            " [ 3121 13403 62626]\n",
            " [ 4117 12920 96503]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.37      0.05      0.09     82110\n",
            "           0       0.39      0.17      0.24     79150\n",
            "           1       0.42      0.85      0.56    113540\n",
            "\n",
            "    accuracy                           0.42    274800\n",
            "   macro avg       0.39      0.36      0.30    274800\n",
            "weighted avg       0.40      0.42      0.33    274800\n",
            "\n",
            "------------------ end -----------\n",
            "max accuracy:\n",
            "0.4287754730713246\n",
            "['tend7', 'range30', 'stosc', 'MACD']\n",
            "------------------ end -----------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## removed avg30, accuracy 0.4287754730713246\n",
        "## removed range30, accuracy 0.42457241630276565"
      ],
      "metadata": {
        "id": "Y7RwtoBaD5Go"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = []\n",
        "y_train_7 = []\n",
        "y_train_30 = []\n",
        "x_test = []\n",
        "y_test_7 = []\n",
        "y_test_30 = []\n",
        "features = ['tend7', 'range30', 'stosc', 'MACD']\n",
        "count = len(features)\n",
        "max = 0\n",
        "max_features = []\n",
        "\n",
        "# for y in range(2):\n",
        "for x in range(len(features)): \n",
        "  features_curr = features[:x] + features[x+1:]\n",
        "  print(\"testing features: \")\n",
        "  print(features_curr)\n",
        "\n",
        "  for index, row in df.iterrows():\n",
        "    if (isinstance(row['date'], str)):\n",
        "      dt = datetime.strptime(row['date'], '%d/%m/%Y')\n",
        "      curr = []\n",
        "\n",
        "      for feature in features_curr:\n",
        "        curr.append(row[feature])\n",
        "\n",
        "      if (dt.year == 2008 or dt.year == 2012 or dt.year == 2017): # test data\n",
        "        x_test.append(curr)\n",
        "        # print(curr)\n",
        "        y_test_7.append(row['dirNext7'])\n",
        "      else: # train data\n",
        "        x_train.append(curr)\n",
        "        y_train_7.append(row['dirNext7'])\n",
        "\n",
        "  bst = XGBClassifier(n_estimators=5, max_depth=5, learning_rate=1, objective='binary:logistic', tree_method='hist')\n",
        "  bst.fit(np.array(x_train), np.array(y_train_7))\n",
        "  y_pred_7 = bst.predict(x_test)\n",
        "  accuracy = metrics.accuracy_score(y_test_7, y_pred_7)\n",
        "  print(\"Accuracy:\", accuracy)\n",
        "  print(confusion_matrix(y_test_7,y_pred_7))\n",
        "  print(classification_report(y_test_7,y_pred_7))\n",
        "\n",
        "  if (accuracy > max): \n",
        "    max = accuracy\n",
        "    max_features = features_curr\n",
        "\n",
        "print(\"------------------ end -----------\")\n",
        "print(\"max accuracy:\")\n",
        "print(max)\n",
        "print(max_features)\n",
        "max = 0\n",
        "features = max_features\n",
        "print(\"------------------ end -----------\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd8a31fa-6452-4fff-9456-1264d5d3a3e3",
        "id": "d_IK5QzdD5Gp"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "testing features: \n",
            "['range30', 'stosc', 'MACD']\n",
            "Accuracy: 0.4211972343522562\n",
            "[[ 1292  2178 12952]\n",
            " [  711  3491 11628]\n",
            " [ 1085  3257 18366]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.42      0.08      0.13     16422\n",
            "           0       0.39      0.22      0.28     15830\n",
            "           1       0.43      0.81      0.56     22708\n",
            "\n",
            "    accuracy                           0.42     54960\n",
            "   macro avg       0.41      0.37      0.32     54960\n",
            "weighted avg       0.41      0.42      0.35     54960\n",
            "\n",
            "testing features: \n",
            "['tend7', 'stosc', 'MACD']\n",
            "Accuracy: 0.42457241630276565\n",
            "[[ 4096  4023 24725]\n",
            " [ 2171  5861 23628]\n",
            " [ 2762  5942 36712]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.45      0.12      0.20     32844\n",
            "           0       0.37      0.19      0.25     31660\n",
            "           1       0.43      0.81      0.56     45416\n",
            "\n",
            "    accuracy                           0.42    109920\n",
            "   macro avg       0.42      0.37      0.34    109920\n",
            "weighted avg       0.42      0.42      0.36    109920\n",
            "\n",
            "testing features: \n",
            "['tend7', 'range30', 'MACD']\n",
            "Accuracy: 0.41988112566715186\n",
            "[[ 3456  5093 40717]\n",
            " [ 1958  8081 37451]\n",
            " [ 2584  7847 57693]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.43      0.07      0.12     49266\n",
            "           0       0.38      0.17      0.24     47490\n",
            "           1       0.42      0.85      0.57     68124\n",
            "\n",
            "    accuracy                           0.42    164880\n",
            "   macro avg       0.41      0.36      0.31    164880\n",
            "weighted avg       0.42      0.42      0.34    164880\n",
            "\n",
            "testing features: \n",
            "['tend7', 'range30', 'stosc']\n",
            "Accuracy: 0.4179994541484716\n",
            "[[ 4021  5637 56030]\n",
            " [ 2312  8744 52264]\n",
            " [ 2937  8767 79128]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.43      0.06      0.11     65688\n",
            "           0       0.38      0.14      0.20     63320\n",
            "           1       0.42      0.87      0.57     90832\n",
            "\n",
            "    accuracy                           0.42    219840\n",
            "   macro avg       0.41      0.36      0.29    219840\n",
            "weighted avg       0.41      0.42      0.33    219840\n",
            "\n",
            "------------------ end -----------\n",
            "max accuracy:\n",
            "0.42457241630276565\n",
            "['tend7', 'stosc', 'MACD']\n",
            "------------------ end -----------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conclusion: \n",
        "Set of features yielding best accuracy is ['tend7', 'avg30', 'sd30', 'range30', 'vol30', 'stosc', 'MACD']"
      ],
      "metadata": {
        "id": "7ijP6WyjEbg6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing different models\n",
        "\n",
        "\n",
        "1.   n_estimators\n",
        "2.   max_depth\n",
        "3.   learning_rate\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "X0QMdrpFEpyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = []\n",
        "y_train_7 = []\n",
        "x_test = []\n",
        "y_test_7 = []\n",
        "features = ['tend7', 'avg30', 'sd30', 'range30', 'vol30', 'stosc', 'MACD']\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "  if (isinstance(row['date'], str)):\n",
        "    dt = datetime.strptime(row['date'], '%d/%m/%Y')\n",
        "    curr = []\n",
        "\n",
        "    for feature in features:\n",
        "      curr.append(row[feature])\n",
        "\n",
        "    if (dt.year == 2008 or dt.year == 2012 or dt.year == 2017): # test data\n",
        "      x_test.append(curr)\n",
        "      y_test_7.append(row['dirNext7'])\n",
        "    else: # train data\n",
        "      x_train.append(curr)\n",
        "      y_train_7.append(row['dirNext7'])"
      ],
      "metadata": {
        "id": "tIZzMvj6FAwv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "testing combinations of n_estimators and max_depth"
      ],
      "metadata": {
        "id": "zeB_i5UdpAtu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "  max_x = -1\n",
        "  max_y = -1\n",
        "  max_accuracy = 0\n",
        "  \n",
        "  for x in range(1, 10):\n",
        "    for y in range(1, 10): \n",
        "      print(\"testing\", 10*x, \" \", 10*y)\n",
        "      bst = XGBClassifier(n_estimators=10*x, max_depth=10*y, learning_rate=1, objective='binary:logistic', tree_method='hist')\n",
        "      bst.fit(np.array(x_train), np.array(y_train_7))\n",
        "      y_pred_7 = bst.predict(x_test)\n",
        "      accuracy = metrics.accuracy_score(y_test_7, y_pred_7)\n",
        "      print(\"Accuracy:\", accuracy)\n",
        "      print(confusion_matrix(y_test_7,y_pred_7))\n",
        "      print(classification_report(y_test_7,y_pred_7))\n",
        "\n",
        "      if (accuracy > max_accuracy):\n",
        "        max_x = 10*x\n",
        "        max_y = 10*y\n",
        "        max_accuracy = accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sEv0kebDM0Q-",
        "outputId": "149c065f-2199-4f6a-9314-792d28257a21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "testing 10   10\n",
            "Accuracy: 0.3941957787481805\n",
            "[[ 4337  3474  8611]\n",
            " [ 3465  4582  7783]\n",
            " [ 4729  5233 12746]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.35      0.26      0.30     16422\n",
            "           0       0.34      0.29      0.31     15830\n",
            "           1       0.44      0.56      0.49     22708\n",
            "\n",
            "    accuracy                           0.39     54960\n",
            "   macro avg       0.38      0.37      0.37     54960\n",
            "weighted avg       0.38      0.39      0.38     54960\n",
            "\n",
            "testing 10   20\n",
            "Accuracy: 0.37565502183406113\n",
            "[[ 4902  4105  7415]\n",
            " [ 4188  4877  6765]\n",
            " [ 5734  6107 10867]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.33      0.30      0.31     16422\n",
            "           0       0.32      0.31      0.32     15830\n",
            "           1       0.43      0.48      0.46     22708\n",
            "\n",
            "    accuracy                           0.38     54960\n",
            "   macro avg       0.36      0.36      0.36     54960\n",
            "weighted avg       0.37      0.38      0.37     54960\n",
            "\n",
            "testing 10   30\n",
            "Accuracy: 0.3791848617176128\n",
            "[[ 4916  3983  7523]\n",
            " [ 4267  4814  6749]\n",
            " [ 5830  5768 11110]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.33      0.30      0.31     16422\n",
            "           0       0.33      0.30      0.32     15830\n",
            "           1       0.44      0.49      0.46     22708\n",
            "\n",
            "    accuracy                           0.38     54960\n",
            "   macro avg       0.37      0.36      0.36     54960\n",
            "weighted avg       0.37      0.38      0.38     54960\n",
            "\n",
            "testing 10   40\n",
            "Accuracy: 0.3722707423580786\n",
            "[[ 4810  4035  7577]\n",
            " [ 4248  4822  6760]\n",
            " [ 5925  5955 10828]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.32      0.29      0.31     16422\n",
            "           0       0.33      0.30      0.31     15830\n",
            "           1       0.43      0.48      0.45     22708\n",
            "\n",
            "    accuracy                           0.37     54960\n",
            "   macro avg       0.36      0.36      0.36     54960\n",
            "weighted avg       0.37      0.37      0.37     54960\n",
            "\n",
            "testing 10   50\n",
            "Accuracy: 0.37656477438136826\n",
            "[[ 4951  3951  7520]\n",
            " [ 4365  4731  6734]\n",
            " [ 5867  5827 11014]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.33      0.30      0.31     16422\n",
            "           0       0.33      0.30      0.31     15830\n",
            "           1       0.44      0.49      0.46     22708\n",
            "\n",
            "    accuracy                           0.38     54960\n",
            "   macro avg       0.36      0.36      0.36     54960\n",
            "weighted avg       0.37      0.38      0.37     54960\n",
            "\n",
            "testing 10   60\n",
            "Accuracy: 0.37676491994177586\n",
            "[[ 4935  3954  7533]\n",
            " [ 4330  4722  6778]\n",
            " [ 5845  5813 11050]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.33      0.30      0.31     16422\n",
            "           0       0.33      0.30      0.31     15830\n",
            "           1       0.44      0.49      0.46     22708\n",
            "\n",
            "    accuracy                           0.38     54960\n",
            "   macro avg       0.36      0.36      0.36     54960\n",
            "weighted avg       0.37      0.38      0.37     54960\n",
            "\n",
            "testing 10   70\n",
            "Accuracy: 0.3763646288209607\n",
            "[[ 4938  4035  7449]\n",
            " [ 4337  4696  6797]\n",
            " [ 5838  5819 11051]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.33      0.30      0.31     16422\n",
            "           0       0.32      0.30      0.31     15830\n",
            "           1       0.44      0.49      0.46     22708\n",
            "\n",
            "    accuracy                           0.38     54960\n",
            "   macro avg       0.36      0.36      0.36     54960\n",
            "weighted avg       0.37      0.38      0.37     54960\n",
            "\n",
            "testing 10   80\n",
            "Accuracy: 0.37412663755458514\n",
            "[[ 4935  3989  7498]\n",
            " [ 4402  4648  6780]\n",
            " [ 5877  5852 10979]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.32      0.30      0.31     16422\n",
            "           0       0.32      0.29      0.31     15830\n",
            "           1       0.43      0.48      0.46     22708\n",
            "\n",
            "    accuracy                           0.37     54960\n",
            "   macro avg       0.36      0.36      0.36     54960\n",
            "weighted avg       0.37      0.37      0.37     54960\n",
            "\n",
            "testing 10   90\n",
            "Accuracy: 0.37438136826783114\n",
            "[[ 4913  3996  7513]\n",
            " [ 4357  4719  6754]\n",
            " [ 5940  5824 10944]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.32      0.30      0.31     16422\n",
            "           0       0.32      0.30      0.31     15830\n",
            "           1       0.43      0.48      0.46     22708\n",
            "\n",
            "    accuracy                           0.37     54960\n",
            "   macro avg       0.36      0.36      0.36     54960\n",
            "weighted avg       0.37      0.37      0.37     54960\n",
            "\n",
            "testing 20   10\n",
            "Accuracy: 0.3848071324599709\n",
            "[[ 4464  3709  8249]\n",
            " [ 3735  4809  7286]\n",
            " [ 5258  5574 11876]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.33      0.27      0.30     16422\n",
            "           0       0.34      0.30      0.32     15830\n",
            "           1       0.43      0.52      0.47     22708\n",
            "\n",
            "    accuracy                           0.38     54960\n",
            "   macro avg       0.37      0.37      0.36     54960\n",
            "weighted avg       0.38      0.38      0.38     54960\n",
            "\n",
            "testing 20   20\n",
            "Accuracy: 0.376655749636099\n",
            "[[ 4882  4051  7489]\n",
            " [ 4167  4905  6758]\n",
            " [ 5676  6118 10914]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.33      0.30      0.31     16422\n",
            "           0       0.33      0.31      0.32     15830\n",
            "           1       0.43      0.48      0.46     22708\n",
            "\n",
            "    accuracy                           0.38     54960\n",
            "   macro avg       0.36      0.36      0.36     54960\n",
            "weighted avg       0.37      0.38      0.37     54960\n",
            "\n",
            "testing 20   30\n",
            "Accuracy: 0.3776928675400291\n",
            "[[ 4917  4003  7502]\n",
            " [ 4258  4778  6794]\n",
            " [ 5883  5762 11063]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.33      0.30      0.31     16422\n",
            "           0       0.33      0.30      0.31     15830\n",
            "           1       0.44      0.49      0.46     22708\n",
            "\n",
            "    accuracy                           0.38     54960\n",
            "   macro avg       0.36      0.36      0.36     54960\n",
            "weighted avg       0.37      0.38      0.37     54960\n",
            "\n",
            "testing 20   40\n",
            "Accuracy: 0.37383551673944687\n",
            "[[ 4793  3987  7642]\n",
            " [ 4227  4858  6745]\n",
            " [ 5803  6010 10895]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.32      0.29      0.31     16422\n",
            "           0       0.33      0.31      0.32     15830\n",
            "           1       0.43      0.48      0.45     22708\n",
            "\n",
            "    accuracy                           0.37     54960\n",
            "   macro avg       0.36      0.36      0.36     54960\n",
            "weighted avg       0.37      0.37      0.37     54960\n",
            "\n",
            "testing 20   50\n",
            "Accuracy: 0.376528384279476\n",
            "[[ 4876  3954  7592]\n",
            " [ 4300  4787  6743]\n",
            " [ 5825  5852 11031]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.33      0.30      0.31     16422\n",
            "           0       0.33      0.30      0.31     15830\n",
            "           1       0.43      0.49      0.46     22708\n",
            "\n",
            "    accuracy                           0.38     54960\n",
            "   macro avg       0.36      0.36      0.36     54960\n",
            "weighted avg       0.37      0.38      0.37     54960\n",
            "\n",
            "testing 20   60\n",
            "Accuracy: 0.37672852983988353\n",
            "[[ 4871  3978  7573]\n",
            " [ 4355  4749  6726]\n",
            " [ 5851  5772 11085]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.32      0.30      0.31     16422\n",
            "           0       0.33      0.30      0.31     15830\n",
            "           1       0.44      0.49      0.46     22708\n",
            "\n",
            "    accuracy                           0.38     54960\n",
            "   macro avg       0.36      0.36      0.36     54960\n",
            "weighted avg       0.37      0.38      0.37     54960\n",
            "\n",
            "testing 20   70\n",
            "Accuracy: 0.3769286754002911\n",
            "[[ 4924  4015  7483]\n",
            " [ 4343  4727  6760]\n",
            " [ 5851  5792 11065]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.33      0.30      0.31     16422\n",
            "           0       0.33      0.30      0.31     15830\n",
            "           1       0.44      0.49      0.46     22708\n",
            "\n",
            "    accuracy                           0.38     54960\n",
            "   macro avg       0.36      0.36      0.36     54960\n",
            "weighted avg       0.37      0.38      0.37     54960\n",
            "\n",
            "testing 20   80\n",
            "Accuracy: 0.3754730713245997\n",
            "[[ 4884  3927  7611]\n",
            " [ 4313  4685  6832]\n",
            " [ 5861  5780 11067]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.32      0.30      0.31     16422\n",
            "           0       0.33      0.30      0.31     15830\n",
            "           1       0.43      0.49      0.46     22708\n",
            "\n",
            "    accuracy                           0.38     54960\n",
            "   macro avg       0.36      0.36      0.36     54960\n",
            "weighted avg       0.37      0.38      0.37     54960\n",
            "\n",
            "testing 20   90\n",
            "Accuracy: 0.3774381368267831\n",
            "[[ 4988  3929  7505]\n",
            " [ 4395  4726  6709]\n",
            " [ 5891  5787 11030]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.33      0.30      0.31     16422\n",
            "           0       0.33      0.30      0.31     15830\n",
            "           1       0.44      0.49      0.46     22708\n",
            "\n",
            "    accuracy                           0.38     54960\n",
            "   macro avg       0.36      0.36      0.36     54960\n",
            "weighted avg       0.37      0.38      0.37     54960\n",
            "\n",
            "testing 30   10\n",
            "Accuracy: 0.3781295487627365\n",
            "[[ 4478  3785  8159]\n",
            " [ 3899  4794  7137]\n",
            " [ 5460  5738 11510]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.32      0.27      0.30     16422\n",
            "           0       0.33      0.30      0.32     15830\n",
            "           1       0.43      0.51      0.46     22708\n",
            "\n",
            "    accuracy                           0.38     54960\n",
            "   macro avg       0.36      0.36      0.36     54960\n",
            "weighted avg       0.37      0.38      0.37     54960\n",
            "\n",
            "testing 30   20\n",
            "Accuracy: 0.37536390101892286\n",
            "[[ 4846  3987  7589]\n",
            " [ 4205  4851  6774]\n",
            " [ 5667  6108 10933]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.33      0.30      0.31     16422\n",
            "           0       0.32      0.31      0.32     15830\n",
            "           1       0.43      0.48      0.46     22708\n",
            "\n",
            "    accuracy                           0.38     54960\n",
            "   macro avg       0.36      0.36      0.36     54960\n",
            "weighted avg       0.37      0.38      0.37     54960\n",
            "\n",
            "testing 30   30\n",
            "Accuracy: 0.375891557496361\n",
            "[[ 4898  3939  7585]\n",
            " [ 4291  4754  6785]\n",
            " [ 5904  5797 11007]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.32      0.30      0.31     16422\n",
            "           0       0.33      0.30      0.31     15830\n",
            "           1       0.43      0.48      0.46     22708\n",
            "\n",
            "    accuracy                           0.38     54960\n",
            "   macro avg       0.36      0.36      0.36     54960\n",
            "weighted avg       0.37      0.38      0.37     54960\n",
            "\n",
            "testing 30   40\n",
            "Accuracy: 0.3746906841339156\n",
            "[[ 4821  3970  7631]\n",
            " [ 4275  4835  6720]\n",
            " [ 5788  5983 10937]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.32      0.29      0.31     16422\n",
            "           0       0.33      0.31      0.32     15830\n",
            "           1       0.43      0.48      0.46     22708\n",
            "\n",
            "    accuracy                           0.37     54960\n",
            "   macro avg       0.36      0.36      0.36     54960\n",
            "weighted avg       0.37      0.37      0.37     54960\n",
            "\n",
            "testing 30   50\n",
            "Accuracy: 0.376528384279476\n",
            "[[ 4873  3944  7605]\n",
            " [ 4311  4747  6772]\n",
            " [ 5833  5801 11074]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.32      0.30      0.31     16422\n",
            "           0       0.33      0.30      0.31     15830\n",
            "           1       0.44      0.49      0.46     22708\n",
            "\n",
            "    accuracy                           0.38     54960\n",
            "   macro avg       0.36      0.36      0.36     54960\n",
            "weighted avg       0.37      0.38      0.37     54960\n",
            "\n",
            "testing 30   60\n",
            "Accuracy: 0.3783660844250364\n",
            "[[ 4939  3959  7524]\n",
            " [ 4319  4777  6734]\n",
            " [ 5854  5775 11079]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.33      0.30      0.31     16422\n",
            "           0       0.33      0.30      0.31     15830\n",
            "           1       0.44      0.49      0.46     22708\n",
            "\n",
            "    accuracy                           0.38     54960\n",
            "   macro avg       0.36      0.36      0.36     54960\n",
            "weighted avg       0.37      0.38      0.37     54960\n",
            "\n",
            "testing 30   70\n",
            "Accuracy: 0.37552765647743813\n",
            "[[ 4839  4036  7547]\n",
            " [ 4344  4729  6757]\n",
            " [ 5841  5796 11071]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.32      0.29      0.31     16422\n",
            "           0       0.32      0.30      0.31     15830\n",
            "           1       0.44      0.49      0.46     22708\n",
            "\n",
            "    accuracy                           0.38     54960\n",
            "   macro avg       0.36      0.36      0.36     54960\n",
            "weighted avg       0.37      0.38      0.37     54960\n",
            "\n",
            "testing 30   80\n",
            "Accuracy: 0.3753093158660844\n",
            "[[ 4875  3923  7624]\n",
            " [ 4275  4717  6838]\n",
            " [ 5878  5795 11035]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.32      0.30      0.31     16422\n",
            "           0       0.33      0.30      0.31     15830\n",
            "           1       0.43      0.49      0.46     22708\n",
            "\n",
            "    accuracy                           0.38     54960\n",
            "   macro avg       0.36      0.36      0.36     54960\n",
            "weighted avg       0.37      0.38      0.37     54960\n",
            "\n",
            "testing 30   90\n",
            "Accuracy: 0.3779839883551674\n",
            "[[ 4971  3910  7541]\n",
            " [ 4373  4713  6744]\n",
            " [ 5797  5821 11090]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.33      0.30      0.31     16422\n",
            "           0       0.33      0.30      0.31     15830\n",
            "           1       0.44      0.49      0.46     22708\n",
            "\n",
            "    accuracy                           0.38     54960\n",
            "   macro avg       0.36      0.36      0.36     54960\n",
            "weighted avg       0.37      0.38      0.37     54960\n",
            "\n",
            "testing 40   10\n",
            "Accuracy: 0.374108442503639\n",
            "[[ 4439  3876  8107]\n",
            " [ 3913  4782  7135]\n",
            " [ 5506  5862 11340]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.32      0.27      0.29     16422\n",
            "           0       0.33      0.30      0.32     15830\n",
            "           1       0.43      0.50      0.46     22708\n",
            "\n",
            "    accuracy                           0.37     54960\n",
            "   macro avg       0.36      0.36      0.36     54960\n",
            "weighted avg       0.37      0.37      0.37     54960\n",
            "\n",
            "testing 40   20\n",
            "Accuracy: 0.377165211062591\n",
            "[[ 4894  3926  7602]\n",
            " [ 4242  4818  6770]\n",
            " [ 5651  6040 11017]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.33      0.30      0.31     16422\n",
            "           0       0.33      0.30      0.31     15830\n",
            "           1       0.43      0.49      0.46     22708\n",
            "\n",
            "    accuracy                           0.38     54960\n",
            "   macro avg       0.36      0.36      0.36     54960\n",
            "weighted avg       0.37      0.38      0.37     54960\n",
            "\n",
            "testing 40   30\n",
            "Accuracy: 0.37720160116448326\n",
            "[[ 4876  3915  7631]\n",
            " [ 4257  4766  6807]\n",
            " [ 5855  5764 11089]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.33      0.30      0.31     16422\n",
            "           0       0.33      0.30      0.31     15830\n",
            "           1       0.43      0.49      0.46     22708\n",
            "\n",
            "    accuracy                           0.38     54960\n",
            "   macro avg       0.36      0.36      0.36     54960\n",
            "weighted avg       0.37      0.38      0.37     54960\n",
            "\n",
            "testing 40   40\n",
            "Accuracy: 0.3745269286754003\n",
            "[[ 4812  3968  7642]\n",
            " [ 4231  4849  6750]\n",
            " [ 5769  6016 10923]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.32      0.29      0.31     16422\n",
            "           0       0.33      0.31      0.32     15830\n",
            "           1       0.43      0.48      0.45     22708\n",
            "\n",
            "    accuracy                           0.37     54960\n",
            "   macro avg       0.36      0.36      0.36     54960\n",
            "weighted avg       0.37      0.37      0.37     54960\n",
            "\n",
            "testing 40   50\n",
            "Accuracy: 0.3764556040756914\n",
            "[[ 4878  3954  7590]\n",
            " [ 4323  4729  6778]\n",
            " [ 5806  5819 11083]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.33      0.30      0.31     16422\n",
            "           0       0.33      0.30      0.31     15830\n",
            "           1       0.44      0.49      0.46     22708\n",
            "\n",
            "    accuracy                           0.38     54960\n",
            "   macro avg       0.36      0.36      0.36     54960\n",
            "weighted avg       0.37      0.38      0.37     54960\n",
            "\n",
            "testing 40   60\n",
            "Accuracy: 0.37776564774381366\n",
            "[[ 4901  3994  7527]\n",
            " [ 4341  4809  6680]\n",
            " [ 5874  5782 11052]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.32      0.30      0.31     16422\n",
            "           0       0.33      0.30      0.32     15830\n",
            "           1       0.44      0.49      0.46     22708\n",
            "\n",
            "    accuracy                           0.38     54960\n",
            "   macro avg       0.36      0.36      0.36     54960\n",
            "weighted avg       0.37      0.38      0.37     54960\n",
            "\n",
            "testing 40   70\n",
            "Accuracy: 0.37527292576419213\n",
            "[[ 4826  4076  7520]\n",
            " [ 4353  4722  6755]\n",
            " [ 5849  5782 11077]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.32      0.29      0.31     16422\n",
            "           0       0.32      0.30      0.31     15830\n",
            "           1       0.44      0.49      0.46     22708\n",
            "\n",
            "    accuracy                           0.38     54960\n",
            "   macro avg       0.36      0.36      0.36     54960\n",
            "weighted avg       0.37      0.38      0.37     54960\n",
            "\n",
            "testing 40   80\n",
            "Accuracy: 0.37534570596797673\n",
            "[[ 4884  3896  7642]\n",
            " [ 4311  4719  6800]\n",
            " [ 5858  5824 11026]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.32      0.30      0.31     16422\n",
            "           0       0.33      0.30      0.31     15830\n",
            "           1       0.43      0.49      0.46     22708\n",
            "\n",
            "    accuracy                           0.38     54960\n",
            "   macro avg       0.36      0.36      0.36     54960\n",
            "weighted avg       0.37      0.38      0.37     54960\n",
            "\n",
            "testing 40   90\n",
            "Accuracy: 0.37829330422125185\n",
            "[[ 4955  3918  7549]\n",
            " [ 4386  4728  6716]\n",
            " [ 5815  5785 11108]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.33      0.30      0.31     16422\n",
            "           0       0.33      0.30      0.31     15830\n",
            "           1       0.44      0.49      0.46     22708\n",
            "\n",
            "    accuracy                           0.38     54960\n",
            "   macro avg       0.36      0.36      0.36     54960\n",
            "weighted avg       0.37      0.38      0.37     54960\n",
            "\n",
            "testing 50   10\n",
            "Accuracy: 0.3757278020378457\n",
            "[[ 4552  3922  7948]\n",
            " [ 3960  4932  6938]\n",
            " [ 5620  5922 11166]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.32      0.28      0.30     16422\n",
            "           0       0.33      0.31      0.32     15830\n",
            "           1       0.43      0.49      0.46     22708\n",
            "\n",
            "    accuracy                           0.38     54960\n",
            "   macro avg       0.36      0.36      0.36     54960\n",
            "weighted avg       0.37      0.38      0.37     54960\n",
            "\n",
            "testing 50   20\n",
            "Accuracy: 0.37596433770014553\n",
            "[[ 4874  3960  7588]\n",
            " [ 4244  4803  6783]\n",
            " [ 5702  6020 10986]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.33      0.30      0.31     16422\n",
            "           0       0.32      0.30      0.31     15830\n",
            "           1       0.43      0.48      0.46     22708\n",
            "\n",
            "    accuracy                           0.38     54960\n",
            "   macro avg       0.36      0.36      0.36     54960\n",
            "weighted avg       0.37      0.38      0.37     54960\n",
            "\n",
            "testing 50   30\n",
            "Accuracy: 0.37676491994177586\n",
            "[[ 4892  3973  7557]\n",
            " [ 4273  4800  6757]\n",
            " [ 5891  5802 11015]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.32      0.30      0.31     16422\n",
            "           0       0.33      0.30      0.32     15830\n",
            "           1       0.43      0.49      0.46     22708\n",
            "\n",
            "    accuracy                           0.38     54960\n",
            "   macro avg       0.36      0.36      0.36     54960\n",
            "weighted avg       0.37      0.38      0.37     54960\n",
            "\n",
            "testing 50   40\n",
            "Accuracy: 0.37465429403202327\n",
            "[[ 4813  3963  7646]\n",
            " [ 4247  4843  6740]\n",
            " [ 5775  5998 10935]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.32      0.29      0.31     16422\n",
            "           0       0.33      0.31      0.32     15830\n",
            "           1       0.43      0.48      0.46     22708\n",
            "\n",
            "    accuracy                           0.37     54960\n",
            "   macro avg       0.36      0.36      0.36     54960\n",
            "weighted avg       0.37      0.37      0.37     54960\n",
            "\n",
            "testing 50   50\n",
            "Accuracy: 0.37627365356623\n",
            "[[ 4866  3974  7582]\n",
            " [ 4315  4715  6800]\n",
            " [ 5835  5774 11099]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.32      0.30      0.31     16422\n",
            "           0       0.33      0.30      0.31     15830\n",
            "           1       0.44      0.49      0.46     22708\n",
            "\n",
            "    accuracy                           0.38     54960\n",
            "   macro avg       0.36      0.36      0.36     54960\n",
            "weighted avg       0.37      0.38      0.37     54960\n",
            "\n",
            "testing 50   60\n",
            "Accuracy: 0.37778384279475985\n",
            "[[ 4936  3979  7507]\n",
            " [ 4348  4795  6687]\n",
            " [ 5850  5826 11032]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.33      0.30      0.31     16422\n",
            "           0       0.33      0.30      0.32     15830\n",
            "           1       0.44      0.49      0.46     22708\n",
            "\n",
            "    accuracy                           0.38     54960\n",
            "   macro avg       0.36      0.36      0.36     54960\n",
            "weighted avg       0.37      0.38      0.37     54960\n",
            "\n",
            "testing 50   70\n",
            "Accuracy: 0.3763282387190684\n",
            "[[ 4842  4039  7541]\n",
            " [ 4353  4731  6746]\n",
            " [ 5800  5798 11110]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.32      0.29      0.31     16422\n",
            "           0       0.32      0.30      0.31     15830\n",
            "           1       0.44      0.49      0.46     22708\n",
            "\n",
            "    accuracy                           0.38     54960\n",
            "   macro avg       0.36      0.36      0.36     54960\n",
            "weighted avg       0.37      0.38      0.37     54960\n",
            "\n",
            "testing 50   80\n",
            "Accuracy: 0.37570960698689954\n",
            "[[ 4896  3905  7621]\n",
            " [ 4342  4702  6786]\n",
            " [ 5841  5816 11051]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.32      0.30      0.31     16422\n",
            "           0       0.33      0.30      0.31     15830\n",
            "           1       0.43      0.49      0.46     22708\n",
            "\n",
            "    accuracy                           0.38     54960\n",
            "   macro avg       0.36      0.36      0.36     54960\n",
            "weighted avg       0.37      0.38      0.37     54960\n",
            "\n",
            "testing 50   90\n",
            "Accuracy: 0.37647379912663753\n",
            "[[ 4894  3940  7588]\n",
            " [ 4428  4715  6687]\n",
            " [ 5826  5800 11082]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.32      0.30      0.31     16422\n",
            "           0       0.33      0.30      0.31     15830\n",
            "           1       0.44      0.49      0.46     22708\n",
            "\n",
            "    accuracy                           0.38     54960\n",
            "   macro avg       0.36      0.36      0.36     54960\n",
            "weighted avg       0.37      0.38      0.37     54960\n",
            "\n",
            "testing 60   10\n",
            "Accuracy: 0.37247088791848615\n",
            "[[ 4610  3976  7836]\n",
            " [ 4013  4822  6995]\n",
            " [ 5759  5910 11039]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.32      0.28      0.30     16422\n",
            "           0       0.33      0.30      0.32     15830\n",
            "           1       0.43      0.49      0.45     22708\n",
            "\n",
            "    accuracy                           0.37     54960\n",
            "   macro avg       0.36      0.36      0.36     54960\n",
            "weighted avg       0.37      0.37      0.37     54960\n",
            "\n",
            "testing 60   20\n",
            "Accuracy: 0.37596433770014553\n",
            "[[ 4888  3998  7536]\n",
            " [ 4234  4831  6765]\n",
            " [ 5746  6018 10944]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.33      0.30      0.31     16422\n",
            "           0       0.33      0.31      0.31     15830\n",
            "           1       0.43      0.48      0.46     22708\n",
            "\n",
            "    accuracy                           0.38     54960\n",
            "   macro avg       0.36      0.36      0.36     54960\n",
            "weighted avg       0.37      0.38      0.37     54960\n",
            "\n",
            "testing 60   30\n",
            "Accuracy: 0.37751091703056766\n",
            "[[ 4908  3964  7550]\n",
            " [ 4295  4810  6725]\n",
            " [ 5870  5808 11030]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.33      0.30      0.31     16422\n",
            "           0       0.33      0.30      0.32     15830\n",
            "           1       0.44      0.49      0.46     22708\n",
            "\n",
            "    accuracy                           0.38     54960\n",
            "   macro avg       0.36      0.36      0.36     54960\n",
            "weighted avg       0.37      0.38      0.37     54960\n",
            "\n",
            "testing 60   40\n",
            "Accuracy: 0.37627365356623\n",
            "[[ 4829  3966  7627]\n",
            " [ 4235  4880  6715]\n",
            " [ 5769  5968 10971]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.33      0.29      0.31     16422\n",
            "           0       0.33      0.31      0.32     15830\n",
            "           1       0.43      0.48      0.46     22708\n",
            "\n",
            "    accuracy                           0.38     54960\n",
            "   macro avg       0.36      0.36      0.36     54960\n",
            "weighted avg       0.37      0.38      0.37     54960\n",
            "\n",
            "testing 60   50\n",
            "Accuracy: 0.375509461426492\n",
            "[[ 4887  3965  7570]\n",
            " [ 4357  4684  6789]\n",
            " [ 5836  5805 11067]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.32      0.30      0.31     16422\n",
            "           0       0.32      0.30      0.31     15830\n",
            "           1       0.44      0.49      0.46     22708\n",
            "\n",
            "    accuracy                           0.38     54960\n",
            "   macro avg       0.36      0.36      0.36     54960\n",
            "weighted avg       0.37      0.38      0.37     54960\n",
            "\n",
            "testing 60   60\n",
            "Accuracy: 0.3759825327510917\n",
            "[[ 4913  3979  7530]\n",
            " [ 4379  4776  6675]\n",
            " [ 5877  5856 10975]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.32      0.30      0.31     16422\n",
            "           0       0.33      0.30      0.31     15830\n",
            "           1       0.44      0.48      0.46     22708\n",
            "\n",
            "    accuracy                           0.38     54960\n",
            "   macro avg       0.36      0.36      0.36     54960\n",
            "weighted avg       0.37      0.38      0.37     54960\n",
            "\n",
            "testing 60   70\n",
            "Accuracy: 0.3754730713245997\n",
            "[[ 4822  4054  7546]\n",
            " [ 4355  4723  6752]\n",
            " [ 5806  5811 11091]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.32      0.29      0.31     16422\n",
            "           0       0.32      0.30      0.31     15830\n",
            "           1       0.44      0.49      0.46     22708\n",
            "\n",
            "    accuracy                           0.38     54960\n",
            "   macro avg       0.36      0.36      0.36     54960\n",
            "weighted avg       0.37      0.38      0.37     54960\n",
            "\n",
            "testing 60   80\n",
            "Accuracy: 0.3760735080058224\n",
            "[[ 4940  3897  7585]\n",
            " [ 4368  4685  6777]\n",
            " [ 5850  5814 11044]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.33      0.30      0.31     16422\n",
            "           0       0.33      0.30      0.31     15830\n",
            "           1       0.43      0.49      0.46     22708\n",
            "\n",
            "    accuracy                           0.38     54960\n",
            "   macro avg       0.36      0.36      0.36     54960\n",
            "weighted avg       0.37      0.38      0.37     54960\n",
            "\n",
            "testing 60   90\n",
            "Accuracy: 0.37605531295487626\n",
            "[[ 4883  3913  7626]\n",
            " [ 4405  4717  6708]\n",
            " [ 5823  5817 11068]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.32      0.30      0.31     16422\n",
            "           0       0.33      0.30      0.31     15830\n",
            "           1       0.44      0.49      0.46     22708\n",
            "\n",
            "    accuracy                           0.38     54960\n",
            "   macro avg       0.36      0.36      0.36     54960\n",
            "weighted avg       0.37      0.38      0.37     54960\n",
            "\n",
            "testing 70   10\n",
            "Accuracy: 0.3729075691411936\n",
            "[[ 4624  3909  7889]\n",
            " [ 4097  4794  6939]\n",
            " [ 5671  5960 11077]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.32      0.28      0.30     16422\n",
            "           0       0.33      0.30      0.31     15830\n",
            "           1       0.43      0.49      0.46     22708\n",
            "\n",
            "    accuracy                           0.37     54960\n",
            "   macro avg       0.36      0.36      0.36     54960\n",
            "weighted avg       0.37      0.37      0.37     54960\n",
            "\n",
            "testing 70   20\n",
            "Accuracy: 0.37536390101892286\n",
            "[[ 4881  3969  7572]\n",
            " [ 4228  4820  6782]\n",
            " [ 5745  6034 10929]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.33      0.30      0.31     16422\n",
            "           0       0.33      0.30      0.31     15830\n",
            "           1       0.43      0.48      0.46     22708\n",
            "\n",
            "    accuracy                           0.38     54960\n",
            "   macro avg       0.36      0.36      0.36     54960\n",
            "weighted avg       0.37      0.38      0.37     54960\n",
            "\n",
            "testing 70   30\n",
            "Accuracy: 0.37754730713246\n",
            "[[ 4928  3963  7531]\n",
            " [ 4321  4792  6717]\n",
            " [ 5906  5772 11030]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.33      0.30      0.31     16422\n",
            "           0       0.33      0.30      0.32     15830\n",
            "           1       0.44      0.49      0.46     22708\n",
            "\n",
            "    accuracy                           0.38     54960\n",
            "   macro avg       0.36      0.36      0.36     54960\n",
            "weighted avg       0.37      0.38      0.37     54960\n",
            "\n",
            "testing 70   40\n",
            "Accuracy: 0.37565502183406113\n",
            "[[ 4816  3983  7623]\n",
            " [ 4223  4886  6721]\n",
            " [ 5780  5984 10944]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.32      0.29      0.31     16422\n",
            "           0       0.33      0.31      0.32     15830\n",
            "           1       0.43      0.48      0.46     22708\n",
            "\n",
            "    accuracy                           0.38     54960\n",
            "   macro avg       0.36      0.36      0.36     54960\n",
            "weighted avg       0.37      0.38      0.37     54960\n",
            "\n",
            "testing 70   50\n",
            "Accuracy: 0.3753275109170306\n",
            "[[ 4868  3988  7566]\n",
            " [ 4343  4701  6786]\n",
            " [ 5813  5836 11059]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.32      0.30      0.31     16422\n",
            "           0       0.32      0.30      0.31     15830\n",
            "           1       0.44      0.49      0.46     22708\n",
            "\n",
            "    accuracy                           0.38     54960\n",
            "   macro avg       0.36      0.36      0.36     54960\n",
            "weighted avg       0.37      0.38      0.37     54960\n",
            "\n",
            "testing 70   60\n",
            "Accuracy: 0.37621906841339153\n",
            "[[ 4925  3981  7516]\n",
            " [ 4383  4788  6659]\n",
            " [ 5912  5832 10964]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.32      0.30      0.31     16422\n",
            "           0       0.33      0.30      0.31     15830\n",
            "           1       0.44      0.48      0.46     22708\n",
            "\n",
            "    accuracy                           0.38     54960\n",
            "   macro avg       0.36      0.36      0.36     54960\n",
            "weighted avg       0.37      0.38      0.37     54960\n",
            "\n",
            "testing 70   70\n",
            "Accuracy: 0.37516375545851527\n",
            "[[ 4799  4065  7558]\n",
            " [ 4343  4739  6748]\n",
            " [ 5819  5808 11081]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.32      0.29      0.31     16422\n",
            "           0       0.32      0.30      0.31     15830\n",
            "           1       0.44      0.49      0.46     22708\n",
            "\n",
            "    accuracy                           0.38     54960\n",
            "   macro avg       0.36      0.36      0.36     54960\n",
            "weighted avg       0.37      0.38      0.37     54960\n",
            "\n",
            "testing 70   80\n",
            "Accuracy: 0.37489082969432314\n",
            "[[ 4924  3870  7628]\n",
            " [ 4363  4683  6784]\n",
            " [ 5899  5812 10997]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.32      0.30      0.31     16422\n",
            "           0       0.33      0.30      0.31     15830\n",
            "           1       0.43      0.48      0.46     22708\n",
            "\n",
            "    accuracy                           0.37     54960\n",
            "   macro avg       0.36      0.36      0.36     54960\n",
            "weighted avg       0.37      0.37      0.37     54960\n",
            "\n",
            "testing 70   90\n",
            "Accuracy: 0.3756004366812227\n",
            "[[ 4898  3943  7581]\n",
            " [ 4399  4697  6734]\n",
            " [ 5851  5809 11048]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.32      0.30      0.31     16422\n",
            "           0       0.33      0.30      0.31     15830\n",
            "           1       0.44      0.49      0.46     22708\n",
            "\n",
            "    accuracy                           0.38     54960\n",
            "   macro avg       0.36      0.36      0.36     54960\n",
            "weighted avg       0.37      0.38      0.37     54960\n",
            "\n",
            "testing 80   10\n",
            "Accuracy: 0.371561135371179\n",
            "[[ 4695  3934  7793]\n",
            " [ 4195  4768  6867]\n",
            " [ 5807  5943 10958]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.32      0.29      0.30     16422\n",
            "           0       0.33      0.30      0.31     15830\n",
            "           1       0.43      0.48      0.45     22708\n",
            "\n",
            "    accuracy                           0.37     54960\n",
            "   macro avg       0.36      0.36      0.36     54960\n",
            "weighted avg       0.37      0.37      0.37     54960\n",
            "\n",
            "testing 80   20\n",
            "Accuracy: 0.375\n",
            "[[ 4861  3971  7590]\n",
            " [ 4242  4816  6772]\n",
            " [ 5696  6079 10933]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.33      0.30      0.31     16422\n",
            "           0       0.32      0.30      0.31     15830\n",
            "           1       0.43      0.48      0.46     22708\n",
            "\n",
            "    accuracy                           0.38     54960\n",
            "   macro avg       0.36      0.36      0.36     54960\n",
            "weighted avg       0.37      0.38      0.37     54960\n",
            "\n",
            "testing 80   30\n",
            "Accuracy: 0.3773653566229985\n",
            "[[ 4910  3970  7542]\n",
            " [ 4284  4811  6735]\n",
            " [ 5890  5799 11019]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.33      0.30      0.31     16422\n",
            "           0       0.33      0.30      0.32     15830\n",
            "           1       0.44      0.49      0.46     22708\n",
            "\n",
            "    accuracy                           0.38     54960\n",
            "   macro avg       0.36      0.36      0.36     54960\n",
            "weighted avg       0.37      0.38      0.37     54960\n",
            "\n",
            "testing 80   40\n",
            "Accuracy: 0.376783114992722\n",
            "[[ 4859  3962  7601]\n",
            " [ 4241  4877  6712]\n",
            " [ 5778  5958 10972]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.33      0.30      0.31     16422\n",
            "           0       0.33      0.31      0.32     15830\n",
            "           1       0.43      0.48      0.46     22708\n",
            "\n",
            "    accuracy                           0.38     54960\n",
            "   macro avg       0.36      0.36      0.36     54960\n",
            "weighted avg       0.37      0.38      0.37     54960\n",
            "\n",
            "testing 80   50\n",
            "Accuracy: 0.3754366812227074\n",
            "[[ 4893  3956  7573]\n",
            " [ 4357  4678  6795]\n",
            " [ 5845  5800 11063]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.32      0.30      0.31     16422\n",
            "           0       0.32      0.30      0.31     15830\n",
            "           1       0.44      0.49      0.46     22708\n",
            "\n",
            "    accuracy                           0.38     54960\n",
            "   macro avg       0.36      0.36      0.36     54960\n",
            "weighted avg       0.37      0.38      0.37     54960\n",
            "\n",
            "testing 80   60\n",
            "Accuracy: 0.376146288209607\n",
            "[[ 4914  3979  7529]\n",
            " [ 4370  4767  6693]\n",
            " [ 5879  5837 10992]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.32      0.30      0.31     16422\n",
            "           0       0.33      0.30      0.31     15830\n",
            "           1       0.44      0.48      0.46     22708\n",
            "\n",
            "    accuracy                           0.38     54960\n",
            "   macro avg       0.36      0.36      0.36     54960\n",
            "weighted avg       0.37      0.38      0.37     54960\n",
            "\n",
            "testing 80   70\n",
            "Accuracy: 0.37501819505094613\n",
            "[[ 4805  4047  7570]\n",
            " [ 4344  4739  6747]\n",
            " [ 5824  5817 11067]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.32      0.29      0.31     16422\n",
            "           0       0.32      0.30      0.31     15830\n",
            "           1       0.44      0.49      0.46     22708\n",
            "\n",
            "    accuracy                           0.38     54960\n",
            "   macro avg       0.36      0.36      0.36     54960\n",
            "weighted avg       0.37      0.38      0.37     54960\n",
            "\n",
            "testing 80   80\n",
            "Accuracy: 0.374745269286754\n",
            "[[ 4896  3886  7640]\n",
            " [ 4377  4696  6757]\n",
            " [ 5887  5817 11004]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.32      0.30      0.31     16422\n",
            "           0       0.33      0.30      0.31     15830\n",
            "           1       0.43      0.48      0.46     22708\n",
            "\n",
            "    accuracy                           0.37     54960\n",
            "   macro avg       0.36      0.36      0.36     54960\n",
            "weighted avg       0.37      0.37      0.37     54960\n",
            "\n",
            "testing 80   90\n",
            "Accuracy: 0.37534570596797673\n",
            "[[ 4894  3933  7595]\n",
            " [ 4413  4675  6742]\n",
            " [ 5875  5773 11060]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.32      0.30      0.31     16422\n",
            "           0       0.33      0.30      0.31     15830\n",
            "           1       0.44      0.49      0.46     22708\n",
            "\n",
            "    accuracy                           0.38     54960\n",
            "   macro avg       0.36      0.36      0.36     54960\n",
            "weighted avg       0.37      0.38      0.37     54960\n",
            "\n",
            "testing 90   10\n",
            "Accuracy: 0.3719978165938865\n",
            "[[ 4719  3993  7710]\n",
            " [ 4197  4792  6841]\n",
            " [ 5838  5936 10934]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.32      0.29      0.30     16422\n",
            "           0       0.33      0.30      0.31     15830\n",
            "           1       0.43      0.48      0.45     22708\n",
            "\n",
            "    accuracy                           0.37     54960\n",
            "   macro avg       0.36      0.36      0.36     54960\n",
            "weighted avg       0.37      0.37      0.37     54960\n",
            "\n",
            "testing 90   20\n",
            "Accuracy: 0.37627365356623\n",
            "[[ 4869  3977  7576]\n",
            " [ 4254  4808  6768]\n",
            " [ 5688  6017 11003]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.33      0.30      0.31     16422\n",
            "           0       0.32      0.30      0.31     15830\n",
            "           1       0.43      0.48      0.46     22708\n",
            "\n",
            "    accuracy                           0.38     54960\n",
            "   macro avg       0.36      0.36      0.36     54960\n",
            "weighted avg       0.37      0.38      0.37     54960\n",
            "\n",
            "testing 90   30\n",
            "Accuracy: 0.37714701601164485\n",
            "[[ 4914  3959  7549]\n",
            " [ 4286  4803  6741]\n",
            " [ 5902  5795 11011]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.33      0.30      0.31     16422\n",
            "           0       0.33      0.30      0.32     15830\n",
            "           1       0.44      0.48      0.46     22708\n",
            "\n",
            "    accuracy                           0.38     54960\n",
            "   macro avg       0.36      0.36      0.36     54960\n",
            "weighted avg       0.37      0.38      0.37     54960\n",
            "\n",
            "testing 90   40\n",
            "Accuracy: 0.376910480349345\n",
            "[[ 4855  3962  7605]\n",
            " [ 4250  4872  6708]\n",
            " [ 5765  5955 10988]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.33      0.30      0.31     16422\n",
            "           0       0.33      0.31      0.32     15830\n",
            "           1       0.43      0.48      0.46     22708\n",
            "\n",
            "    accuracy                           0.38     54960\n",
            "   macro avg       0.36      0.36      0.36     54960\n",
            "weighted avg       0.37      0.38      0.37     54960\n",
            "\n",
            "testing 90   50\n",
            "Accuracy: 0.3756004366812227\n",
            "[[ 4883  4018  7521]\n",
            " [ 4368  4697  6765]\n",
            " [ 5847  5798 11063]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.32      0.30      0.31     16422\n",
            "           0       0.32      0.30      0.31     15830\n",
            "           1       0.44      0.49      0.46     22708\n",
            "\n",
            "    accuracy                           0.38     54960\n",
            "   macro avg       0.36      0.36      0.36     54960\n",
            "weighted avg       0.37      0.38      0.37     54960\n",
            "\n",
            "testing 90   60\n",
            "Accuracy: 0.3747998544395924\n",
            "[[ 4903  4017  7502]\n",
            " [ 4402  4746  6682]\n",
            " [ 5899  5859 10950]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.32      0.30      0.31     16422\n",
            "           0       0.32      0.30      0.31     15830\n",
            "           1       0.44      0.48      0.46     22708\n",
            "\n",
            "    accuracy                           0.37     54960\n",
            "   macro avg       0.36      0.36      0.36     54960\n",
            "weighted avg       0.37      0.37      0.37     54960\n",
            "\n",
            "testing 90   70\n",
            "Accuracy: 0.3755822416302766\n",
            "[[ 4812  4042  7568]\n",
            " [ 4346  4729  6755]\n",
            " [ 5798  5809 11101]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.32      0.29      0.31     16422\n",
            "           0       0.32      0.30      0.31     15830\n",
            "           1       0.44      0.49      0.46     22708\n",
            "\n",
            "    accuracy                           0.38     54960\n",
            "   macro avg       0.36      0.36      0.36     54960\n",
            "weighted avg       0.37      0.38      0.37     54960\n",
            "\n",
            "testing 90   80\n",
            "Accuracy: 0.3748180494905386\n",
            "[[ 4907  3872  7643]\n",
            " [ 4376  4720  6734]\n",
            " [ 5907  5828 10973]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.32      0.30      0.31     16422\n",
            "           0       0.33      0.30      0.31     15830\n",
            "           1       0.43      0.48      0.46     22708\n",
            "\n",
            "    accuracy                           0.37     54960\n",
            "   macro avg       0.36      0.36      0.36     54960\n",
            "weighted avg       0.37      0.37      0.37     54960\n",
            "\n",
            "testing 90   90\n",
            "Accuracy: 0.37470887918486173\n",
            "[[ 4857  3933  7632]\n",
            " [ 4410  4681  6739]\n",
            " [ 5869  5783 11056]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.32      0.30      0.31     16422\n",
            "           0       0.33      0.30      0.31     15830\n",
            "           1       0.43      0.49      0.46     22708\n",
            "\n",
            "    accuracy                           0.37     54960\n",
            "   macro avg       0.36      0.36      0.36     54960\n",
            "weighted avg       0.37      0.37      0.37     54960\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (max_x)\n",
        "print (max_y)\n",
        "print (max_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RrU3ipBeNhBH",
        "outputId": "25e2e9dd-9615-4724-c040-83bd189091d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n",
            "10\n",
            "0.3941957787481805\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  max_x = -1\n",
        "  max_y = -1\n",
        "  max_accuracy = 0\n",
        "  \n",
        "  for x in range(10):\n",
        "    for y in range(10): \n",
        "      print(\"testing\", x+2, \" \", y+2)\n",
        "      bst = XGBClassifier(n_estimators=x+2, max_depth=y+2, learning_rate=1, objective='binary:logistic', tree_method='hist')\n",
        "      bst.fit(np.array(x_train), np.array(y_train_7))\n",
        "      y_pred_7 = bst.predict(x_test)\n",
        "      accuracy = metrics.accuracy_score(y_test_7, y_pred_7)\n",
        "      print(\"Accuracy:\", accuracy)\n",
        "      print(confusion_matrix(y_test_7,y_pred_7))\n",
        "      print(classification_report(y_test_7,y_pred_7))\n",
        "\n",
        "      if (accuracy > max_accuracy):\n",
        "        max_x = x+2\n",
        "        max_y = y+2\n",
        "        max_accuracy = accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2y507haLFMWb",
        "outputId": "a5e6ec02-788f-4b5c-d0d3-fd4ffb71cc7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "testing 2   2\n",
            "Accuracy: 0.41584788937409023\n",
            "[[  319   113 15990]\n",
            " [  204   319 15307]\n",
            " [  226   265 22217]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.43      0.02      0.04     16422\n",
            "           0       0.46      0.02      0.04     15830\n",
            "           1       0.42      0.98      0.58     22708\n",
            "\n",
            "    accuracy                           0.42     54960\n",
            "   macro avg       0.43      0.34      0.22     54960\n",
            "weighted avg       0.43      0.42      0.26     54960\n",
            "\n",
            "testing 2   3\n",
            "Accuracy: 0.42467248908296945\n",
            "[[ 1423  1553 13446]\n",
            " [  730  2347 12753]\n",
            " [  950  2188 19570]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.46      0.09      0.15     16422\n",
            "           0       0.39      0.15      0.21     15830\n",
            "           1       0.43      0.86      0.57     22708\n",
            "\n",
            "    accuracy                           0.42     54960\n",
            "   macro avg       0.42      0.37      0.31     54960\n",
            "weighted avg       0.42      0.42      0.34     54960\n",
            "\n",
            "testing 2   4\n",
            "Accuracy: 0.42778384279475984\n",
            "[[ 1928  1859 12635]\n",
            " [  976  2619 12235]\n",
            " [ 1339  2405 18964]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.45      0.12      0.19     16422\n",
            "           0       0.38      0.17      0.23     15830\n",
            "           1       0.43      0.84      0.57     22708\n",
            "\n",
            "    accuracy                           0.43     54960\n",
            "   macro avg       0.42      0.37      0.33     54960\n",
            "weighted avg       0.42      0.43      0.36     54960\n",
            "\n",
            "testing 2   5\n",
            "Accuracy: 0.43058588064046577\n",
            "[[ 2579  1357 12486]\n",
            " [ 1434  2002 12394]\n",
            " [ 1862  1762 19084]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.44      0.16      0.23     16422\n",
            "           0       0.39      0.13      0.19     15830\n",
            "           1       0.43      0.84      0.57     22708\n",
            "\n",
            "    accuracy                           0.43     54960\n",
            "   macro avg       0.42      0.37      0.33     54960\n",
            "weighted avg       0.42      0.43      0.36     54960\n",
            "\n",
            "testing 2   6\n",
            "Accuracy: 0.4318413391557496\n",
            "[[ 2711  1821 11890]\n",
            " [ 1456  2861 11513]\n",
            " [ 1988  2558 18162]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.44      0.17      0.24     16422\n",
            "           0       0.40      0.18      0.25     15830\n",
            "           1       0.44      0.80      0.57     22708\n",
            "\n",
            "    accuracy                           0.43     54960\n",
            "   macro avg       0.42      0.38      0.35     54960\n",
            "weighted avg       0.43      0.43      0.38     54960\n",
            "\n",
            "testing 2   7\n",
            "Accuracy: 0.4283842794759825\n",
            "[[ 2908  1940 11574]\n",
            " [ 1776  3121 10933]\n",
            " [ 2326  2867 17515]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.41      0.18      0.25     16422\n",
            "           0       0.39      0.20      0.26     15830\n",
            "           1       0.44      0.77      0.56     22708\n",
            "\n",
            "    accuracy                           0.43     54960\n",
            "   macro avg       0.42      0.38      0.36     54960\n",
            "weighted avg       0.42      0.43      0.38     54960\n",
            "\n",
            "testing 2   8\n",
            "Accuracy: 0.42727438136826784\n",
            "[[ 3394  2424 10604]\n",
            " [ 2023  3683 10124]\n",
            " [ 2798  3504 16406]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.41      0.21      0.28     16422\n",
            "           0       0.38      0.23      0.29     15830\n",
            "           1       0.44      0.72      0.55     22708\n",
            "\n",
            "    accuracy                           0.43     54960\n",
            "   macro avg       0.41      0.39      0.37     54960\n",
            "weighted avg       0.42      0.43      0.39     54960\n",
            "\n",
            "testing 2   9\n",
            "Accuracy: 0.42554585152838426\n",
            "[[ 3752  2518 10152]\n",
            " [ 2451  3860  9519]\n",
            " [ 3193  3739 15776]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.40      0.23      0.29     16422\n",
            "           0       0.38      0.24      0.30     15830\n",
            "           1       0.45      0.69      0.54     22708\n",
            "\n",
            "    accuracy                           0.43     54960\n",
            "   macro avg       0.41      0.39      0.38     54960\n",
            "weighted avg       0.41      0.43      0.40     54960\n",
            "\n",
            "testing 2   10\n",
            "Accuracy: 0.4173580786026201\n",
            "[[ 3751  2735  9936]\n",
            " [ 2550  4086  9194]\n",
            " [ 3481  4126 15101]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.38      0.23      0.29     16422\n",
            "           0       0.37      0.26      0.31     15830\n",
            "           1       0.44      0.67      0.53     22708\n",
            "\n",
            "    accuracy                           0.42     54960\n",
            "   macro avg       0.40      0.38      0.37     54960\n",
            "weighted avg       0.40      0.42      0.39     54960\n",
            "\n",
            "testing 2   11\n",
            "Accuracy: 0.4088427947598253\n",
            "[[ 3976  3133  9313]\n",
            " [ 2907  4139  8784]\n",
            " [ 3814  4539 14355]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.37      0.24      0.29     16422\n",
            "           0       0.35      0.26      0.30     15830\n",
            "           1       0.44      0.63      0.52     22708\n",
            "\n",
            "    accuracy                           0.41     54960\n",
            "   macro avg       0.39      0.38      0.37     54960\n",
            "weighted avg       0.39      0.41      0.39     54960\n",
            "\n",
            "testing 3   2\n",
            "Accuracy: 0.41810407569141195\n",
            "[[  354  1546 14522]\n",
            " [  225  2352 13253]\n",
            " [  243  2192 20273]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.43      0.02      0.04     16422\n",
            "           0       0.39      0.15      0.21     15830\n",
            "           1       0.42      0.89      0.57     22708\n",
            "\n",
            "    accuracy                           0.42     54960\n",
            "   macro avg       0.41      0.35      0.28     54960\n",
            "weighted avg       0.41      0.42      0.31     54960\n",
            "\n",
            "testing 3   3\n",
            "Accuracy: 0.4282569141193595\n",
            "[[ 1875  1675 12872]\n",
            " [ 1058  2740 12032]\n",
            " [ 1240  2546 18922]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.45      0.11      0.18     16422\n",
            "           0       0.39      0.17      0.24     15830\n",
            "           1       0.43      0.83      0.57     22708\n",
            "\n",
            "    accuracy                           0.43     54960\n",
            "   macro avg       0.42      0.37      0.33     54960\n",
            "weighted avg       0.43      0.43      0.36     54960\n",
            "\n",
            "testing 3   4\n",
            "Accuracy: 0.4264919941775837\n",
            "[[ 1953  1977 12492]\n",
            " [ 1058  2763 12009]\n",
            " [ 1435  2549 18724]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.44      0.12      0.19     16422\n",
            "           0       0.38      0.17      0.24     15830\n",
            "           1       0.43      0.82      0.57     22708\n",
            "\n",
            "    accuracy                           0.43     54960\n",
            "   macro avg       0.42      0.37      0.33     54960\n",
            "weighted avg       0.42      0.43      0.36     54960\n",
            "\n",
            "testing 3   5\n",
            "Accuracy: 0.4320778748180495\n",
            "[[ 2588  2025 11809]\n",
            " [ 1396  3248 11186]\n",
            " [ 1867  2930 17911]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.44      0.16      0.23     16422\n",
            "           0       0.40      0.21      0.27     15830\n",
            "           1       0.44      0.79      0.56     22708\n",
            "\n",
            "    accuracy                           0.43     54960\n",
            "   macro avg       0.43      0.38      0.36     54960\n",
            "weighted avg       0.43      0.43      0.38     54960\n",
            "\n",
            "testing 3   6\n",
            "Accuracy: 0.4316411935953421\n",
            "[[ 2926  2309 11187]\n",
            " [ 1628  3506 10696]\n",
            " [ 2282  3135 17291]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.43      0.18      0.25     16422\n",
            "           0       0.39      0.22      0.28     15830\n",
            "           1       0.44      0.76      0.56     22708\n",
            "\n",
            "    accuracy                           0.43     54960\n",
            "   macro avg       0.42      0.39      0.36     54960\n",
            "weighted avg       0.42      0.43      0.39     54960\n",
            "\n",
            "testing 3   7\n",
            "Accuracy: 0.4256550218340611\n",
            "[[ 3186  2305 10931]\n",
            " [ 2016  3550 10264]\n",
            " [ 2661  3389 16658]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.41      0.19      0.26     16422\n",
            "           0       0.38      0.22      0.28     15830\n",
            "           1       0.44      0.73      0.55     22708\n",
            "\n",
            "    accuracy                           0.43     54960\n",
            "   macro avg       0.41      0.38      0.37     54960\n",
            "weighted avg       0.41      0.43      0.39     54960\n",
            "\n",
            "testing 3   8\n",
            "Accuracy: 0.4220887918486172\n",
            "[[ 3453  2755 10214]\n",
            " [ 2163  4195  9472]\n",
            " [ 3077  4081 15550]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.40      0.21      0.27     16422\n",
            "           0       0.38      0.27      0.31     15830\n",
            "           1       0.44      0.68      0.54     22708\n",
            "\n",
            "    accuracy                           0.42     54960\n",
            "   macro avg       0.41      0.39      0.37     54960\n",
            "weighted avg       0.41      0.42      0.39     54960\n",
            "\n",
            "testing 3   9\n",
            "Accuracy: 0.4181950509461427\n",
            "[[ 3721  2907  9794]\n",
            " [ 2562  4204  9064]\n",
            " [ 3291  4358 15059]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.39      0.23      0.29     16422\n",
            "           0       0.37      0.27      0.31     15830\n",
            "           1       0.44      0.66      0.53     22708\n",
            "\n",
            "    accuracy                           0.42     54960\n",
            "   macro avg       0.40      0.39      0.38     54960\n",
            "weighted avg       0.41      0.42      0.39     54960\n",
            "\n",
            "testing 3   10\n",
            "Accuracy: 0.4072962154294032\n",
            "[[ 3897  2967  9558]\n",
            " [ 2773  4250  8807]\n",
            " [ 3916  4554 14238]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.37      0.24      0.29     16422\n",
            "           0       0.36      0.27      0.31     15830\n",
            "           1       0.44      0.63      0.51     22708\n",
            "\n",
            "    accuracy                           0.41     54960\n",
            "   macro avg       0.39      0.38      0.37     54960\n",
            "weighted avg       0.39      0.41      0.39     54960\n",
            "\n",
            "testing 3   11\n",
            "Accuracy: 0.4032387190684134\n",
            "[[ 4073  3267  9082]\n",
            " [ 3072  4374  8384]\n",
            " [ 4132  4861 13715]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.36      0.25      0.29     16422\n",
            "           0       0.35      0.28      0.31     15830\n",
            "           1       0.44      0.60      0.51     22708\n",
            "\n",
            "    accuracy                           0.40     54960\n",
            "   macro avg       0.38      0.38      0.37     54960\n",
            "weighted avg       0.39      0.40      0.39     54960\n",
            "\n",
            "testing 4   2\n",
            "Accuracy: 0.42256186317321687\n",
            "[[ 1236  1589 13597]\n",
            " [  708  2424 12698]\n",
            " [  817  2327 19564]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.45      0.08      0.13     16422\n",
            "           0       0.38      0.15      0.22     15830\n",
            "           1       0.43      0.86      0.57     22708\n",
            "\n",
            "    accuracy                           0.42     54960\n",
            "   macro avg       0.42      0.36      0.31     54960\n",
            "weighted avg       0.42      0.42      0.34     54960\n",
            "\n",
            "testing 4   3\n",
            "Accuracy: 0.43033114992721977\n",
            "[[ 2201  1503 12718]\n",
            " [ 1330  2417 12083]\n",
            " [ 1564  2111 19033]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.43      0.13      0.20     16422\n",
            "           0       0.40      0.15      0.22     15830\n",
            "           1       0.43      0.84      0.57     22708\n",
            "\n",
            "    accuracy                           0.43     54960\n",
            "   macro avg       0.42      0.37      0.33     54960\n",
            "weighted avg       0.42      0.43      0.36     54960\n",
            "\n",
            "testing 4   4\n",
            "Accuracy: 0.42656477438136825\n",
            "[[ 2375  2111 11936]\n",
            " [ 1302  2991 11537]\n",
            " [ 1812  2818 18078]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.43      0.14      0.22     16422\n",
            "           0       0.38      0.19      0.25     15830\n",
            "           1       0.44      0.80      0.56     22708\n",
            "\n",
            "    accuracy                           0.43     54960\n",
            "   macro avg       0.42      0.38      0.34     54960\n",
            "weighted avg       0.42      0.43      0.37     54960\n",
            "\n",
            "testing 4   5\n",
            "Accuracy: 0.43091339155749636\n",
            "[[ 2728  2076 11618]\n",
            " [ 1528  3343 10959]\n",
            " [ 2110  2986 17612]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.43      0.17      0.24     16422\n",
            "           0       0.40      0.21      0.28     15830\n",
            "           1       0.44      0.78      0.56     22708\n",
            "\n",
            "    accuracy                           0.43     54960\n",
            "   macro avg       0.42      0.38      0.36     54960\n",
            "weighted avg       0.42      0.43      0.38     54960\n",
            "\n",
            "testing 4   6\n",
            "Accuracy: 0.42949417758369723\n",
            "[[ 3123  2366 10933]\n",
            " [ 1848  3676 10306]\n",
            " [ 2530  3372 16806]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.42      0.19      0.26     16422\n",
            "           0       0.39      0.23      0.29     15830\n",
            "           1       0.44      0.74      0.55     22708\n",
            "\n",
            "    accuracy                           0.43     54960\n",
            "   macro avg       0.42      0.39      0.37     54960\n",
            "weighted avg       0.42      0.43      0.39     54960\n",
            "\n",
            "testing 4   7\n",
            "Accuracy: 0.42412663755458513\n",
            "[[ 3577  2455 10390]\n",
            " [ 2328  3875  9627]\n",
            " [ 3136  3714 15858]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.40      0.22      0.28     16422\n",
            "           0       0.39      0.24      0.30     15830\n",
            "           1       0.44      0.70      0.54     22708\n",
            "\n",
            "    accuracy                           0.42     54960\n",
            "   macro avg       0.41      0.39      0.37     54960\n",
            "weighted avg       0.41      0.42      0.39     54960\n",
            "\n",
            "testing 4   8\n",
            "Accuracy: 0.42130640465793306\n",
            "[[ 3557  2972  9893]\n",
            " [ 2272  4357  9201]\n",
            " [ 3213  4254 15241]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.39      0.22      0.28     16422\n",
            "           0       0.38      0.28      0.32     15830\n",
            "           1       0.44      0.67      0.53     22708\n",
            "\n",
            "    accuracy                           0.42     54960\n",
            "   macro avg       0.40      0.39      0.38     54960\n",
            "weighted avg       0.41      0.42      0.40     54960\n",
            "\n",
            "testing 4   9\n",
            "Accuracy: 0.4169032023289665\n",
            "[[ 3790  3166  9466]\n",
            " [ 2612  4433  8785]\n",
            " [ 3413  4605 14690]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.39      0.23      0.29     16422\n",
            "           0       0.36      0.28      0.32     15830\n",
            "           1       0.45      0.65      0.53     22708\n",
            "\n",
            "    accuracy                           0.42     54960\n",
            "   macro avg       0.40      0.39      0.38     54960\n",
            "weighted avg       0.40      0.42      0.40     54960\n",
            "\n",
            "testing 4   10\n",
            "Accuracy: 0.40407569141193594\n",
            "[[ 3953  3149  9320]\n",
            " [ 2988  4338  8504]\n",
            " [ 4130  4661 13917]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.36      0.24      0.29     16422\n",
            "           0       0.36      0.27      0.31     15830\n",
            "           1       0.44      0.61      0.51     22708\n",
            "\n",
            "    accuracy                           0.40     54960\n",
            "   macro avg       0.38      0.38      0.37     54960\n",
            "weighted avg       0.39      0.40      0.39     54960\n",
            "\n",
            "testing 4   11\n",
            "Accuracy: 0.39929039301310043\n",
            "[[ 4159  3453  8810]\n",
            " [ 3212  4505  8113]\n",
            " [ 4393  5034 13281]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.35      0.25      0.30     16422\n",
            "           0       0.35      0.28      0.31     15830\n",
            "           1       0.44      0.58      0.50     22708\n",
            "\n",
            "    accuracy                           0.40     54960\n",
            "   macro avg       0.38      0.37      0.37     54960\n",
            "weighted avg       0.39      0.40      0.39     54960\n",
            "\n",
            "testing 5   2\n",
            "Accuracy: 0.42167030567685587\n",
            "[[ 1321  1653 13448]\n",
            " [  763  2460 12607]\n",
            " [  943  2371 19394]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.44      0.08      0.14     16422\n",
            "           0       0.38      0.16      0.22     15830\n",
            "           1       0.43      0.85      0.57     22708\n",
            "\n",
            "    accuracy                           0.42     54960\n",
            "   macro avg       0.41      0.36      0.31     54960\n",
            "weighted avg       0.42      0.42      0.34     54960\n",
            "\n",
            "testing 5   3\n",
            "Accuracy: 0.42949417758369723\n",
            "[[ 2358  1722 12342]\n",
            " [ 1387  2727 11716]\n",
            " [ 1710  2478 18520]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.43      0.14      0.22     16422\n",
            "           0       0.39      0.17      0.24     15830\n",
            "           1       0.43      0.82      0.57     22708\n",
            "\n",
            "    accuracy                           0.43     54960\n",
            "   macro avg       0.42      0.38      0.34     54960\n",
            "weighted avg       0.42      0.43      0.37     54960\n",
            "\n",
            "testing 5   4\n",
            "Accuracy: 0.4288755458515284\n",
            "[[ 2565  2170 11687]\n",
            " [ 1411  3143 11276]\n",
            " [ 1981  2864 17863]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.43      0.16      0.23     16422\n",
            "           0       0.38      0.20      0.26     15830\n",
            "           1       0.44      0.79      0.56     22708\n",
            "\n",
            "    accuracy                           0.43     54960\n",
            "   macro avg       0.42      0.38      0.35     54960\n",
            "weighted avg       0.42      0.43      0.38     54960\n",
            "\n",
            "testing 5   5\n",
            "Accuracy: 0.4314410480349345\n",
            "[[ 2998  2193 11231]\n",
            " [ 1729  3548 10553]\n",
            " [ 2376  3166 17166]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.42      0.18      0.25     16422\n",
            "           0       0.40      0.22      0.29     15830\n",
            "           1       0.44      0.76      0.56     22708\n",
            "\n",
            "    accuracy                           0.43     54960\n",
            "   macro avg       0.42      0.39      0.37     54960\n",
            "weighted avg       0.42      0.43      0.39     54960\n",
            "\n",
            "testing 5   6\n",
            "Accuracy: 0.42834788937409024\n",
            "[[ 3259  2608 10555]\n",
            " [ 1928  3954  9948]\n",
            " [ 2737  3642 16329]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.41      0.20      0.27     16422\n",
            "           0       0.39      0.25      0.30     15830\n",
            "           1       0.44      0.72      0.55     22708\n",
            "\n",
            "    accuracy                           0.43     54960\n",
            "   macro avg       0.41      0.39      0.37     54960\n",
            "weighted avg       0.42      0.43      0.39     54960\n",
            "\n",
            "testing 5   7\n",
            "Accuracy: 0.42319868995633186\n",
            "[[ 3713  2604 10105]\n",
            " [ 2478  4043  9309]\n",
            " [ 3351  3854 15503]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.39      0.23      0.29     16422\n",
            "           0       0.39      0.26      0.31     15830\n",
            "           1       0.44      0.68      0.54     22708\n",
            "\n",
            "    accuracy                           0.42     54960\n",
            "   macro avg       0.41      0.39      0.38     54960\n",
            "weighted avg       0.41      0.42      0.40     54960\n",
            "\n",
            "testing 5   8\n",
            "Accuracy: 0.41874090247452694\n",
            "[[ 3689  3103  9630]\n",
            " [ 2460  4453  8917]\n",
            " [ 3444  4392 14872]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.38      0.22      0.28     16422\n",
            "           0       0.37      0.28      0.32     15830\n",
            "           1       0.45      0.65      0.53     22708\n",
            "\n",
            "    accuracy                           0.42     54960\n",
            "   macro avg       0.40      0.39      0.38     54960\n",
            "weighted avg       0.41      0.42      0.40     54960\n",
            "\n",
            "testing 5   9\n",
            "Accuracy: 0.4142467248908297\n",
            "[[ 3878  3230  9314]\n",
            " [ 2725  4475  8630]\n",
            " [ 3615  4679 14414]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.38      0.24      0.29     16422\n",
            "           0       0.36      0.28      0.32     15830\n",
            "           1       0.45      0.63      0.52     22708\n",
            "\n",
            "    accuracy                           0.41     54960\n",
            "   macro avg       0.40      0.38      0.38     54960\n",
            "weighted avg       0.40      0.41      0.39     54960\n",
            "\n",
            "testing 5   10\n",
            "Accuracy: 0.4026018922852984\n",
            "[[ 4119  3158  9145]\n",
            " [ 3208  4378  8244]\n",
            " [ 4314  4764 13630]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.35      0.25      0.29     16422\n",
            "           0       0.36      0.28      0.31     15830\n",
            "           1       0.44      0.60      0.51     22708\n",
            "\n",
            "    accuracy                           0.40     54960\n",
            "   macro avg       0.38      0.38      0.37     54960\n",
            "weighted avg       0.39      0.40      0.39     54960\n",
            "\n",
            "testing 5   11\n",
            "Accuracy: 0.3972343522561863\n",
            "[[ 4284  3376  8762]\n",
            " [ 3361  4435  8034]\n",
            " [ 4549  5046 13113]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.35      0.26      0.30     16422\n",
            "           0       0.34      0.28      0.31     15830\n",
            "           1       0.44      0.58      0.50     22708\n",
            "\n",
            "    accuracy                           0.40     54960\n",
            "   macro avg       0.38      0.37      0.37     54960\n",
            "weighted avg       0.39      0.40      0.38     54960\n",
            "\n",
            "testing 6   2\n",
            "Accuracy: 0.42689228529839884\n",
            "[[ 1754  1016 13652]\n",
            " [  949  1662 13219]\n",
            " [ 1184  1478 20046]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.45      0.11      0.17     16422\n",
            "           0       0.40      0.10      0.17     15830\n",
            "           1       0.43      0.88      0.58     22708\n",
            "\n",
            "    accuracy                           0.43     54960\n",
            "   macro avg       0.43      0.36      0.30     54960\n",
            "weighted avg       0.43      0.43      0.34     54960\n",
            "\n",
            "testing 6   3\n",
            "Accuracy: 0.4298216885007278\n",
            "[[ 2545  1779 12098]\n",
            " [ 1447  2741 11642]\n",
            " [ 1832  2539 18337]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.44      0.15      0.23     16422\n",
            "           0       0.39      0.17      0.24     15830\n",
            "           1       0.44      0.81      0.57     22708\n",
            "\n",
            "    accuracy                           0.43     54960\n",
            "   macro avg       0.42      0.38      0.34     54960\n",
            "weighted avg       0.42      0.43      0.37     54960\n",
            "\n",
            "testing 6   4\n",
            "Accuracy: 0.4283660844250364\n",
            "[[ 2693  2187 11542]\n",
            " [ 1505  3240 11085]\n",
            " [ 2119  2979 17610]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.43      0.16      0.24     16422\n",
            "           0       0.39      0.20      0.27     15830\n",
            "           1       0.44      0.78      0.56     22708\n",
            "\n",
            "    accuracy                           0.43     54960\n",
            "   macro avg       0.42      0.38      0.35     54960\n",
            "weighted avg       0.42      0.43      0.38     54960\n",
            "\n",
            "testing 6   5\n",
            "Accuracy: 0.4293486171761281\n",
            "[[ 3119  2577 10726]\n",
            " [ 1835  4075  9920]\n",
            " [ 2507  3798 16403]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.42      0.19      0.26     16422\n",
            "           0       0.39      0.26      0.31     15830\n",
            "           1       0.44      0.72      0.55     22708\n",
            "\n",
            "    accuracy                           0.43     54960\n",
            "   macro avg       0.42      0.39      0.37     54960\n",
            "weighted avg       0.42      0.43      0.39     54960\n",
            "\n",
            "testing 6   6\n",
            "Accuracy: 0.42783842794759824\n",
            "[[ 3362  2683 10377]\n",
            " [ 2025  4062  9743]\n",
            " [ 2872  3746 16090]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.41      0.20      0.27     16422\n",
            "           0       0.39      0.26      0.31     15830\n",
            "           1       0.44      0.71      0.55     22708\n",
            "\n",
            "    accuracy                           0.43     54960\n",
            "   macro avg       0.41      0.39      0.38     54960\n",
            "weighted avg       0.42      0.43      0.40     54960\n",
            "\n",
            "testing 6   7\n",
            "Accuracy: 0.42092430858806407\n",
            "[[ 3804  2673  9945]\n",
            " [ 2604  4139  9087]\n",
            " [ 3572  3945 15191]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.38      0.23      0.29     16422\n",
            "           0       0.38      0.26      0.31     15830\n",
            "           1       0.44      0.67      0.53     22708\n",
            "\n",
            "    accuracy                           0.42     54960\n",
            "   macro avg       0.40      0.39      0.38     54960\n",
            "weighted avg       0.41      0.42      0.40     54960\n",
            "\n",
            "testing 6   8\n",
            "Accuracy: 0.41764919941775835\n",
            "[[ 3885  3125  9412]\n",
            " [ 2680  4463  8687]\n",
            " [ 3658  4444 14606]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.38      0.24      0.29     16422\n",
            "           0       0.37      0.28      0.32     15830\n",
            "           1       0.45      0.64      0.53     22708\n",
            "\n",
            "    accuracy                           0.42     54960\n",
            "   macro avg       0.40      0.39      0.38     54960\n",
            "weighted avg       0.40      0.42      0.40     54960\n",
            "\n",
            "testing 6   9\n",
            "Accuracy: 0.41102620087336245\n",
            "[[ 3935  3252  9235]\n",
            " [ 2818  4404  8608]\n",
            " [ 3806  4651 14251]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.37      0.24      0.29     16422\n",
            "           0       0.36      0.28      0.31     15830\n",
            "           1       0.44      0.63      0.52     22708\n",
            "\n",
            "    accuracy                           0.41     54960\n",
            "   macro avg       0.39      0.38      0.37     54960\n",
            "weighted avg       0.40      0.41      0.39     54960\n",
            "\n",
            "testing 6   10\n",
            "Accuracy: 0.4009279475982533\n",
            "[[ 4155  3225  9042]\n",
            " [ 3313  4375  8142]\n",
            " [ 4363  4840 13505]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.35      0.25      0.29     16422\n",
            "           0       0.35      0.28      0.31     15830\n",
            "           1       0.44      0.59      0.51     22708\n",
            "\n",
            "    accuracy                           0.40     54960\n",
            "   macro avg       0.38      0.37      0.37     54960\n",
            "weighted avg       0.39      0.40      0.39     54960\n",
            "\n",
            "testing 6   11\n",
            "Accuracy: 0.3941957787481805\n",
            "[[ 4341  3405  8676]\n",
            " [ 3446  4443  7941]\n",
            " [ 4728  5099 12881]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.35      0.26      0.30     16422\n",
            "           0       0.34      0.28      0.31     15830\n",
            "           1       0.44      0.57      0.49     22708\n",
            "\n",
            "    accuracy                           0.39     54960\n",
            "   macro avg       0.38      0.37      0.37     54960\n",
            "weighted avg       0.38      0.39      0.38     54960\n",
            "\n",
            "testing 7   2\n",
            "Accuracy: 0.42745633187772925\n",
            "[[ 1887  1430 13105]\n",
            " [ 1073  2068 12689]\n",
            " [ 1324  1846 19538]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.44      0.11      0.18     16422\n",
            "           0       0.39      0.13      0.20     15830\n",
            "           1       0.43      0.86      0.57     22708\n",
            "\n",
            "    accuracy                           0.43     54960\n",
            "   macro avg       0.42      0.37      0.32     54960\n",
            "weighted avg       0.42      0.43      0.35     54960\n",
            "\n",
            "testing 7   3\n",
            "Accuracy: 0.4287663755458515\n",
            "[[ 2634  1968 11820]\n",
            " [ 1544  3052 11234]\n",
            " [ 1960  2869 17879]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.43      0.16      0.23     16422\n",
            "           0       0.39      0.19      0.26     15830\n",
            "           1       0.44      0.79      0.56     22708\n",
            "\n",
            "    accuracy                           0.43     54960\n",
            "   macro avg       0.42      0.38      0.35     54960\n",
            "weighted avg       0.42      0.43      0.38     54960\n",
            "\n",
            "testing 7   4\n",
            "Accuracy: 0.43033114992721977\n",
            "[[ 2943  2341 11138]\n",
            " [ 1560  3529 10741]\n",
            " [ 2269  3260 17179]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.43      0.18      0.25     16422\n",
            "           0       0.39      0.22      0.28     15830\n",
            "           1       0.44      0.76      0.56     22708\n",
            "\n",
            "    accuracy                           0.43     54960\n",
            "   macro avg       0.42      0.39      0.36     54960\n",
            "weighted avg       0.42      0.43      0.39     54960\n",
            "\n",
            "testing 7   5\n",
            "Accuracy: 0.4293486171761281\n",
            "[[ 3192  2573 10657]\n",
            " [ 1902  4083  9845]\n",
            " [ 2595  3791 16322]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.42      0.19      0.26     16422\n",
            "           0       0.39      0.26      0.31     15830\n",
            "           1       0.44      0.72      0.55     22708\n",
            "\n",
            "    accuracy                           0.43     54960\n",
            "   macro avg       0.42      0.39      0.37     54960\n",
            "weighted avg       0.42      0.43      0.40     54960\n",
            "\n",
            "testing 7   6\n",
            "Accuracy: 0.4284024745269287\n",
            "[[ 3462  2707 10253]\n",
            " [ 2104  4059  9667]\n",
            " [ 2937  3747 16024]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.41      0.21      0.28     16422\n",
            "           0       0.39      0.26      0.31     15830\n",
            "           1       0.45      0.71      0.55     22708\n",
            "\n",
            "    accuracy                           0.43     54960\n",
            "   macro avg       0.41      0.39      0.38     54960\n",
            "weighted avg       0.42      0.43      0.40     54960\n",
            "\n",
            "testing 7   7\n",
            "Accuracy: 0.4186499272197962\n",
            "[[ 3811  2810  9801]\n",
            " [ 2634  4207  8989]\n",
            " [ 3652  4065 14991]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.38      0.23      0.29     16422\n",
            "           0       0.38      0.27      0.31     15830\n",
            "           1       0.44      0.66      0.53     22708\n",
            "\n",
            "    accuracy                           0.42     54960\n",
            "   macro avg       0.40      0.39      0.38     54960\n",
            "weighted avg       0.41      0.42      0.40     54960\n",
            "\n",
            "testing 7   8\n",
            "Accuracy: 0.41599344978165936\n",
            "[[ 3899  3151  9372]\n",
            " [ 2702  4453  8675]\n",
            " [ 3760  4437 14511]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.38      0.24      0.29     16422\n",
            "           0       0.37      0.28      0.32     15830\n",
            "           1       0.45      0.64      0.53     22708\n",
            "\n",
            "    accuracy                           0.42     54960\n",
            "   macro avg       0.40      0.39      0.38     54960\n",
            "weighted avg       0.40      0.42      0.40     54960\n",
            "\n",
            "testing 7   9\n",
            "Accuracy: 0.41020742358078605\n",
            "[[ 3977  3321  9124]\n",
            " [ 2884  4482  8464]\n",
            " [ 3915  4707 14086]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.37      0.24      0.29     16422\n",
            "           0       0.36      0.28      0.32     15830\n",
            "           1       0.44      0.62      0.52     22708\n",
            "\n",
            "    accuracy                           0.41     54960\n",
            "   macro avg       0.39      0.38      0.38     54960\n",
            "weighted avg       0.40      0.41      0.39     54960\n",
            "\n",
            "testing 7   10\n",
            "Accuracy: 0.40070960698689956\n",
            "[[ 4166  3256  9000]\n",
            " [ 3277  4446  8107]\n",
            " [ 4415  4882 13411]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.35      0.25      0.29     16422\n",
            "           0       0.35      0.28      0.31     15830\n",
            "           1       0.44      0.59      0.50     22708\n",
            "\n",
            "    accuracy                           0.40     54960\n",
            "   macro avg       0.38      0.38      0.37     54960\n",
            "weighted avg       0.39      0.40      0.39     54960\n",
            "\n",
            "testing 7   11\n",
            "Accuracy: 0.39179403202328966\n",
            "[[ 4431  3551  8440]\n",
            " [ 3573  4580  7677]\n",
            " [ 4860  5326 12522]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.34      0.27      0.30     16422\n",
            "           0       0.34      0.29      0.31     15830\n",
            "           1       0.44      0.55      0.49     22708\n",
            "\n",
            "    accuracy                           0.39     54960\n",
            "   macro avg       0.37      0.37      0.37     54960\n",
            "weighted avg       0.38      0.39      0.38     54960\n",
            "\n",
            "testing 8   2\n",
            "Accuracy: 0.4282387190684134\n",
            "[[ 1855  1626 12941]\n",
            " [ 1037  2374 12419]\n",
            " [ 1272  2129 19307]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.45      0.11      0.18     16422\n",
            "           0       0.39      0.15      0.22     15830\n",
            "           1       0.43      0.85      0.57     22708\n",
            "\n",
            "    accuracy                           0.43     54960\n",
            "   macro avg       0.42      0.37      0.32     54960\n",
            "weighted avg       0.42      0.43      0.35     54960\n",
            "\n",
            "testing 8   3\n",
            "Accuracy: 0.4281477438136827\n",
            "[[ 2638  1858 11926]\n",
            " [ 1591  2858 11381]\n",
            " [ 2022  2651 18035]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.42      0.16      0.23     16422\n",
            "           0       0.39      0.18      0.25     15830\n",
            "           1       0.44      0.79      0.56     22708\n",
            "\n",
            "    accuracy                           0.43     54960\n",
            "   macro avg       0.42      0.38      0.35     54960\n",
            "weighted avg       0.42      0.43      0.37     54960\n",
            "\n",
            "testing 8   4\n",
            "Accuracy: 0.4283660844250364\n",
            "[[ 3088  2441 10893]\n",
            " [ 1709  3680 10441]\n",
            " [ 2537  3396 16775]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.42      0.19      0.26     16422\n",
            "           0       0.39      0.23      0.29     15830\n",
            "           1       0.44      0.74      0.55     22708\n",
            "\n",
            "    accuracy                           0.43     54960\n",
            "   macro avg       0.42      0.39      0.37     54960\n",
            "weighted avg       0.42      0.43      0.39     54960\n",
            "\n",
            "testing 8   5\n",
            "Accuracy: 0.4292212518195051\n",
            "[[ 3326  2631 10465]\n",
            " [ 2006  4110  9714]\n",
            " [ 2743  3811 16154]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.41      0.20      0.27     16422\n",
            "           0       0.39      0.26      0.31     15830\n",
            "           1       0.44      0.71      0.55     22708\n",
            "\n",
            "    accuracy                           0.43     54960\n",
            "   macro avg       0.42      0.39      0.38     54960\n",
            "weighted avg       0.42      0.43      0.40     54960\n",
            "\n",
            "testing 8   6\n",
            "Accuracy: 0.4267467248908297\n",
            "[[ 3623  2825  9974]\n",
            " [ 2304  4165  9361]\n",
            " [ 3208  3834 15666]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.40      0.22      0.28     16422\n",
            "           0       0.38      0.26      0.31     15830\n",
            "           1       0.45      0.69      0.54     22708\n",
            "\n",
            "    accuracy                           0.43     54960\n",
            "   macro avg       0.41      0.39      0.38     54960\n",
            "weighted avg       0.41      0.43      0.40     54960\n",
            "\n",
            "testing 8   7\n",
            "Accuracy: 0.4172307132459971\n",
            "[[ 3913  2921  9588]\n",
            " [ 2702  4304  8824]\n",
            " [ 3810  4184 14714]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.38      0.24      0.29     16422\n",
            "           0       0.38      0.27      0.32     15830\n",
            "           1       0.44      0.65      0.53     22708\n",
            "\n",
            "    accuracy                           0.42     54960\n",
            "   macro avg       0.40      0.39      0.38     54960\n",
            "weighted avg       0.40      0.42      0.40     54960\n",
            "\n",
            "testing 8   8\n",
            "Accuracy: 0.41415574963609897\n",
            "[[ 3981  3183  9258]\n",
            " [ 2824  4516  8490]\n",
            " [ 3927  4516 14265]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.37      0.24      0.29     16422\n",
            "           0       0.37      0.29      0.32     15830\n",
            "           1       0.45      0.63      0.52     22708\n",
            "\n",
            "    accuracy                           0.41     54960\n",
            "   macro avg       0.40      0.39      0.38     54960\n",
            "weighted avg       0.40      0.41      0.40     54960\n",
            "\n",
            "testing 8   9\n",
            "Accuracy: 0.4097707423580786\n",
            "[[ 4074  3354  8994]\n",
            " [ 2961  4497  8372]\n",
            " [ 4042  4716 13950]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.37      0.25      0.30     16422\n",
            "           0       0.36      0.28      0.32     15830\n",
            "           1       0.45      0.61      0.52     22708\n",
            "\n",
            "    accuracy                           0.41     54960\n",
            "   macro avg       0.39      0.38      0.38     54960\n",
            "weighted avg       0.40      0.41      0.39     54960\n",
            "\n",
            "testing 8   10\n",
            "Accuracy: 0.39828966521106257\n",
            "[[ 4353  3252  8817]\n",
            " [ 3440  4435  7955]\n",
            " [ 4649  4957 13102]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.35      0.27      0.30     16422\n",
            "           0       0.35      0.28      0.31     15830\n",
            "           1       0.44      0.58      0.50     22708\n",
            "\n",
            "    accuracy                           0.40     54960\n",
            "   macro avg       0.38      0.37      0.37     54960\n",
            "weighted avg       0.39      0.40      0.39     54960\n",
            "\n",
            "testing 8   11\n",
            "Accuracy: 0.38957423580786027\n",
            "[[ 4611  3487  8324]\n",
            " [ 3771  4512  7547]\n",
            " [ 5174  5246 12288]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.34      0.28      0.31     16422\n",
            "           0       0.34      0.29      0.31     15830\n",
            "           1       0.44      0.54      0.48     22708\n",
            "\n",
            "    accuracy                           0.39     54960\n",
            "   macro avg       0.37      0.37      0.37     54960\n",
            "weighted avg       0.38      0.39      0.38     54960\n",
            "\n",
            "testing 9   2\n",
            "Accuracy: 0.42727438136826784\n",
            "[[ 2040  1761 12621]\n",
            " [ 1129  2552 12149]\n",
            " [ 1426  2391 18891]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.44      0.12      0.19     16422\n",
            "           0       0.38      0.16      0.23     15830\n",
            "           1       0.43      0.83      0.57     22708\n",
            "\n",
            "    accuracy                           0.43     54960\n",
            "   macro avg       0.42      0.37      0.33     54960\n",
            "weighted avg       0.42      0.43      0.36     54960\n",
            "\n",
            "testing 9   3\n",
            "Accuracy: 0.4291484716157205\n",
            "[[ 2655  1857 11910]\n",
            " [ 1593  2904 11333]\n",
            " [ 2016  2665 18027]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.42      0.16      0.23     16422\n",
            "           0       0.39      0.18      0.25     15830\n",
            "           1       0.44      0.79      0.56     22708\n",
            "\n",
            "    accuracy                           0.43     54960\n",
            "   macro avg       0.42      0.38      0.35     54960\n",
            "weighted avg       0.42      0.43      0.37     54960\n",
            "\n",
            "testing 9   4\n",
            "Accuracy: 0.4270014556040757\n",
            "[[ 3058  2535 10829]\n",
            " [ 1716  3867 10247]\n",
            " [ 2570  3595 16543]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.42      0.19      0.26     16422\n",
            "           0       0.39      0.24      0.30     15830\n",
            "           1       0.44      0.73      0.55     22708\n",
            "\n",
            "    accuracy                           0.43     54960\n",
            "   macro avg       0.41      0.39      0.37     54960\n",
            "weighted avg       0.42      0.43      0.39     54960\n",
            "\n",
            "testing 9   5\n",
            "Accuracy: 0.42818413391557497\n",
            "[[ 3474  2698 10250]\n",
            " [ 2062  4140  9628]\n",
            " [ 2880  3909 15919]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.41      0.21      0.28     16422\n",
            "           0       0.39      0.26      0.31     15830\n",
            "           1       0.44      0.70      0.54     22708\n",
            "\n",
            "    accuracy                           0.43     54960\n",
            "   macro avg       0.41      0.39      0.38     54960\n",
            "weighted avg       0.42      0.43      0.40     54960\n",
            "\n",
            "testing 9   6\n",
            "Accuracy: 0.4240174672489083\n",
            "[[ 3673  2849  9900]\n",
            " [ 2367  4237  9226]\n",
            " [ 3362  3952 15394]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.39      0.22      0.28     16422\n",
            "           0       0.38      0.27      0.32     15830\n",
            "           1       0.45      0.68      0.54     22708\n",
            "\n",
            "    accuracy                           0.42     54960\n",
            "   macro avg       0.41      0.39      0.38     54960\n",
            "weighted avg       0.41      0.42      0.40     54960\n",
            "\n",
            "testing 9   7\n",
            "Accuracy: 0.4147561863173217\n",
            "[[ 3919  2969  9534]\n",
            " [ 2734  4336  8760]\n",
            " [ 3866  4302 14540]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.37      0.24      0.29     16422\n",
            "           0       0.37      0.27      0.32     15830\n",
            "           1       0.44      0.64      0.52     22708\n",
            "\n",
            "    accuracy                           0.41     54960\n",
            "   macro avg       0.40      0.38      0.38     54960\n",
            "weighted avg       0.40      0.41      0.39     54960\n",
            "\n",
            "testing 9   8\n",
            "Accuracy: 0.4135371179039301\n",
            "[[ 3990  3235  9197]\n",
            " [ 2864  4567  8399]\n",
            " [ 4043  4494 14171]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.37      0.24      0.29     16422\n",
            "           0       0.37      0.29      0.32     15830\n",
            "           1       0.45      0.62      0.52     22708\n",
            "\n",
            "    accuracy                           0.41     54960\n",
            "   macro avg       0.39      0.39      0.38     54960\n",
            "weighted avg       0.40      0.41      0.40     54960\n",
            "\n",
            "testing 9   9\n",
            "Accuracy: 0.4072416302765648\n",
            "[[ 4048  3383  8991]\n",
            " [ 2976  4562  8292]\n",
            " [ 4144  4792 13772]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.36      0.25      0.29     16422\n",
            "           0       0.36      0.29      0.32     15830\n",
            "           1       0.44      0.61      0.51     22708\n",
            "\n",
            "    accuracy                           0.41     54960\n",
            "   macro avg       0.39      0.38      0.38     54960\n",
            "weighted avg       0.39      0.41      0.39     54960\n",
            "\n",
            "testing 9   10\n",
            "Accuracy: 0.3950509461426492\n",
            "[[ 4347  3408  8667]\n",
            " [ 3466  4549  7815]\n",
            " [ 4722  5170 12816]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.35      0.26      0.30     16422\n",
            "           0       0.35      0.29      0.31     15830\n",
            "           1       0.44      0.56      0.49     22708\n",
            "\n",
            "    accuracy                           0.40     54960\n",
            "   macro avg       0.38      0.37      0.37     54960\n",
            "weighted avg       0.38      0.40      0.38     54960\n",
            "\n",
            "testing 9   11\n",
            "Accuracy: 0.3893377001455604\n",
            "[[ 4629  3635  8158]\n",
            " [ 3797  4595  7438]\n",
            " [ 5193  5341 12174]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.34      0.28      0.31     16422\n",
            "           0       0.34      0.29      0.31     15830\n",
            "           1       0.44      0.54      0.48     22708\n",
            "\n",
            "    accuracy                           0.39     54960\n",
            "   macro avg       0.37      0.37      0.37     54960\n",
            "weighted avg       0.38      0.39      0.38     54960\n",
            "\n",
            "testing 10   2\n",
            "Accuracy: 0.4276928675400291\n",
            "[[ 1956  1605 12861]\n",
            " [ 1115  2420 12295]\n",
            " [ 1379  2199 19130]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.44      0.12      0.19     16422\n",
            "           0       0.39      0.15      0.22     15830\n",
            "           1       0.43      0.84      0.57     22708\n",
            "\n",
            "    accuracy                           0.43     54960\n",
            "   macro avg       0.42      0.37      0.33     54960\n",
            "weighted avg       0.42      0.43      0.36     54960\n",
            "\n",
            "testing 10   3\n",
            "Accuracy: 0.4290938864628821\n",
            "[[ 2713  1882 11827]\n",
            " [ 1606  2953 11271]\n",
            " [ 2034  2757 17917]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.43      0.17      0.24     16422\n",
            "           0       0.39      0.19      0.25     15830\n",
            "           1       0.44      0.79      0.56     22708\n",
            "\n",
            "    accuracy                           0.43     54960\n",
            "   macro avg       0.42      0.38      0.35     54960\n",
            "weighted avg       0.42      0.43      0.38     54960\n",
            "\n",
            "testing 10   4\n",
            "Accuracy: 0.4290211062590975\n",
            "[[ 3305  2486 10631]\n",
            " [ 1850  3770 10210]\n",
            " [ 2731  3473 16504]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.42      0.20      0.27     16422\n",
            "           0       0.39      0.24      0.30     15830\n",
            "           1       0.44      0.73      0.55     22708\n",
            "\n",
            "    accuracy                           0.43     54960\n",
            "   macro avg       0.42      0.39      0.37     54960\n",
            "weighted avg       0.42      0.43      0.39     54960\n",
            "\n",
            "testing 10   5\n",
            "Accuracy: 0.4273835516739447\n",
            "[[ 3608  2695 10119]\n",
            " [ 2230  4210  9390]\n",
            " [ 3046  3991 15671]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.41      0.22      0.29     16422\n",
            "           0       0.39      0.27      0.32     15830\n",
            "           1       0.45      0.69      0.54     22708\n",
            "\n",
            "    accuracy                           0.43     54960\n",
            "   macro avg       0.41      0.39      0.38     54960\n",
            "weighted avg       0.42      0.43      0.40     54960\n",
            "\n",
            "testing 10   6\n",
            "Accuracy: 0.4235080058224163\n",
            "[[ 3684  2852  9886]\n",
            " [ 2339  4303  9188]\n",
            " [ 3338  4081 15289]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.39      0.22      0.29     16422\n",
            "           0       0.38      0.27      0.32     15830\n",
            "           1       0.44      0.67      0.54     22708\n",
            "\n",
            "    accuracy                           0.42     54960\n",
            "   macro avg       0.41      0.39      0.38     54960\n",
            "weighted avg       0.41      0.42      0.40     54960\n",
            "\n",
            "testing 10   7\n",
            "Accuracy: 0.4143013100436681\n",
            "[[ 3922  3047  9453]\n",
            " [ 2745  4447  8638]\n",
            " [ 3887  4420 14401]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.37      0.24      0.29     16422\n",
            "           0       0.37      0.28      0.32     15830\n",
            "           1       0.44      0.63      0.52     22708\n",
            "\n",
            "    accuracy                           0.41     54960\n",
            "   macro avg       0.40      0.38      0.38     54960\n",
            "weighted avg       0.40      0.41      0.39     54960\n",
            "\n",
            "testing 10   8\n",
            "Accuracy: 0.4141193595342067\n",
            "[[ 4078  3277  9067]\n",
            " [ 2895  4547  8388]\n",
            " [ 4058  4515 14135]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.37      0.25      0.30     16422\n",
            "           0       0.37      0.29      0.32     15830\n",
            "           1       0.45      0.62      0.52     22708\n",
            "\n",
            "    accuracy                           0.41     54960\n",
            "   macro avg       0.40      0.39      0.38     54960\n",
            "weighted avg       0.40      0.41      0.40     54960\n",
            "\n",
            "testing 10   9\n",
            "Accuracy: 0.40554949053857353\n",
            "[[ 4053  3421  8948]\n",
            " [ 2993  4574  8263]\n",
            " [ 4181  4865 13662]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.36      0.25      0.29     16422\n",
            "           0       0.36      0.29      0.32     15830\n",
            "           1       0.44      0.60      0.51     22708\n",
            "\n",
            "    accuracy                           0.41     54960\n",
            "   macro avg       0.39      0.38      0.37     54960\n",
            "weighted avg       0.39      0.41      0.39     54960\n",
            "\n",
            "testing 10   10\n",
            "Accuracy: 0.3941957787481805\n",
            "[[ 4337  3474  8611]\n",
            " [ 3465  4582  7783]\n",
            " [ 4729  5233 12746]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.35      0.26      0.30     16422\n",
            "           0       0.34      0.29      0.31     15830\n",
            "           1       0.44      0.56      0.49     22708\n",
            "\n",
            "    accuracy                           0.39     54960\n",
            "   macro avg       0.38      0.37      0.37     54960\n",
            "weighted avg       0.38      0.39      0.38     54960\n",
            "\n",
            "testing 10   11\n",
            "Accuracy: 0.3878457059679767\n",
            "[[ 4587  3648  8187]\n",
            " [ 3822  4620  7388]\n",
            " [ 5150  5449 12109]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.34      0.28      0.31     16422\n",
            "           0       0.34      0.29      0.31     15830\n",
            "           1       0.44      0.53      0.48     22708\n",
            "\n",
            "    accuracy                           0.39     54960\n",
            "   macro avg       0.37      0.37      0.37     54960\n",
            "weighted avg       0.38      0.39      0.38     54960\n",
            "\n",
            "testing 11   2\n",
            "Accuracy: 0.42856622998544397\n",
            "[[ 2131  1452 12839]\n",
            " [ 1199  2206 12425]\n",
            " [ 1518  1973 19217]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.44      0.13      0.20     16422\n",
            "           0       0.39      0.14      0.21     15830\n",
            "           1       0.43      0.85      0.57     22708\n",
            "\n",
            "    accuracy                           0.43     54960\n",
            "   macro avg       0.42      0.37      0.33     54960\n",
            "weighted avg       0.42      0.43      0.36     54960\n",
            "\n",
            "testing 11   3\n",
            "Accuracy: 0.43045851528384277\n",
            "[[ 2912  1921 11589]\n",
            " [ 1690  3011 11129]\n",
            " [ 2124  2849 17735]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.43      0.18      0.25     16422\n",
            "           0       0.39      0.19      0.26     15830\n",
            "           1       0.44      0.78      0.56     22708\n",
            "\n",
            "    accuracy                           0.43     54960\n",
            "   macro avg       0.42      0.38      0.36     54960\n",
            "weighted avg       0.42      0.43      0.38     54960\n",
            "\n",
            "testing 11   4\n",
            "Accuracy: 0.4288755458515284\n",
            "[[ 3428  2656 10338]\n",
            " [ 1885  3996  9949]\n",
            " [ 2828  3733 16147]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.42      0.21      0.28     16422\n",
            "           0       0.38      0.25      0.30     15830\n",
            "           1       0.44      0.71      0.55     22708\n",
            "\n",
            "    accuracy                           0.43     54960\n",
            "   macro avg       0.42      0.39      0.38     54960\n",
            "weighted avg       0.42      0.43      0.40     54960\n",
            "\n",
            "testing 11   5\n",
            "Accuracy: 0.4270014556040757\n",
            "[[ 3640  2785  9997]\n",
            " [ 2249  4326  9255]\n",
            " [ 3108  4098 15502]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.40      0.22      0.29     16422\n",
            "           0       0.39      0.27      0.32     15830\n",
            "           1       0.45      0.68      0.54     22708\n",
            "\n",
            "    accuracy                           0.43     54960\n",
            "   macro avg       0.41      0.39      0.38     54960\n",
            "weighted avg       0.42      0.43      0.40     54960\n",
            "\n",
            "testing 11   6\n",
            "Accuracy: 0.42139737991266374\n",
            "[[ 3736  2905  9781]\n",
            " [ 2456  4344  9030]\n",
            " [ 3482  4146 15080]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.39      0.23      0.29     16422\n",
            "           0       0.38      0.27      0.32     15830\n",
            "           1       0.44      0.66      0.53     22708\n",
            "\n",
            "    accuracy                           0.42     54960\n",
            "   macro avg       0.40      0.39      0.38     54960\n",
            "weighted avg       0.41      0.42      0.40     54960\n",
            "\n",
            "testing 11   7\n",
            "Accuracy: 0.4143013100436681\n",
            "[[ 3972  3064  9386]\n",
            " [ 2779  4439  8612]\n",
            " [ 3943  4406 14359]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.37      0.24      0.29     16422\n",
            "           0       0.37      0.28      0.32     15830\n",
            "           1       0.44      0.63      0.52     22708\n",
            "\n",
            "    accuracy                           0.41     54960\n",
            "   macro avg       0.40      0.38      0.38     54960\n",
            "weighted avg       0.40      0.41      0.40     54960\n",
            "\n",
            "testing 11   8\n",
            "Accuracy: 0.4116266375545852\n",
            "[[ 4105  3217  9100]\n",
            " [ 2946  4522  8362]\n",
            " [ 4131  4581 13996]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.37      0.25      0.30     16422\n",
            "           0       0.37      0.29      0.32     15830\n",
            "           1       0.44      0.62      0.52     22708\n",
            "\n",
            "    accuracy                           0.41     54960\n",
            "   macro avg       0.39      0.38      0.38     54960\n",
            "weighted avg       0.40      0.41      0.39     54960\n",
            "\n",
            "testing 11   9\n",
            "Accuracy: 0.40343886462882095\n",
            "[[ 4156  3403  8863]\n",
            " [ 3118  4537  8175]\n",
            " [ 4405  4823 13480]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.36      0.25      0.30     16422\n",
            "           0       0.36      0.29      0.32     15830\n",
            "           1       0.44      0.59      0.51     22708\n",
            "\n",
            "    accuracy                           0.40     54960\n",
            "   macro avg       0.38      0.38      0.37     54960\n",
            "weighted avg       0.39      0.40      0.39     54960\n",
            "\n",
            "testing 11   10\n",
            "Accuracy: 0.3937409024745269\n",
            "[[ 4363  3530  8529]\n",
            " [ 3521  4652  7657]\n",
            " [ 4872  5211 12625]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.34      0.27      0.30     16422\n",
            "           0       0.35      0.29      0.32     15830\n",
            "           1       0.44      0.56      0.49     22708\n",
            "\n",
            "    accuracy                           0.39     54960\n",
            "   macro avg       0.38      0.37      0.37     54960\n",
            "weighted avg       0.38      0.39      0.38     54960\n",
            "\n",
            "testing 11   11\n",
            "Accuracy: 0.3844250363901019\n",
            "[[ 4535  3750  8137]\n",
            " [ 3859  4665  7306]\n",
            " [ 5209  5571 11928]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.33      0.28      0.30     16422\n",
            "           0       0.33      0.29      0.31     15830\n",
            "           1       0.44      0.53      0.48     22708\n",
            "\n",
            "    accuracy                           0.38     54960\n",
            "   macro avg       0.37      0.37      0.36     54960\n",
            "weighted avg       0.38      0.38      0.38     54960\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (max_x)\n",
        "print (max_y)\n",
        "print (max_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2bt7ueZFepi",
        "outputId": "61452437-a7c9-4042-937b-14ddc14f7907"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n",
            "5\n",
            "0.4320778748180495\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "best combination when n_estimators=3, max_depth=5\n",
        "\n",
        "-------------------------\n",
        "\n",
        "testing combinations of learning_rates"
      ],
      "metadata": {
        "id": "Zlp38cSQpQ0l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bst = XGBClassifier(n_estimators=3, max_depth=5, learning_rate=1, objective='binary:logistic', tree_method='hist')\n",
        "bst.fit(np.array(x_train), np.array(y_train_7))\n",
        "y_pred_7 = bst.predict(x_test)\n",
        "accuracy = metrics.accuracy_score(y_test_7, y_pred_7)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(confusion_matrix(y_test_7,y_pred_7))\n",
        "print(classification_report(y_test_7,y_pred_7))\n",
        "\n",
        "bst = XGBClassifier(n_estimators=3, max_depth=5, learning_rate=0.9, objective='binary:logistic', tree_method='hist')\n",
        "bst.fit(np.array(x_train), np.array(y_train_7))\n",
        "y_pred_7 = bst.predict(x_test)\n",
        "accuracy = metrics.accuracy_score(y_test_7, y_pred_7)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(confusion_matrix(y_test_7,y_pred_7))\n",
        "print(classification_report(y_test_7,y_pred_7))\n",
        "\n",
        "\n",
        "bst = XGBClassifier(n_estimators=3, max_depth=5, learning_rate=1.1, objective='binary:logistic', tree_method='hist')\n",
        "bst.fit(np.array(x_train), np.array(y_train_7))\n",
        "y_pred_7 = bst.predict(x_test)\n",
        "accuracy = metrics.accuracy_score(y_test_7, y_pred_7)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(confusion_matrix(y_test_7,y_pred_7))\n",
        "print(classification_report(y_test_7,y_pred_7))\n",
        "\n",
        "\n",
        "bst = XGBClassifier(n_estimators=3, max_depth=5, learning_rate=1.2, objective='binary:logistic', tree_method='hist')\n",
        "bst.fit(np.array(x_train), np.array(y_train_7))\n",
        "y_pred_7 = bst.predict(x_test)\n",
        "accuracy = metrics.accuracy_score(y_test_7, y_pred_7)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(confusion_matrix(y_test_7,y_pred_7))\n",
        "print(classification_report(y_test_7,y_pred_7))\n",
        "\n",
        "bst = XGBClassifier(n_estimators=3, max_depth=5, learning_rate=0.8, objective='binary:logistic', tree_method='hist')\n",
        "bst.fit(np.array(x_train), np.array(y_train_7))\n",
        "y_pred_7 = bst.predict(x_test)\n",
        "accuracy = metrics.accuracy_score(y_test_7, y_pred_7)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(confusion_matrix(y_test_7,y_pred_7))\n",
        "print(classification_report(y_test_7,y_pred_7))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCCQLWOIIjbh",
        "outputId": "99e8b8a4-e64a-40d0-f4e4-e0db233346ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.4320778748180495\n",
            "[[ 2588  2025 11809]\n",
            " [ 1396  3248 11186]\n",
            " [ 1867  2930 17911]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.44      0.16      0.23     16422\n",
            "           0       0.40      0.21      0.27     15830\n",
            "           1       0.44      0.79      0.56     22708\n",
            "\n",
            "    accuracy                           0.43     54960\n",
            "   macro avg       0.43      0.38      0.36     54960\n",
            "weighted avg       0.43      0.43      0.38     54960\n",
            "\n",
            "Accuracy: 0.4308951965065502\n",
            "[[ 2309  1860 12253]\n",
            " [ 1159  3009 11662]\n",
            " [ 1569  2775 18364]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.46      0.14      0.22     16422\n",
            "           0       0.39      0.19      0.26     15830\n",
            "           1       0.43      0.81      0.57     22708\n",
            "\n",
            "    accuracy                           0.43     54960\n",
            "   macro avg       0.43      0.38      0.35     54960\n",
            "weighted avg       0.43      0.43      0.37     54960\n",
            "\n",
            "Accuracy: 0.42918486171761283\n",
            "[[ 2707  1959 11756]\n",
            " [ 1471  3109 11250]\n",
            " [ 1994  2942 17772]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.44      0.16      0.24     16422\n",
            "           0       0.39      0.20      0.26     15830\n",
            "           1       0.44      0.78      0.56     22708\n",
            "\n",
            "    accuracy                           0.43     54960\n",
            "   macro avg       0.42      0.38      0.35     54960\n",
            "weighted avg       0.42      0.43      0.38     54960\n",
            "\n",
            "Accuracy: 0.42954876273653564\n",
            "[[ 2800  1941 11681]\n",
            " [ 1532  3012 11286]\n",
            " [ 2100  2812 17796]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.44      0.17      0.25     16422\n",
            "           0       0.39      0.19      0.26     15830\n",
            "           1       0.44      0.78      0.56     22708\n",
            "\n",
            "    accuracy                           0.43     54960\n",
            "   macro avg       0.42      0.38      0.35     54960\n",
            "weighted avg       0.42      0.43      0.38     54960\n",
            "\n",
            "Accuracy: 0.43040393013100436\n",
            "[[ 2246  1832 12344]\n",
            " [ 1170  2736 11924]\n",
            " [ 1508  2527 18673]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.46      0.14      0.21     16422\n",
            "           0       0.39      0.17      0.24     15830\n",
            "           1       0.43      0.82      0.57     22708\n",
            "\n",
            "    accuracy                           0.43     54960\n",
            "   macro avg       0.43      0.38      0.34     54960\n",
            "weighted avg       0.43      0.43      0.37     54960\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conclusion: model works well with n_estimators=3, max_depth=5, learning_rate=1 setting"
      ],
      "metadata": {
        "id": "A-CJQUWQIOPK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing with different training sets\n",
        "\n",
        "1.   changing 2008 to test data\n",
        "2.   removing 2008 from test and train data\n",
        "\n",
        "Conclusion: does not seem to improve accuracy result"
      ],
      "metadata": {
        "id": "omyUmeJWI_yW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = []\n",
        "y_train_7 = []\n",
        "x_test = []\n",
        "y_test_7 = []\n",
        "features = ['tend7', 'avg30', 'sd30', 'range30', 'vol30', 'stosc', 'MACD']\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "  if (isinstance(row['date'], str)):\n",
        "    dt = datetime.strptime(row['date'], '%d/%m/%Y')\n",
        "    curr = []\n",
        "\n",
        "    for feature in features:\n",
        "      curr.append(row[feature])\n",
        "\n",
        "    if (dt.year == 2009 or dt.year == 2012 or dt.year == 2017): # test data\n",
        "      x_test.append(curr)\n",
        "      y_test_7.append(row['dirNext7'])\n",
        "    else: # train data\n",
        "      x_train.append(curr)\n",
        "      y_train_7.append(row['dirNext7'])\n",
        "\n",
        "bst = XGBClassifier(n_estimators=3, max_depth=5, learning_rate=1, objective='binary:logistic', tree_method='hist')\n",
        "bst.fit(np.array(x_train), np.array(y_train_7))\n",
        "y_pred_7 = bst.predict(x_test)\n",
        "accuracy = metrics.accuracy_score(y_test_7, y_pred_7)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(confusion_matrix(y_test_7,y_pred_7))\n",
        "print(classification_report(y_test_7,y_pred_7))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yycqc7OeJjC0",
        "outputId": "6defb9ac-6eff-43f9-ac41-61bc8fdaef51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.42787268346587926\n",
            "[[ 2502  2575  8796]\n",
            " [ 1892  3908 11350]\n",
            " [ 2934  4035 17209]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.34      0.18      0.24     13873\n",
            "           0       0.37      0.23      0.28     17150\n",
            "           1       0.46      0.71      0.56     24178\n",
            "\n",
            "    accuracy                           0.43     55201\n",
            "   macro avg       0.39      0.37      0.36     55201\n",
            "weighted avg       0.40      0.43      0.39     55201\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = []\n",
        "y_train_7 = []\n",
        "x_test = []\n",
        "y_test_7 = []\n",
        "features = ['tend7', 'avg30', 'sd30', 'range30', 'vol30', 'stosc', 'MACD']\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "  if (isinstance(row['date'], str)):\n",
        "    dt = datetime.strptime(row['date'], '%d/%m/%Y')\n",
        "    curr = []\n",
        "\n",
        "    for feature in features:\n",
        "      curr.append(row[feature])\n",
        "\n",
        "    if (dt.year == 2017): # test data\n",
        "      x_test.append(curr)\n",
        "      y_test_7.append(row['dirNext7'])\n",
        "    elif (dt.year == 2013 or dt.year == 2014 or dt.year == 2015 or dt.year == 2016): # train data\n",
        "      x_train.append(curr)\n",
        "      y_train_7.append(row['dirNext7'])\n",
        "\n",
        "bst = XGBClassifier(n_estimators=3, max_depth=5, learning_rate=1, objective='binary:logistic', tree_method='hist')\n",
        "bst.fit(np.array(x_train), np.array(y_train_7))\n",
        "y_pred_7 = bst.predict(x_test)\n",
        "accuracy = metrics.accuracy_score(y_test_7, y_pred_7)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(confusion_matrix(y_test_7,y_pred_7))\n",
        "print(classification_report(y_test_7,y_pred_7))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pME33k6TKXIt",
        "outputId": "d58458b0-69ed-4f0a-ee89-300207acf41d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.4222941720629047\n",
            "[[ 724  699 2297]\n",
            " [ 896 1219 3534]\n",
            " [1182 1384 5361]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.26      0.19      0.22      3720\n",
            "           0       0.37      0.22      0.27      5649\n",
            "           1       0.48      0.68      0.56      7927\n",
            "\n",
            "    accuracy                           0.42     17296\n",
            "   macro avg       0.37      0.36      0.35     17296\n",
            "weighted avg       0.40      0.42      0.39     17296\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing with df30 using different set of features"
      ],
      "metadata": {
        "id": "1kELkq0OOXR9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = []\n",
        "y_train_30 = []\n",
        "y_train_7 = []\n",
        "x_test = []\n",
        "y_test_30 = []\n",
        "y_test_7 = []\n",
        "features = [\"open\", \"close\", \"high\", \"low\", \"avg\", \"avg7\", \"range7\", \"avg30\",  \"range30\"] \n",
        "for index, row in df.iterrows():\n",
        "  if (isinstance(row['date'], str)):\n",
        "    dt = datetime.strptime(row['date'], '%d/%m/%Y')\n",
        "    curr = []\n",
        "\n",
        "    for feature in features:\n",
        "      curr.append(row[feature])\n",
        "\n",
        "    date = int(dt.strftime('%Y-%m-%d').translate({ord('-'): None}))\n",
        "    curr.append(date)\n",
        "\n",
        "    if (dt.year == 2008 or dt.year == 2012 or dt.year == 2017): # test data\n",
        "      x_test.append(curr)\n",
        "      y_test_30.append(row['dirNext30'])\n",
        "      y_test_7.append(row['dirNext7'])\n",
        "    else: # train data\n",
        "      x_train.append(curr)\n",
        "      y_train_30.append(row['dirNext30'])\n",
        "      y_train_7.append(row['dirNext7'])"
      ],
      "metadata": {
        "id": "mUdYk9YIOWjC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bst = XGBClassifier(n_estimators=3, max_depth=5, learning_rate=1, objective='binary:logistic', tree_method='hist')\n",
        "bst.fit(np.array(x_train), np.array(y_train_30))\n",
        "y_pred_30 = bst.predict(x_test)\n",
        "accuracy = metrics.accuracy_score(y_test_30, y_pred_30)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(confusion_matrix(y_test_30,y_pred_30))\n",
        "print(classification_report(y_test_30,y_pred_30))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJn9qPRpACEc",
        "outputId": "41d0725d-a0c2-4eb7-ff02-c4b93985832c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5426491994177584\n",
            "[[ 8092   237  5749]\n",
            " [ 3471   843 11042]\n",
            " [ 4204   433 20889]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.51      0.57      0.54     14078\n",
            "           0       0.56      0.05      0.10     15356\n",
            "           1       0.55      0.82      0.66     25526\n",
            "\n",
            "    accuracy                           0.54     54960\n",
            "   macro avg       0.54      0.48      0.43     54960\n",
            "weighted avg       0.54      0.54      0.47     54960\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bst = XGBClassifier(n_estimators=3, max_depth=5, learning_rate=1, objective='binary:logistic', tree_method='hist')\n",
        "bst.fit(np.array(x_train), np.array(y_train_7))\n",
        "y_pred_7 = bst.predict(x_test)\n",
        "accuracy = metrics.accuracy_score(y_test_7, y_pred_7)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(confusion_matrix(y_test_7,y_pred_7))\n",
        "print(classification_report(y_test_7,y_pred_7))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SLCimFa1t0Pm",
        "outputId": "2c61591c-d249-4a05-d55d-886a5b4a7aa4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.442085152838428\n",
            "[[ 7506   308  8608]\n",
            " [ 3320   712 11798]\n",
            " [ 6062   567 16079]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.44      0.46      0.45     16422\n",
            "           0       0.45      0.04      0.08     15830\n",
            "           1       0.44      0.71      0.54     22708\n",
            "\n",
            "    accuracy                           0.44     54960\n",
            "   macro avg       0.44      0.40      0.36     54960\n",
            "weighted avg       0.44      0.44      0.38     54960\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# more testings after consulting TA\n",
        "*  Testing higher n_estimators, max_depth, and smaller learning_rate\n",
        "*   List item\n",
        "\n"
      ],
      "metadata": {
        "id": "0_lIncGGmqry"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = []\n",
        "y_train_7 = []\n",
        "y_train_30 = []\n",
        "x_test = []\n",
        "y_test_7 = []\n",
        "y_test_30 = []\n",
        "features = ['tend7', 'avg30', 'sd30', 'range30', 'vol30', 'stosc', 'MACD']\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "  if (isinstance(row['date'], str)):\n",
        "    dt = datetime.strptime(row['date'], '%d/%m/%Y')\n",
        "    curr = []\n",
        "\n",
        "    for feature in features:\n",
        "      curr.append(row[feature])\n",
        "\n",
        "    if (dt.year == 2009 or dt.year == 2012 or dt.year == 2017): # test data\n",
        "      x_test.append(curr)\n",
        "      y_test_7.append(row['dirNext7'])\n",
        "      y_test_30.append(row['dirNext30'])\n",
        "    else: # train data\n",
        "      x_train.append(curr)\n",
        "      y_train_7.append(row['dirNext7'])\n",
        "      y_train_30.append(row['dirNext30'])"
      ],
      "metadata": {
        "id": "q5iRThucmrBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bst = XGBClassifier(n_estimators=100, max_depth=7, learning_rate=0.1, objective='binary:logistic', tree_method='hist')\n",
        "bst.fit(np.array(x_train), np.array(y_train_30))\n",
        "y_pred_30 = bst.predict(x_test)\n",
        "accuracy = metrics.accuracy_score(y_test_30, y_pred_30)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(confusion_matrix(y_test_30,y_pred_30))\n",
        "print(classification_report(y_test_30,y_pred_30))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9noXeRd1mwuK",
        "outputId": "c3660ef1-2398-4b67-bd18-dd9c9c8833b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.4777449683882538\n",
            "[[  903  1238  6943]\n",
            " [ 1163  3139 11715]\n",
            " [ 2966  4804 22330]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.18      0.10      0.13      9084\n",
            "           0       0.34      0.20      0.25     16017\n",
            "           1       0.54      0.74      0.63     30100\n",
            "\n",
            "    accuracy                           0.48     55201\n",
            "   macro avg       0.36      0.35      0.34     55201\n",
            "weighted avg       0.43      0.48      0.44     55201\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.rename(columns = {'Unnamed: 0' :'index'})\n",
        "df['date'] = pd.to_datetime(df['date'])\n",
        "df['year'] = df['date'].dt.year\n",
        "train_year = [2005, 2006, 2007, 2008, 2010, 2011, 2013, 2014, 2015, 2016]\n",
        "test_year = [2009, 2012, 2017]\n",
        "\n",
        "df_train = df[df['year'].isin(train_year)]\n",
        "df_test = df[df['year'].isin(test_year)]\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import neighbors\n",
        "from sklearn.metrics import mean_squared_error, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "# based on corr matrix, choose those 4 features with lowest corr\n",
        "df30_Xtrain = df_train[[\"avg30\", \"sd30\", \"range30\", \"vol30\", \"dir30\", \"tend30\", \"RSI\", \"stosc\", \"MACD\"]].copy() \n",
        "df30_ytrain = df_train['dirNext30'].copy()\n",
        "df30_Xtest = df_test[[\"avg30\", \"sd30\", \"range30\", \"vol30\", \"dir30\", \"tend30\", \"RSI\", \"stosc\", \"MACD\"]].copy()\n",
        "df30_ytest = df_test['dirNext30'].copy()  "
      ],
      "metadata": {
        "id": "RzpFhW3zyLOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bst = XGBClassifier(n_estimators=3, max_depth=5, learning_rate=0.1, objective='binary:logistic', tree_method='hist')\n",
        "bst.fit(np.array(x_train), np.array(y_train_30))\n",
        "y_pred_30 = bst.predict(x_test)\n",
        "accuracy = metrics.accuracy_score(y_test_30, y_pred_30)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(confusion_matrix(y_test_30,y_pred_30))\n",
        "print(classification_report(y_test_30,y_pred_30))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FReVYyuwzt2U",
        "outputId": "b58cc267-96a8-4ee4-daf6-963db7015c57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5415481603594138\n",
            "[[  122   108  8854]\n",
            " [  133   341 15543]\n",
            " [  374   295 29431]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.19      0.01      0.03      9084\n",
            "           0       0.46      0.02      0.04     16017\n",
            "           1       0.55      0.98      0.70     30100\n",
            "\n",
            "    accuracy                           0.54     55201\n",
            "   macro avg       0.40      0.34      0.26     55201\n",
            "weighted avg       0.46      0.54      0.40     55201\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# conclusion"
      ],
      "metadata": {
        "id": "WkUF-YhheHzG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Due to time constraint, we did not explore more possibilities of using boosting trees. Our final performance of boosting trees was similar to random forest."
      ],
      "metadata": {
        "id": "GUfBTUqgh2lg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "References: \n",
        "\n",
        "XGBoost documentation: https://xgboost.readthedocs.io/en/stable/tutorials/multioutput.html\n",
        "\n",
        "Introduction to boosted trees: https://towardsdatascience.com/introduction-to-boosted-trees-2692b6653b53#:~:text=Boosting%20transforms%20weak%20decision%20trees,known%20as%20ensemble%20meta%2Dalgorithms.\n",
        "\n"
      ],
      "metadata": {
        "id": "RuOeV4LQeJUv"
      }
    }
  ]
}